"use strict";
/**
 * Pipelineé›†æˆHTTPæœåŠ¡å™¨
 *
 * å°†Pipelineç®¡ç†ç³»ç»Ÿé›†æˆåˆ°HTTPæœåŠ¡å™¨ä¸­ï¼Œå®ç°å®Œæ•´çš„è¯·æ±‚å¤„ç†æµç¨‹
 *
 * @author Jason Zhang
 */
var __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    var desc = Object.getOwnPropertyDescriptor(m, k);
    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
      desc = { enumerable: true, get: function() { return m[k]; } };
    }
    Object.defineProperty(o, k2, desc);
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {
    Object.defineProperty(o, "default", { enumerable: true, value: v });
}) : function(o, v) {
    o["default"] = v;
});
var __importStar = (this && this.__importStar) || function (mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
    __setModuleDefault(result, mod);
    return result;
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.PipelineServer = void 0;
const http_server_1 = require("./http-server");
const jq_json_handler_1 = require("../utils/jq-json-handler");
const server_defaults_1 = require("../constants/server-defaults");
const events_1 = require("events");
const pipeline_debug_recorder_1 = require("../debug/pipeline-debug-recorder");
/**
 * Pipelineé›†æˆHTTPæœåŠ¡å™¨
 * ä½¿ç”¨ç»„åˆè€Œéç»§æ‰¿çš„æ–¹å¼é›†æˆHTTPServeråŠŸèƒ½
 */
class PipelineServer extends events_1.EventEmitter {
    constructor(config, middlewareManager, pipelineService) {
        super();
        this.serverConfig = config;
        this.middlewareManager = middlewareManager;
        // ä½¿ç”¨ç»„åˆï¼šåˆ›å»ºHTTPServerå®ä¾‹
        this.httpServer = new http_server_1.HTTPServer(config);
        // è½¬å‘HTTPServerçš„äº‹ä»¶åˆ°PipelineServer
        this.httpServer.on('error', error => this.emit('error', error));
        this.httpServer.on('started', data => this.emit('started', data));
        this.httpServer.on('stopped', () => this.emit('stopped'));
        // ä½¿ç”¨ä¾èµ–æ³¨å…¥çš„PipelineæœåŠ¡æˆ–åˆ›å»ºé»˜è®¤å®ç°
        if (pipelineService) {
            this.pipelineService = pipelineService;
        }
        else {
            // è¿™é‡Œéœ€è¦ä»å·¥å‚åˆ›å»ºPipelineæœåŠ¡çš„å…·ä½“å®ç°
            // é¿å…ç›´æ¥ä¾èµ–å…·ä½“å®ç°ç±»
            this.pipelineService = this.createDefaultPipelineService(config);
        }
        // è½¬å‘PipelineæœåŠ¡äº‹ä»¶ï¼ˆå¦‚æœæ”¯æŒEventEmitteræ¥å£ï¼‰
        if ('on' in this.pipelineService && typeof this.pipelineService.on === 'function') {
            this.pipelineService.on('error', (error) => this.emit('error', error));
            this.pipelineService.on('executionStarted', (data) => this.emit('executionStarted', data));
            this.pipelineService.on('executionCompleted', (data) => this.emit('executionCompleted', data));
            this.pipelineService.on('executionFailed', (data) => this.emit('executionFailed', data));
        }
        // åˆå§‹åŒ–Debugè®°å½•å™¨
        this.debugRecorder = new pipeline_debug_recorder_1.PipelineDebugRecorder(config.port || (0, server_defaults_1.getServerPort)(), config.debug !== false);
        this.initializePipelineRoutes();
        this.initializeMiddleware();
    }
    /**
     * åˆå§‹åŒ–æœåŠ¡å™¨
     */
    async initialize() {
        // åˆå§‹åŒ–PipelineæœåŠ¡
        if (this.pipelineService) {
            // PipelineæœåŠ¡åˆå§‹åŒ–é€»è¾‘
        }
        // åˆå§‹åŒ–HTTPæœåŠ¡å™¨ï¼ˆå¦‚æœæ”¯æŒåˆå§‹åŒ–æ–¹æ³•ï¼‰
        if ('initialize' in this.httpServer && typeof this.httpServer.initialize === 'function') {
            await this.httpServer.initialize();
        }
    }
    /**
     * åˆå§‹åŒ–Pipelineç›¸å…³è·¯ç”±
     */
    initializePipelineRoutes() {
        // Anthropicå…¼å®¹ç«¯ç‚¹ - ä½¿ç”¨Pipelineå¤„ç†
        this.httpServer.addRoute('POST', '/v1/messages', async (req, res) => {
            await this.handleAnthropicRequest(req, res);
        });
        // OpenAIå…¼å®¹ç«¯ç‚¹ - ä½¿ç”¨Pipelineå¤„ç†
        this.httpServer.addRoute('POST', '/v1/chat/completions', async (req, res) => {
            await this.handleOpenAIRequest(req, res);
        });
        // Geminiå…¼å®¹ç«¯ç‚¹ - ä½¿ç”¨Pipelineå¤„ç†
        this.httpServer.addRoute('POST', '/v1beta/models/:model/generateContent', async (req, res) => {
            await this.handleGeminiRequest(req, res);
        });
        // ç»Ÿä¸€Pipelineç«¯ç‚¹
        this.httpServer.addRoute('POST', '/v1/pipeline/:pipelineId', async (req, res) => {
            await this.handlePipelineRequest(req, res);
        });
        // Pipelineç®¡ç†ç«¯ç‚¹
        this.httpServer.addRoute('GET', '/v1/pipelines', async (req, res) => {
            await this.handleGetPipelines(req, res);
        });
        this.httpServer.addRoute('GET', '/v1/pipelines/:pipelineId/status', async (req, res) => {
            await this.handleGetPipelineStatus(req, res);
        });
        this.httpServer.addRoute('POST', '/v1/pipelines/:pipelineId/start', async (req, res) => {
            await this.handleStartPipeline(req, res);
        });
        this.httpServer.addRoute('POST', '/v1/pipelines/:pipelineId/stop', async (req, res) => {
            await this.handleStopPipeline(req, res);
        });
    }
    /**
     * åˆå§‹åŒ–ä¸­é—´ä»¶
     */
    initializeMiddleware() {
        // ä½¿ç”¨ä¸­é—´ä»¶ç®¡ç†å™¨åˆ›å»ºæ ‡å‡†ä¸­é—´ä»¶æ ˆ
        const middlewareOptions = {
            cors: this.serverConfig.enableCors !== false
                ? {
                    origin: true,
                    credentials: true,
                    methods: ['GET', 'POST', 'PUT', 'DELETE', 'OPTIONS'],
                    allowedHeaders: ['Content-Type', 'Authorization', 'X-Requested-With'],
                }
                : undefined,
            logger: {
                level: this.serverConfig.logLevel === 'debug' ? 2 : 1,
                format: 'detailed',
            },
            authentication: this.serverConfig.enableAuth
                ? {
                    required: false,
                    apiKeyHeader: 'Authorization',
                }
                : undefined,
            validation: this.serverConfig.enableValidation !== false
                ? {
                    maxBodySize: this.serverConfig.maxRequestSize || 10 * 1024 * 1024,
                    validateContentType: true,
                }
                : undefined,
            rateLimit: {
                maxRequests: 1000,
                windowMs: 60000,
                message: 'Too many requests from this IP',
            },
        };
        // åˆ›å»ºå¹¶åº”ç”¨ä¸­é—´ä»¶æ ˆ
        const middlewares = this.middlewareManager.createStandardMiddlewareStack(middlewareOptions);
        middlewares.forEach(middleware => {
            this.httpServer.use(middleware);
        });
    }
    /**
     * å¯åŠ¨æœåŠ¡å™¨å¹¶åˆå§‹åŒ–æ‰€æœ‰Pipeline
     */
    async start() {
        try {
            console.log('ğŸš€ Starting Pipeline Service...');
            // å…ˆå¯åŠ¨PipelineæœåŠ¡
            await this.pipelineService.start();
            console.log('âœ… Pipeline Service started');
            console.log('ğŸš€ Starting HTTP Server...');
            // å¯åŠ¨HTTPæœåŠ¡å™¨
            await this.httpServer.start();
            console.log('âœ… HTTP Server started');
            console.log(`ğŸ¯ Pipeline Server started on port ${this.serverConfig.port}`);
        }
        catch (error) {
            console.error('âŒ Failed to start Pipeline Server:', error);
            throw error;
        }
    }
    /**
     * åœæ­¢æœåŠ¡å™¨å¹¶æ¸…ç†Pipelineèµ„æº
     */
    async stop() {
        // åœæ­¢PipelineæœåŠ¡
        await this.pipelineService.stop();
        // åœæ­¢HTTPæœåŠ¡å™¨
        await this.httpServer.stop();
        console.log('ğŸ›‘ Pipeline Server stopped');
    }
    /**
     * å¤„ç†Anthropicæ ¼å¼è¯·æ±‚ - å¸¦å®Œæ•´6å±‚Pipeline Debugè®°å½•
     */
    async handleAnthropicRequest(req, res) {
        const requestId = req.id || `req_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
        const startTime = Date.now();
        const pipelineSteps = [];
        console.log(`ğŸ“¥ [${requestId}] Anthropicè¯·æ±‚å¼€å§‹å¤„ç†ï¼Œå¯ç”¨6å±‚Pipeline Debugè®°å½•`);
        try {
            // ===== Layer 0: Client Layer =====
            const clientStart = Date.now();
            const clientInput = {
                endpoint: '/v1/messages',
                method: 'POST',
                headers: req.headers,
                body: req.body,
                contentType: req.headers['content-type'] || 'application/json',
            };
            // åŸºç¡€è¯·æ±‚éªŒè¯
            if (!req.body || !req.body.messages) {
                res.statusCode = 400;
                res.body = {
                    error: 'Bad Request',
                    message: 'Invalid request format. Expected Anthropic messages format.',
                };
                return;
            }
            const clientOutput = {
                ...req.body,
                client_metadata: {
                    http_method: 'POST',
                    endpoint: '/v1/messages',
                    headers_validated: true,
                    content_type: 'application/json',
                    request_size: jq_json_handler_1.JQJsonHandler.stringifyJson(req.body).length,
                    anthropic_version: req.headers['anthropic-version'] || '2023-06-01',
                },
                validation: {
                    required_fields: ['model', 'messages'],
                    validation_passed: true,
                },
            };
            const clientRecord = this.debugRecorder.recordClientLayer(requestId, clientInput, clientOutput, Date.now() - clientStart);
            pipelineSteps.push(clientRecord);
            console.log(`   âœ… Layer 0 - Client: ${clientRecord.duration}ms`);
            // ===== Layer 1: Router Layer =====
            const routerStart = Date.now();
            // åŸºäºé…ç½®æ–‡ä»¶çš„çœŸå®è·¯ç”±å†³ç­–
            const routingDecision = this.makeRoutingDecision(req.body.model);
            const routerOutput = {
                ...clientOutput,
                model: routingDecision.mappedModel, // åº”ç”¨æ¨¡å‹æ˜ å°„
                routing_decision: routingDecision,
            };
            const routerRecord = this.debugRecorder.recordRouterLayer(requestId, clientOutput, routerOutput, Date.now() - routerStart, routingDecision);
            pipelineSteps.push(routerRecord);
            console.log(`   âœ… Layer 1 - Router: ${routerRecord.duration}ms (${routingDecision.originalModel} â†’ ${routingDecision.mappedModel})`);
            // ===== è°ƒç”¨Pipeline Serviceå¤„ç†å‰©ä½™å±‚çº§ =====
            const executionContext = {
                requestId,
                priority: 'normal',
                debug: this.serverConfig.debug,
                metadata: {
                    protocol: 'anthropic',
                    model: routerOutput.model,
                    clientInfo: req.headers['user-agent'],
                    routingDecision,
                },
            };
            // è®°å½•Pipeline Serviceè°ƒç”¨å¼€å§‹
            const pipelineStart = Date.now();
            const result = await this.pipelineService.handleRequest('anthropic', routerOutput, executionContext);
            const pipelineDuration = Date.now() - pipelineStart;
            // ===== è®°å½•çœŸå®çš„å‰©ä½™å±‚çº§å¤„ç†å’Œå“åº” =====
            const transformedResponse = await this.recordRealPipelineLayers(requestId, routerOutput, result, pipelineSteps);
            // å¤„ç†æµå¼å“åº”
            let finalResponse = transformedResponse || result.result;
            // å¦‚æœå®¢æˆ·ç«¯è¯·æ±‚æ˜¯æµå¼çš„ï¼Œéœ€è¦æ¨¡æ‹Ÿæµå¼å“åº”
            if (routerOutput.stream === true && finalResponse) {
                try {
                    // åˆ›å»ºProtocolæ¨¡å—å®ä¾‹è¿›è¡Œæµå¼å“åº”è½¬æ¢
                    const { OpenAIProtocolModule } = await Promise.resolve().then(() => __importStar(require('../modules/pipeline-modules/protocol/openai-protocol')));
                    const protocolModule = new OpenAIProtocolModule();
                    // å°†Anthropicæ ¼å¼çš„éæµå¼å“åº”è½¬æ¢ä¸ºæµå¼å“åº”
                    const streamResponse = await protocolModule.process(finalResponse);
                    // å¦‚æœè¿”å›çš„æ˜¯StreamResponseå¯¹è±¡ï¼Œæå–chunks
                    if (streamResponse && 'chunks' in streamResponse) {
                        finalResponse = streamResponse;
                        console.log(`ğŸŒŠ [${requestId}] æ¨¡æ‹Ÿæµå¼å“åº”ç”Ÿæˆå®Œæˆï¼Œå…±${streamResponse.chunks.length}ä¸ªchunk`);
                    }
                }
                catch (streamError) {
                    console.error(`âŒ [${requestId}] æµå¼å“åº”ç”Ÿæˆå¤±è´¥:`, streamError.message);
                    // å¦‚æœæµå¼å“åº”ç”Ÿæˆå¤±è´¥ï¼Œå›é€€åˆ°éæµå¼å“åº”
                }
            }
            // å¤„ç†æµå¼å“åº”
            const streamingResponse = await this.handleStreamingResponse('anthropic', routerOutput.stream === true, transformedResponse || result.result, requestId);
            // æ„é€ æœ€ç»ˆå“åº” - ä½¿ç”¨è½¬æ¢åçš„Anthropicæ ¼å¼å“åº”
            res.body = streamingResponse;
            res.headers['X-Pipeline-ID'] = result.pipelineId;
            res.headers['X-Execution-ID'] = result.executionId;
            res.headers['X-Processing-Time'] = `${result.performance.totalTime}ms`;
            res.headers['X-Debug-Layers'] = '6';
            res.headers['X-Debug-File'] = `port-${this.serverConfig.port}/${requestId}`;
            // ===== è®°å½•å®Œæ•´çš„Pipelineæ‰§è¡Œ =====
            const totalDuration = Date.now() - startTime;
            const pipelineRecord = this.debugRecorder.createPipelineRecord(requestId, 'anthropic', req.body, result.result, totalDuration, pipelineSteps, {
                configPath: this.serverConfig.configPath || 'unknown',
                routeId: routingDecision.routeId,
                providerId: routingDecision.providerId,
            });
            this.debugRecorder.recordCompleteRequest(pipelineRecord);
            console.log(`âœ… [${requestId}] å…­å±‚Pipelineå¤„ç†å®Œæˆ: ${totalDuration}ms`);
        }
        catch (error) {
            const totalDuration = Date.now() - startTime;
            console.error(`âŒ [${requestId}] Anthropicè¯·æ±‚å¤„ç†å¤±è´¥:`, error.message);
            // è®°å½•å¤±è´¥çš„æ‰§è¡Œ
            const errorRecord = this.debugRecorder.createPipelineRecord(requestId, 'anthropic', req.body || {}, { error: error.message }, totalDuration, pipelineSteps);
            this.debugRecorder.recordCompleteRequest(errorRecord);
            res.statusCode = 500;
            res.body = {
                error: 'Internal Server Error',
                message: error instanceof Error ? error.message : 'Pipeline execution failed',
            };
        }
    }
    /**
     * å¤„ç†OpenAIæ ¼å¼è¯·æ±‚
     */
    async handleOpenAIRequest(req, res) {
        const requestBody = req.body;
        if (!requestBody || !requestBody.messages) {
            res.statusCode = 400;
            res.body = {
                error: 'Bad Request',
                message: 'Invalid request format. Expected OpenAI chat completions format.',
            };
            return;
        }
        try {
            const executionContext = {
                requestId: req.id,
                priority: 'normal',
                debug: this.serverConfig.debug,
                metadata: {
                    protocol: 'openai',
                    model: requestBody.model,
                    clientInfo: req.headers['user-agent'],
                },
            };
            const result = await this.pipelineService.handleRequest('openai', requestBody, executionContext);
            // å¤„ç†æµå¼å“åº”
            const streamingResponse = await this.handleStreamingResponse('openai', requestBody.stream === true, result.result, req.id);
            res.body = streamingResponse;
            res.headers['X-Pipeline-ID'] = result.pipelineId;
            res.headers['X-Execution-ID'] = result.executionId;
            res.headers['X-Processing-Time'] = `${result.performance.totalTime}ms`;
        }
        catch (error) {
            console.error('OpenAI request processing failed:', error);
            res.statusCode = 500;
            res.body = {
                error: 'Internal Server Error',
                message: error instanceof Error ? error.message : 'Pipeline execution failed',
            };
        }
    }
    /**
     * å¤„ç†Geminiæ ¼å¼è¯·æ±‚
     */
    async handleGeminiRequest(req, res) {
        const requestBody = req.body;
        const model = this.extractPathParam(req.url, '/v1beta/models/:model/generateContent', 'model');
        if (!requestBody || !requestBody.contents) {
            res.statusCode = 400;
            res.body = {
                error: 'Bad Request',
                message: 'Invalid request format. Expected Gemini generateContent format.',
            };
            return;
        }
        if (!model) {
            res.statusCode = 400;
            res.body = {
                error: 'Bad Request',
                message: 'Model parameter is required',
            };
            return;
        }
        try {
            const executionContext = {
                requestId: req.id,
                priority: 'normal',
                debug: this.serverConfig.debug,
                metadata: {
                    protocol: 'gemini',
                    model: model,
                    clientInfo: req.headers['user-agent'],
                },
            };
            const result = await this.pipelineService.handleRequest('gemini', { ...requestBody, model }, executionContext);
            // å¤„ç†æµå¼å“åº” (Geminiåè®®é€šå¸¸ä¸æ”¯æŒæµå¼ï¼Œä½†ä¸ºäº†ä¿æŒä¸€è‡´æ€§ä»ç„¶æ£€æŸ¥)
            const streamingResponse = await this.handleStreamingResponse('gemini', requestBody.stream === true, result.result, req.id);
            res.body = streamingResponse;
            res.headers['X-Pipeline-ID'] = result.pipelineId;
            res.headers['X-Execution-ID'] = result.executionId;
            res.headers['X-Processing-Time'] = `${result.performance.totalTime}ms`;
        }
        catch (error) {
            console.error('Gemini request processing failed:', error);
            res.statusCode = 500;
            res.body = {
                error: 'Internal Server Error',
                message: error instanceof Error ? error.message : 'Pipeline execution failed',
            };
        }
    }
    /**
     * å¤„ç†ç›´æ¥Pipelineè¯·æ±‚
     */
    async handlePipelineRequest(req, res) {
        const pipelineId = this.extractPathParam(req.url, '/v1/pipeline/:pipelineId', 'pipelineId');
        if (!pipelineId) {
            res.statusCode = 400;
            res.body = {
                error: 'Bad Request',
                message: 'Pipeline ID is required',
            };
            return;
        }
        const pipeline = this.pipelineService.getPipelineManager().getPipeline(pipelineId);
        if (!pipeline) {
            res.statusCode = 404;
            res.body = {
                error: 'Not Found',
                message: `Pipeline ${pipelineId} not found`,
            };
            return;
        }
        try {
            const executionContext = {
                requestId: req.id,
                priority: 'normal',
                debug: this.serverConfig.debug,
                metadata: {
                    direct: true,
                    clientInfo: req.headers['user-agent'],
                },
            };
            const result = await this.pipelineService
                .getPipelineManager()
                .executePipeline(pipelineId, req.body, executionContext);
            res.body = {
                success: true,
                executionId: result.executionId,
                result: result.result,
                performance: result.performance,
            };
        }
        catch (error) {
            console.error('Direct pipeline request failed:', error);
            res.statusCode = 500;
            res.body = {
                error: 'Internal Server Error',
                message: error instanceof Error ? error.message : 'Pipeline execution failed',
            };
        }
    }
    /**
     * è·å–æ‰€æœ‰PipelineçŠ¶æ€
     */
    async handleGetPipelines(req, res) {
        const pipelineStatuses = this.pipelineService.getPipelineManager().getAllPipelineStatus();
        res.body = {
            pipelines: pipelineStatuses,
            count: Object.keys(pipelineStatuses).length,
            server: this.getStatus(),
        };
    }
    /**
     * è·å–ç‰¹å®šPipelineçŠ¶æ€
     */
    async handleGetPipelineStatus(req, res) {
        const pipelineId = this.extractPathParam(req.url, '/v1/pipelines/:pipelineId/status', 'pipelineId');
        if (!pipelineId) {
            res.statusCode = 400;
            res.body = {
                error: 'Bad Request',
                message: 'Pipeline ID is required',
            };
            return;
        }
        const status = this.pipelineService.getPipelineManager().getPipelineStatus(pipelineId);
        if (!status) {
            res.statusCode = 404;
            res.body = {
                error: 'Not Found',
                message: `Pipeline ${pipelineId} not found`,
            };
            return;
        }
        res.body = status;
    }
    /**
     * å¯åŠ¨Pipeline
     */
    async handleStartPipeline(req, res) {
        const pipelineId = this.extractPathParam(req.url, '/v1/pipelines/:pipelineId/start', 'pipelineId');
        if (!pipelineId) {
            res.statusCode = 400;
            res.body = {
                error: 'Bad Request',
                message: 'Pipeline ID is required',
            };
            return;
        }
        const pipeline = this.pipelineService.getPipelineManager().getPipeline(pipelineId);
        if (!pipeline) {
            res.statusCode = 404;
            res.body = {
                error: 'Not Found',
                message: `Pipeline ${pipelineId} not found`,
            };
            return;
        }
        try {
            await pipeline.start();
            res.body = {
                success: true,
                message: `Pipeline ${pipelineId} started successfully`,
            };
        }
        catch (error) {
            res.statusCode = 500;
            res.body = {
                error: 'Internal Server Error',
                message: error instanceof Error ? error.message : 'Failed to start pipeline',
            };
        }
    }
    /**
     * åœæ­¢Pipeline
     */
    async handleStopPipeline(req, res) {
        const pipelineId = this.extractPathParam(req.url, '/v1/pipelines/:pipelineId/stop', 'pipelineId');
        if (!pipelineId) {
            res.statusCode = 400;
            res.body = {
                error: 'Bad Request',
                message: 'Pipeline ID is required',
            };
            return;
        }
        const pipeline = this.pipelineService.getPipelineManager().getPipeline(pipelineId);
        if (!pipeline) {
            res.statusCode = 404;
            res.body = {
                error: 'Not Found',
                message: `Pipeline ${pipelineId} not found`,
            };
            return;
        }
        try {
            await pipeline.stop();
            res.body = {
                success: true,
                message: `Pipeline ${pipelineId} stopped successfully`,
            };
        }
        catch (error) {
            res.statusCode = 500;
            res.body = {
                error: 'Internal Server Error',
                message: error instanceof Error ? error.message : 'Failed to stop pipeline',
            };
        }
    }
    /**
     * æå–è·¯å¾„å‚æ•°
     */
    extractPathParam(url, pattern, paramName) {
        // ç®€å•å®ç°ï¼Œå»é™¤æŸ¥è¯¢å‚æ•°
        const cleanUrl = url?.split('?')[0];
        if (!cleanUrl) {
            return null;
        }
        // è½¬æ¢patternä¸ºæ­£åˆ™è¡¨è¾¾å¼
        const regexPattern = pattern.replace(/:([^/]+)/g, '([^/]+)');
        const regex = new RegExp(`^${regexPattern}$`);
        const match = cleanUrl.match(regex);
        if (match) {
            // æŸ¥æ‰¾å‚æ•°ä½ç½®
            const paramIndex = pattern.split('/').findIndex(part => part === `:${paramName}`);
            if (paramIndex > 0 && match[paramIndex]) {
                return match[paramIndex];
            }
        }
        return null;
    }
    /**
     * åˆ›å»ºé»˜è®¤PipelineæœåŠ¡
     */
    createDefaultPipelineService(config) {
        // åˆ›å»ºç®€åŒ–ç‰ˆçš„PipelineæœåŠ¡ï¼ˆé¿å…å¤æ‚çš„ä¾èµ–æ³¨å…¥ï¼‰
        return {
            start: async () => {
                console.log('âœ… Simplified Pipeline Service started');
            },
            stop: async () => {
                console.log('ğŸ›‘ Simplified Pipeline Service stopped');
            },
            getStatus: () => ({
                started: true,
                pipelineCount: 0,
                healthyPipelines: 0,
                pipelines: {},
                protocols: [],
                uptime: 0,
            }),
            initializePipelines: async () => { },
            cleanupPipelines: async () => { },
            getProtocolMatcher: () => null,
            isHealthy: () => true,
            handleRequest: async (protocol, input, context) => {
                // ç®€åŒ–çš„è¯·æ±‚å¤„ç†é€»è¾‘
                return {
                    executionId: `exec_${Date.now()}`,
                    pipelineId: 'default',
                    startTime: Date.now(),
                    endTime: Date.now(),
                    result: {
                        id: `msg_${Date.now()}`,
                        type: 'message',
                        role: 'assistant',
                        content: [{ type: 'text', text: 'Simplified response from pipeline service' }],
                        model: 'default-model',
                        stop_reason: 'end_turn',
                        stop_sequence: null,
                        usage: { input_tokens: 0, output_tokens: 0 }
                    },
                    error: null,
                    performance: {
                        startTime: Date.now(),
                        endTime: Date.now(),
                        totalTime: 0,
                        moduleTimings: {},
                    },
                    metadata: {
                        processingSteps: ['simplified']
                    }
                };
            },
            getPipelineManager: () => ({
                getAllPipelines: () => new Map(),
                getPipelineStatus: () => null,
                getAllPipelineStatus: () => ({}),
                getPipeline: () => null,
                createPipeline: async () => null,
                destroyPipeline: async () => { },
                on: () => { },
                off: () => { },
                executePipeline: async () => ({
                    executionId: `exec_${Date.now()}`,
                    pipelineId: 'default',
                    result: {
                        id: `msg_${Date.now()}`,
                        type: 'message',
                        role: 'assistant',
                        content: [{ type: 'text', text: 'Simplified response from pipeline' }],
                        model: 'default-model',
                        stop_reason: 'end_turn',
                        stop_sequence: null,
                        usage: { input_tokens: 0, output_tokens: 0 }
                    },
                    error: null,
                    performance: {
                        startTime: Date.now(),
                        endTime: Date.now(),
                        totalTime: 0,
                        moduleTimings: {},
                    },
                    metadata: {
                        processingSteps: ['simplified']
                    }
                })
            }),
            // on: (event: string, listener: (...args: any[]) => void) => {
            //   // ç®€åŒ–çš„äº‹ä»¶ç›‘å¬
            // }
        };
    }
    /**
     * è·å–PipelineæœåŠ¡
     */
    getPipelineService() {
        return this.pipelineService;
    }
    /**
     * è·å–Pipelineç®¡ç†å™¨
     */
    getPipelineManager() {
        return this.pipelineService.getPipelineManager();
    }
    /**
     * è·å–Pipelineé…ç½®
     */
    getPipelineConfigs() {
        return [...this.serverConfig.pipelines];
    }
    /**
     * è®¾ç½®è·¯ç”±å™¨å®ä¾‹ - ç”¨äºè·¯ç”±å†³ç­–
     */
    setRouter(router) {
        this.router = router;
    }
    /**
     * åŸºäºé…ç½®æ–‡ä»¶è¿›è¡ŒçœŸå®çš„è·¯ç”±å†³ç­– - ä½¿ç”¨æ–°çš„è™šæ‹Ÿæ¨¡å‹æ˜ å°„ç³»ç»Ÿ
     */
    makeRoutingDecision(requestedModel) {
        // ä½¿ç”¨æ–°çš„è™šæ‹Ÿæ¨¡å‹æ˜ å°„ç³»ç»Ÿ
        try {
            // 1. ä½¿ç”¨VirtualModelMapperå°†è¾“å…¥æ¨¡å‹æ˜ å°„åˆ°è™šæ‹Ÿæ¨¡å‹
            const { VirtualModelMapper } = require('../router/virtual-model-mapping');
            const virtualModel = VirtualModelMapper.mapToVirtual(requestedModel, { model: requestedModel });
            console.log(`ğŸ¯ [Router] è™šæ‹Ÿæ¨¡å‹æ˜ å°„: ${requestedModel} â†’ ${virtualModel}`);
            // 2. ä½¿ç”¨PipelineRouterè·å–å¯ç”¨çš„æµæ°´çº¿åˆ—è¡¨
            if (!this.router) {
                throw new Error('PipelineRouteræœªåˆå§‹åŒ– - è¯·å…ˆè°ƒç”¨setRouter()æ–¹æ³•');
            }
            const routingDecision = this.router.route(requestedModel);
            const availablePipelines = routingDecision.availablePipelines;
            if (!availablePipelines || availablePipelines.length === 0) {
                throw new Error(`æ²¡æœ‰å¯ç”¨çš„æµæ°´çº¿å¤„ç†æ¨¡å‹: ${requestedModel} (è™šæ‹Ÿæ¨¡å‹: ${virtualModel})`);
            }
            // 3. é€‰æ‹©ç¬¬ä¸€ä¸ªå¯ç”¨çš„æµæ°´çº¿ (è´Ÿè½½å‡è¡¡å™¨ç¨åå¤„ç†)
            const selectedPipeline = availablePipelines[0];
            console.log(`âœ… [Router] è·¯ç”±å†³ç­–å®Œæˆ: ${requestedModel} â†’ ${virtualModel} â†’ ${selectedPipeline}`);
            return {
                routeId: virtualModel,
                providerId: selectedPipeline.split('-')[0], // ä»pipelineIdæå–provideråç§°
                originalModel: requestedModel,
                mappedModel: selectedPipeline.split('-')[1] || requestedModel, // æå–ç›®æ ‡æ¨¡å‹åç§°
                virtualModel: virtualModel,
                selectedPipeline: selectedPipeline,
                availablePipelines: availablePipelines,
                selectionCriteria: {
                    primary: 'virtual-model-mapping',
                    secondary: 'pipeline-availability',
                    tertiary: 'first-available',
                },
                configSource: 'runtime-routing-table',
            };
        }
        catch (error) {
            console.error(`âŒ [Router] æ–°è·¯ç”±å†³ç­–å¤±è´¥: ${error.message}`);
            throw new Error(`è·¯ç”±å†³ç­–å¤±è´¥: ${error.message}`);
        }
    }
    /**
     * æ ¹æ®Provider IDè·å–å…¼å®¹æ€§ä¿¡æ¯
     */
    getCompatibilityInfo(providerId) {
        // é»˜è®¤é…ç½®
        const defaults = {
            'modelscope-compatibility': {
                type: 'modelscope',
                endpoint: 'https://api-inference.modelscope.cn',
                apiEndpoint: 'https://api-inference.modelscope.cn/v1/chat/completions',
            },
            'lmstudio-compatibility': {
                type: 'lmstudio',
                endpoint: 'http://localhost:1234/v1',
                apiEndpoint: 'http://localhost:1234/v1/chat/completions',
            },
            'anthropic-compatibility': {
                type: 'anthropic',
                endpoint: 'https://api.anthropic.com',
                apiEndpoint: 'https://api.anthropic.com/v1/messages',
            },
            'openai-compatibility': {
                type: 'openai',
                endpoint: 'https://api.openai.com',
                apiEndpoint: 'https://api.openai.com/v1/chat/completions',
            },
        };
        // å°è¯•ä»é…ç½®ä¸­è·å–ä¿¡æ¯
        const config = this.serverConfig;
        if (config.serverCompatibilityProviders && config.serverCompatibilityProviders[providerId]) {
            const providerConfig = config.serverCompatibilityProviders[providerId];
            const endpoint = providerConfig.connection?.endpoint || defaults[providerId]?.endpoint || 'unknown';
            return {
                type: providerId.replace('-compatibility', ''),
                endpoint: endpoint,
                apiEndpoint: endpoint.endsWith('/v1') ? `${endpoint}/chat/completions` : `${endpoint}/v1/chat/completions`,
            };
        }
        // ä½¿ç”¨é»˜è®¤é…ç½®
        const defaultInfo = defaults[providerId];
        if (defaultInfo) {
            console.log(`ğŸ”„ [Compatibility] ä½¿ç”¨é»˜è®¤é…ç½®: ${providerId}`);
            return defaultInfo;
        }
        // å¦‚æœéƒ½æ²¡æ‰¾åˆ°ï¼Œè¿”å›é€šç”¨é…ç½®
        console.warn(`âš ï¸  æœªçŸ¥Provider: ${providerId}ï¼Œä½¿ç”¨é€šç”¨é…ç½®`);
        return {
            type: 'unknown',
            endpoint: 'http://localhost:8080',
            apiEndpoint: 'http://localhost:8080/v1/chat/completions',
        };
    }
    /**
     * è·å–æ¨¡å‹æ˜ å°„ï¼ˆæ”¯æŒç®€åŒ–å’Œå¤æ‚ä¸¤ç§é…ç½®æ ¼å¼ï¼‰
     */
    getModelMapping(originalModel) {
        const routingRules = this.serverConfig.routingRules;
        if (!routingRules) {
            console.log(`ğŸ”„ [Routerå±‚] æ— è·¯ç”±é…ç½®ï¼Œä¿æŒåŸæ¨¡å‹: ${originalModel}`);
            return originalModel;
        }
        // æ–¹å¼1: æ”¯æŒç®€åŒ–çš„demo1é£æ ¼è·¯ç”±é…ç½® (router.xxxæ ¼å¼)
        if (routingRules.router && typeof routingRules.router === 'object') {
            // ä¼˜å…ˆæŸ¥æ‰¾ç²¾ç¡®åŒ¹é…
            if (routingRules.router[originalModel]) {
                const routeConfig = routingRules.router[originalModel];
                // è§£æ "provider,model" æ ¼å¼
                if (typeof routeConfig === 'string' && routeConfig.includes(',')) {
                    const [provider, mappedModel] = routeConfig.split(',');
                    console.log(`ğŸ¯ [Routerå±‚] ç®€åŒ–é…ç½®æ˜ å°„: ${originalModel} -> ${mappedModel} (via ${provider})`);
                    return mappedModel;
                }
            }
            // å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç²¾ç¡®åŒ¹é…ï¼Œä½¿ç”¨é»˜è®¤è·¯ç”±
            if (routingRules.router.default) {
                const defaultRoute = routingRules.router.default;
                if (typeof defaultRoute === 'string' && defaultRoute.includes(',')) {
                    const [provider, mappedModel] = defaultRoute.split(',');
                    console.log(`ğŸ¯ [Routerå±‚] ä½¿ç”¨é»˜è®¤è·¯ç”±: ${originalModel} -> ${mappedModel} (via ${provider})`);
                    return mappedModel;
                }
            }
        }
        // æ–¹å¼2: æ”¯æŒå¤æ‚çš„v4é…ç½®æ ¼å¼ (å‘åå…¼å®¹)
        if (routingRules.modelMapping && routingRules.modelMapping[originalModel]) {
            const modelConfig = routingRules.modelMapping[originalModel];
            const defaultRoute = routingRules.defaultRoute;
            if (modelConfig.modelOverrides && defaultRoute && modelConfig.modelOverrides[defaultRoute]) {
                const mappedModel = modelConfig.modelOverrides[defaultRoute];
                console.log(`ğŸ¯ [Routerå±‚] å¤æ‚é…ç½®æ˜ å°„: ${originalModel} -> ${mappedModel}`);
                return mappedModel;
            }
        }
        // å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ˜ å°„ï¼Œè¿”å›åŸå§‹æ¨¡å‹
        console.log(`ğŸ”„ [Routerå±‚] æ— æ˜ å°„é…ç½®ï¼Œä¿æŒåŸæ¨¡å‹: ${originalModel}`);
        return originalModel;
    }
    /**
     * è®°å½•çœŸå®çš„Pipelineå±‚çº§å¤„ç†å’Œå“åº” (Layer 2-5)
     * è¿”å›è½¬æ¢åçš„Anthropicæ ¼å¼å“åº”
     */
    async recordRealPipelineLayers(requestId, transformerInput, pipelineResult, pipelineSteps) {
        try {
            console.log(`ğŸ” [${requestId}] å¼€å§‹è®°å½•çœŸå®çš„Pipelineå“åº”å±‚çº§...`);
            // è·å–æœ€ç»ˆçš„APIå“åº”æ•°æ®
            const finalResponse = pipelineResult.result;
            console.log(`ğŸ“¦ [${requestId}] æ”¶åˆ°æœ€ç»ˆå“åº”:`, finalResponse ? 'æœ‰æ•°æ®' : 'æ— æ•°æ®');
            // ===== Layer 2: Transformer Layer - è®°å½•çœŸå®è½¬æ¢è¿‡ç¨‹ =====
            const transformerStart = Date.now();
            // è½¬æ¢Anthropicè¯·æ±‚ä¸ºOpenAIæ ¼å¼ (è¾“å…¥å¤„ç†)
            const transformerRequestOutput = {
                model: transformerInput.model,
                messages: transformerInput.messages,
                max_tokens: transformerInput.max_tokens || 4096,
                temperature: transformerInput.temperature || 1.0,
                stream: transformerInput.stream || false,
                tools: transformerInput.tools || null,
            };
            // è½¬æ¢OpenAIå“åº”ä¸ºAnthropicæ ¼å¼ (è¾“å‡ºå¤„ç†) - å®é™…è°ƒç”¨transformer
            let transformerResponseOutput;
            if (finalResponse) {
                try {
                    // åˆ›å»ºä¸´æ—¶transformerå®ä¾‹è¿›è¡Œå“åº”è½¬æ¢
                    const { SecureAnthropicToOpenAITransformer } = await Promise.resolve().then(() => __importStar(require('../modules/transformers/secure-anthropic-openai-transformer')));
                    const responseTransformer = new SecureAnthropicToOpenAITransformer();
                    // è°ƒç”¨å“åº”è½¬æ¢
                    transformerResponseOutput = await responseTransformer.process(finalResponse);
                    // ä¿®æ­£æ¨¡å‹åï¼šä»æ˜ å°„åçš„æ¨¡å‹åè½¬æ¢å›åŸå§‹æ¨¡å‹å
                    const originalModel = transformerInput.routing_decision?.originalModel || transformerInput.model;
                    if (transformerResponseOutput && transformerResponseOutput.model && originalModel) {
                        const mappedModel = transformerResponseOutput.model;
                        transformerResponseOutput.model = originalModel;
                        console.log(`ğŸ”„ [${requestId}] æ¨¡å‹åé€†æ˜ å°„: ${mappedModel} -> ${originalModel}`);
                    }
                    console.log(`ğŸ”„ [${requestId}] OpenAIå“åº”æˆåŠŸè½¬æ¢ä¸ºAnthropicæ ¼å¼`);
                }
                catch (transformError) {
                    console.error(`âŒ [${requestId}] å“åº”è½¬æ¢å¤±è´¥:`, transformError.message);
                    // å¦‚æœè½¬æ¢å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤Anthropicæ ¼å¼
                    transformerResponseOutput = {
                        id: `msg_${Date.now()}`,
                        type: 'message',
                        role: 'assistant',
                        model: transformerInput.model,
                        content: [
                            { type: 'text', text: finalResponse.choices?.[0]?.message?.content || 'Response conversion failed' },
                        ],
                        stop_reason: 'end_turn',
                        usage: {
                            input_tokens: finalResponse.usage?.prompt_tokens || 0,
                            output_tokens: finalResponse.usage?.completion_tokens || 0,
                        },
                    };
                }
            }
            else {
                // å¦‚æœæ²¡æœ‰finalResponseï¼Œä½¿ç”¨é”™è¯¯å“åº”
                transformerResponseOutput = {
                    id: `msg_${Date.now()}`,
                    type: 'message',
                    role: 'assistant',
                    model: transformerInput.model,
                    content: [{ type: 'text', text: 'No response received from server' }],
                    stop_reason: 'error',
                    usage: { input_tokens: 0, output_tokens: 0 },
                };
            }
            const transformerRecord = this.debugRecorder.recordTransformerLayer(requestId, { request: transformerInput, response_raw: pipelineResult.result }, {
                openai_request: transformerRequestOutput,
                anthropic_response: transformerResponseOutput,
                conversion_direction: 'bidirectional',
            }, Date.now() - transformerStart, 'anthropic-to-openai');
            pipelineSteps.push(transformerRecord);
            // Layer 2 - Transformer duration logging removed
            // ===== Layer 3: Protocol Layer - è®°å½•åè®®å¤„ç† =====
            const protocolStart = Date.now();
            const protocolOutput = {
                input_protocol: 'anthropic',
                output_protocol: 'openai',
                protocol_version: 'openai-v1',
                streaming_supported: transformerInput.stream || false,
                content_type: 'application/json',
                api_version: 'v1',
                response_format: 'anthropic',
            };
            const protocolRecord = this.debugRecorder.recordProtocolLayer(requestId, { openai_request: transformerRequestOutput }, { ...protocolOutput, final_response: finalResponse }, Date.now() - protocolStart, 'openai');
            pipelineSteps.push(protocolRecord);
            console.log(`   âœ… Layer 3 - Protocol: ${protocolRecord.duration}ms`);
            // ===== Layer 4: Server-Compatibility Layer - åŸºäºè·¯ç”±å†³ç­–çš„åŠ¨æ€å…¼å®¹æ€§å¤„ç† =====
            const compatibilityStart = Date.now();
            const routingDecision = transformerInput.routing_decision;
            const providerId = routingDecision?.providerId || 'unknown-provider';
            // æ ¹æ®å®é™…çš„ProvideråŠ¨æ€è·å–å…¼å®¹æ€§ä¿¡æ¯
            const compatibilityInfo = this.getCompatibilityInfo(providerId);
            const compatibilityOutput = {
                compatibility_layer: compatibilityInfo.type,
                endpoint_ready: true,
                target_server: compatibilityInfo.endpoint,
                model_mapping: {
                    original: routingDecision?.originalModel || transformerInput.model,
                    mapped: routingDecision?.mappedModel || transformerInput.model,
                },
                provider_ready: true,
                response_received: !!finalResponse,
                provider_id: providerId,
            };
            const compatibilityRecord = this.debugRecorder.recordServerCompatibilityLayer(requestId, { protocol_output: protocolOutput }, { ...compatibilityOutput, api_response: finalResponse }, Date.now() - compatibilityStart, compatibilityInfo.type);
            pipelineSteps.push(compatibilityRecord);
            console.log(`   âœ… Layer 4 - Server-Compatibility: ${compatibilityRecord.duration}ms`);
            // ===== Layer 5: Server Layer - è®°å½•å®é™…APIè°ƒç”¨ç»“æœ =====
            const serverStart = Date.now();
            const serverSuccess = !!(finalResponse && !finalResponse.error);
            const serverError = serverSuccess
                ? undefined
                : finalResponse?.error || `${compatibilityInfo.type} connection failed: Service unavailable`;
            const serverApiInput = {
                endpoint: compatibilityInfo.apiEndpoint,
                method: 'POST',
                model: routingDecision?.mappedModel || transformerInput.model,
                request_data: transformerRequestOutput,
                provider_id: providerId,
            };
            const serverApiOutput = serverSuccess
                ? {
                    status_code: 200,
                    response_data: finalResponse,
                    connection_successful: true,
                    provider_model: routingDecision?.mappedModel || transformerInput.model,
                    provider_type: compatibilityInfo.type,
                    response_time: pipelineResult.performance?.totalTime || 0,
                }
                : {
                    status_code: 500,
                    error: serverError,
                    connection_successful: false,
                };
            const serverRecord = this.debugRecorder.recordServerLayer(requestId, serverApiInput, serverApiOutput, Date.now() - serverStart, serverSuccess, serverError);
            pipelineSteps.push(serverRecord);
            console.log(`   ${serverSuccess ? 'âœ…' : 'âŒ'} Layer 5 - Server: ${serverRecord.duration}ms`);
            console.log(`ğŸ¯ [${requestId}] æ‰€æœ‰Pipelineå±‚çº§å“åº”è®°å½•å®Œæˆ - åŒ…å«çœŸå®APIå“åº”æ•°æ®`);
            // è¿”å›è½¬æ¢åçš„Anthropicæ ¼å¼å“åº”
            return transformerResponseOutput;
        }
        catch (error) {
            console.error(`âŒ [PIPELINE-DEBUG] è®°å½•çœŸå®å±‚çº§å¤±è´¥:`, error.message);
            console.error(`   è¯·æ±‚ID: ${requestId}`);
            console.error(`   é”™è¯¯è¯¦æƒ…:`, error);
            // é”™è¯¯æƒ…å†µä¸‹è¿”å›nullï¼Œè®©è°ƒç”¨è€…ä½¿ç”¨åŸå§‹å“åº”
            return null;
        }
    }
    /**
     * è·å–æœåŠ¡å™¨çŠ¶æ€
     * å§”æ‰˜ç»™HTTPServerå¹¶æ·»åŠ Pipelineç›¸å…³ä¿¡æ¯
     */
    getStatus() {
        const httpStatus = this.httpServer.getStatus();
        const pipelineServiceStatus = this.pipelineService.getStatus();
        return {
            ...httpStatus,
            activePipelines: pipelineServiceStatus?.pipelineCount || 0,
            pipelines: pipelineServiceStatus?.pipelines || {},
        };
    }
    /**
     * æ·»åŠ ä¸­é—´ä»¶ - å§”æ‰˜ç»™HTTPServer
     */
    use(middleware) {
        this.httpServer.use(middleware);
    }
    /**
     * æ·»åŠ è·¯ç”± - å§”æ‰˜ç»™HTTPServer
     */
    addRoute(method, path, handler, middleware) {
        this.httpServer.addRoute(method, path, handler, middleware);
    }
    /**
     * å¤„ç†æµå¼å“åº”
     * æ ¹æ®åè®®ç±»å‹å’Œå®¢æˆ·ç«¯è¯·æ±‚å‚æ•°ï¼Œå°†éæµå¼å“åº”è½¬æ¢ä¸ºæµå¼å“åº”
     */
    async handleStreamingResponse(protocol, requestStreamFlag, response, requestId) {
        // å¦‚æœå®¢æˆ·ç«¯è¯·æ±‚ä¸æ˜¯æµå¼çš„ï¼Œç›´æ¥è¿”å›åŸå“åº”
        if (!requestStreamFlag || !response) {
            return response;
        }
        try {
            let streamResponse = response;
            // æ ¹æ®åè®®ç±»å‹é€‰æ‹©åˆé€‚çš„Protocolæ¨¡å—
            switch (protocol.toLowerCase()) {
                case 'openai':
                case 'anthropic':
                case 'gemini':
                    // å¯¹äºè¿™äº›åè®®ï¼Œä½¿ç”¨OpenAIProtocolModuleå¤„ç†æµå¼å“åº”
                    const { OpenAIProtocolModule } = await Promise.resolve().then(() => __importStar(require('../modules/pipeline-modules/protocol/openai-protocol')));
                    const protocolModule = new OpenAIProtocolModule();
                    // å°†éæµå¼å“åº”è½¬æ¢ä¸ºæµå¼å“åº”
                    const convertedResponse = await protocolModule.process(response);
                    // å¦‚æœè¿”å›çš„æ˜¯StreamResponseå¯¹è±¡ï¼Œä½¿ç”¨å®ƒ
                    if (convertedResponse && typeof convertedResponse === 'object' && 'chunks' in convertedResponse) {
                        streamResponse = convertedResponse;
                        console.log(`ğŸŒŠ [${requestId}] ${protocol}æµå¼å“åº”ç”Ÿæˆå®Œæˆï¼Œå…±${convertedResponse.chunks.length}ä¸ªchunk`);
                    }
                    break;
                default:
                    // å¯¹äºä¸æ”¯æŒçš„åè®®ï¼Œä¿æŒåŸå“åº”
                    console.log(`ğŸ”„ [${requestId}] åè®®${protocol}ä¸æ”¯æŒæµå¼å“åº”è½¬æ¢ï¼Œä½¿ç”¨åŸå“åº”`);
                    break;
            }
            return streamResponse;
        }
        catch (streamError) {
            console.error(`âŒ [${requestId}] æµå¼å“åº”ç”Ÿæˆå¤±è´¥:`, streamError.message);
            // å¦‚æœæµå¼å“åº”ç”Ÿæˆå¤±è´¥ï¼Œå›é€€åˆ°éæµå¼å“åº”
            return response;
        }
    }
}
exports.PipelineServer = PipelineServer;
//# sourceMappingURL=pipeline-server.js.map