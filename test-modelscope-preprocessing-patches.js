#!/usr/bin/env node

/**
 * æµ‹è¯•ModelScopeé¢„å¤„ç†è¡¥ä¸å¯¹GLM-4.5å’ŒQwen3-Coderçš„æ”¯æŒ
 */

// ä½¿ç”¨requireè¯­æ³•ä»¥é¿å…ESæ¨¡å—é—®é¢˜
const fs = require('fs');
const path = require('path');

console.log('ðŸ§ª Testing ModelScope Preprocessing Patches');
console.log('=' + '='.repeat(60));

// æµ‹è¯•æ•°æ®
const testCases = [
  {
    name: 'GLM-4.5 Tool Call Request',
    provider: 'openai',
    model: 'ZhipuAI/GLM-4.5',
    stage: 'input',
    data: {
      messages: [
        {
          role: 'user',
          content: [
            { type: 'text', text: 'Please search for information about Node.js' },
            { 
              type: 'tool_use', 
              name: 'web_search',
              input: { query: 'Node.js latest features' }
            }
          ]
        }
      ],
      tools: [
        {
          type: 'function',
          function: {
            name: 'web_search',
            description: 'Search the web for information'
          }
        }
      ]
    }
  },
  {
    name: 'Qwen3-Coder Tool Response',
    provider: 'openai', 
    model: 'Qwen/Qwen3-Coder-480B-A35B-Instruct',
    stage: 'response',
    data: {
      choices: [{
        message: {
          role: 'assistant',
          content: 'I will help you write a Python function',
          tool_calls: [
            {
              id: 'tool_123',
              type: 'function',
              function: {
                name: 'code_generator',
                arguments: '{"language": "python", "task": "fibonacci"}'
              }
            }
          ]
        },
        finish_reason: 'tool_calls'
      }],
      usage: { 
        prompt_tokens: 50,
        completion_tokens: 30 
      }
    }
  },
  {
    name: 'GLM-4.5 Response Processing',
    provider: 'openai',
    model: 'glm-4.5-turbo',
    stage: 'response', 
    data: {
      content: [
        {
          type: 'text',
          text: 'Tool call: web_search({"query": "Node.js performance tips"})'
        }
      ],
      id: 'msg_123',
      role: 'assistant'
    }
  },
  {
    name: 'Qwen3 Missing Choices Format',
    provider: 'openai',
    model: 'qwen3-coder-large', 
    stage: 'response',
    data: {
      id: 'resp_456',
      role: 'assistant',
      content: 'Here is the code solution',
      finish_reason: 'stop',
      usage: { total_tokens: 100 }
    }
  }
];

async function runTests() {
  const patchManager = createPatchManager();
  const preprocessor = getUnifiedPatchPreprocessor(undefined, {
    debugMode: true,
    forceAllInputs: true
  });

  let passedTests = 0;
  let totalTests = testCases.length;

  for (const [index, testCase] of testCases.entries()) {
    console.log(`\\n${index + 1}. Testing: ${testCase.name}`);
    console.log(`   Model: ${testCase.model}`);
    console.log(`   Stage: ${testCase.stage}`);

    try {
      let result;
      const requestId = `test_${Date.now()}_${index}`;

      if (testCase.stage === 'input') {
        result = await preprocessor.preprocessInput(
          testCase.data,
          testCase.provider,
          testCase.model,
          requestId
        );
      } else if (testCase.stage === 'response') {
        result = await preprocessor.preprocessResponse(
          testCase.data, 
          testCase.provider,
          testCase.model,
          requestId
        );
      }

      // éªŒè¯ç»“æžœ
      const success = result && typeof result === 'object';
      
      if (success) {
        console.log(`   âœ… PASSED`);
        
        // ç‰¹æ®ŠéªŒè¯é€»è¾‘
        if (testCase.name.includes('GLM-4.5') && testCase.stage === 'input') {
          if (result.temperature === 0.8) {
            console.log(`   ðŸ“Š GLM-4.5 temperature correctly set to 0.8`);
          }
          if (result.messages && result.messages[0] && typeof result.messages[0].content === 'string') {
            console.log(`   ðŸ”§ Tool call format converted to ModelScope GLM format`);
          }
        }
        
        if (testCase.name.includes('Qwen3') && testCase.stage === 'response') {
          if (result.choices && Array.isArray(result.choices)) {
            console.log(`   ðŸ”§ Missing choices field fixed for Qwen3`);
          }
        }
        
        passedTests++;
      } else {
        console.log(`   âŒ FAILED - Result is invalid`);
      }

      // æ˜¾ç¤ºå…³é”®è¾“å‡ºä¿¡æ¯
      if (result !== testCase.data) {
        console.log(`   ðŸ”„ Data was processed and modified`);
      }

    } catch (error) {
      console.log(`   âŒ FAILED - ${error.message}`);
      console.log(`   ðŸ“ Error details:`, error.stack?.split('\\n')[0]);
    }
  }

  console.log(`\\n` + '='.repeat(60));
  console.log(`ðŸŽ¯ Test Results: ${passedTests}/${totalTests} passed`);
  
  if (passedTests === totalTests) {
    console.log(`âœ… All ModelScope preprocessing patches working correctly!`);
    console.log(`ðŸŽ‰ GLM-4.5 and Qwen3-Coder support validated`);
  } else {
    console.log(`âš ï¸  Some tests failed. Please review the patches.`);
  }

  // æ˜¾ç¤ºè¡¥ä¸ç»Ÿè®¡
  const stats = patchManager.getStats();
  console.log(`\\nðŸ“Š Patch Manager Stats:`);
  console.log(`   Registered patches: ${stats.totalPatches}`);
  console.log(`   Active patches: ${stats.activePatches}`);
  
  return passedTests === totalTests;
}

// è¿è¡Œæµ‹è¯•
runTests().then(success => {
  console.log(`\\nðŸ”š Testing completed`);
  process.exit(success ? 0 : 1);
}).catch(error => {
  console.error('ðŸ’¥ Test execution failed:', error);
  process.exit(1);
});