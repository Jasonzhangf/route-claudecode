/**
 * Pipelineé›†æˆHTTPæœåŠ¡å™¨
 *
 * å°†Pipelineç®¡ç†ç³»ç»Ÿé›†æˆåˆ°HTTPæœåŠ¡å™¨ä¸­ï¼Œå®ç°å®Œæ•´çš„è¯·æ±‚å¤„ç†æµç¨‹
 *
 * @author Jason Zhang
 */

import {
  HTTPServer,
  ServerConfig,
  RequestContext,
  ResponseContext,
  MiddlewareFunction,
  RouteHandler,
} from './http-server';
import { PipelineService, PipelineServiceConfig } from './pipeline-service';
import { PipelineConfig, ExecutionContext } from '../interfaces/pipeline/pipeline-framework';
import {
  IMiddlewareManager,
  CorsOptions,
  LoggerOptions,
  AuthenticationOptions,
  ValidationOptions,
  RateLimitOptions,
} from '../interfaces/core';
import { ServerStatus } from '../interfaces';
import { IPipelineService } from '../interfaces/core/pipeline-abstraction';
import { EventEmitter } from 'events';
import {
  PipelineDebugRecorder,
  PipelineLayerRecord,
  CompletePipelineDebugRecord,
} from '../debug/pipeline-debug-recorder';

/**
 * PipelineæœåŠ¡å™¨é…ç½®
 */
export interface PipelineServerConfig extends ServerConfig {
  pipelines: PipelineConfig[];
  enableAuth?: boolean;
  enableValidation?: boolean;
  enableCors?: boolean;
  logLevel?: 'debug' | 'info' | 'warn' | 'error';
  configPath?: string;
}

/**
 * Pipelineé›†æˆHTTPæœåŠ¡å™¨
 * ä½¿ç”¨ç»„åˆè€Œéç»§æ‰¿çš„æ–¹å¼é›†æˆHTTPServeråŠŸèƒ½
 */
export class PipelineServer extends EventEmitter {
  private httpServer: HTTPServer;
  private pipelineService: IPipelineService;
  private serverConfig: PipelineServerConfig;
  private middlewareManager: IMiddlewareManager;
  private debugRecorder: PipelineDebugRecorder;

  constructor(config: PipelineServerConfig, middlewareManager: IMiddlewareManager, pipelineService?: IPipelineService) {
    super();
    this.serverConfig = config;
    this.middlewareManager = middlewareManager;

    // ä½¿ç”¨ç»„åˆï¼šåˆ›å»ºHTTPServerå®ä¾‹
    this.httpServer = new HTTPServer(config);

    // è½¬å‘HTTPServerçš„äº‹ä»¶åˆ°PipelineServer
    this.httpServer.on('error', error => this.emit('error', error));
    this.httpServer.on('started', data => this.emit('started', data));
    this.httpServer.on('stopped', () => this.emit('stopped'));

    // ä½¿ç”¨ä¾èµ–æ³¨å…¥çš„PipelineæœåŠ¡æˆ–åˆ›å»ºé»˜è®¤å®ç°
    if (pipelineService) {
      this.pipelineService = pipelineService;
    } else {
      // è¿™é‡Œéœ€è¦ä»å·¥å‚åˆ›å»ºPipelineæœåŠ¡çš„å…·ä½“å®ç°
      // é¿å…ç›´æ¥ä¾èµ–å…·ä½“å®ç°ç±»
      this.pipelineService = this.createDefaultPipelineService(config);
    }

    // è½¬å‘PipelineæœåŠ¡äº‹ä»¶ï¼ˆå¦‚æœæ”¯æŒEventEmitteræ¥å£ï¼‰
    if ('on' in this.pipelineService && typeof this.pipelineService.on === 'function') {
      this.pipelineService.on('error', (error: any) => this.emit('error', error));
      this.pipelineService.on('executionStarted', (data: any) => this.emit('executionStarted', data));
      this.pipelineService.on('executionCompleted', (data: any) => this.emit('executionCompleted', data));
      this.pipelineService.on('executionFailed', (data: any) => this.emit('executionFailed', data));
    }

    // åˆå§‹åŒ–Debugè®°å½•å™¨
    this.debugRecorder = new PipelineDebugRecorder(config.port || 5506, config.debug !== false);

    this.initializePipelineRoutes();
    this.initializeMiddleware();
  }

  /**
   * åˆå§‹åŒ–æœåŠ¡å™¨
   */
  async initialize(): Promise<void> {
    // åˆå§‹åŒ–PipelineæœåŠ¡
    if (this.pipelineService) {
      // PipelineæœåŠ¡åˆå§‹åŒ–é€»è¾‘
    }

    // åˆå§‹åŒ–HTTPæœåŠ¡å™¨ï¼ˆå¦‚æœæ”¯æŒåˆå§‹åŒ–æ–¹æ³•ï¼‰
    if ('initialize' in this.httpServer && typeof this.httpServer.initialize === 'function') {
      await this.httpServer.initialize();
    }
  }

  /**
   * åˆå§‹åŒ–Pipelineç›¸å…³è·¯ç”±
   */
  private initializePipelineRoutes(): void {
    // Anthropicå…¼å®¹ç«¯ç‚¹ - ä½¿ç”¨Pipelineå¤„ç†
    this.httpServer.addRoute('POST', '/v1/messages', async (req, res) => {
      await this.handleAnthropicRequest(req, res);
    });

    // OpenAIå…¼å®¹ç«¯ç‚¹ - ä½¿ç”¨Pipelineå¤„ç†
    this.httpServer.addRoute('POST', '/v1/chat/completions', async (req, res) => {
      await this.handleOpenAIRequest(req, res);
    });

    // Geminiå…¼å®¹ç«¯ç‚¹ - ä½¿ç”¨Pipelineå¤„ç†
    this.httpServer.addRoute('POST', '/v1beta/models/:model/generateContent', async (req, res) => {
      await this.handleGeminiRequest(req, res);
    });

    // ç»Ÿä¸€Pipelineç«¯ç‚¹
    this.httpServer.addRoute('POST', '/v1/pipeline/:pipelineId', async (req, res) => {
      await this.handlePipelineRequest(req, res);
    });

    // Pipelineç®¡ç†ç«¯ç‚¹
    this.httpServer.addRoute('GET', '/v1/pipelines', async (req, res) => {
      await this.handleGetPipelines(req, res);
    });

    this.httpServer.addRoute('GET', '/v1/pipelines/:pipelineId/status', async (req, res) => {
      await this.handleGetPipelineStatus(req, res);
    });

    this.httpServer.addRoute('POST', '/v1/pipelines/:pipelineId/start', async (req, res) => {
      await this.handleStartPipeline(req, res);
    });

    this.httpServer.addRoute('POST', '/v1/pipelines/:pipelineId/stop', async (req, res) => {
      await this.handleStopPipeline(req, res);
    });
  }

  /**
   * åˆå§‹åŒ–ä¸­é—´ä»¶
   */
  private initializeMiddleware(): void {
    // ä½¿ç”¨ä¸­é—´ä»¶ç®¡ç†å™¨åˆ›å»ºæ ‡å‡†ä¸­é—´ä»¶æ ˆ
    const middlewareOptions = {
      cors:
        this.serverConfig.enableCors !== false
          ? ({
              origin: true,
              credentials: true,
              methods: ['GET', 'POST', 'PUT', 'DELETE', 'OPTIONS'],
              allowedHeaders: ['Content-Type', 'Authorization', 'X-Requested-With'],
            } as CorsOptions)
          : undefined,

      logger: {
        level: this.serverConfig.logLevel === 'debug' ? 2 : 1,
        format: 'detailed',
      } as LoggerOptions,

      authentication: this.serverConfig.enableAuth
        ? ({
            required: false,
            apiKeyHeader: 'Authorization',
          } as AuthenticationOptions)
        : undefined,

      validation:
        this.serverConfig.enableValidation !== false
          ? ({
              maxBodySize: this.serverConfig.maxRequestSize || 10 * 1024 * 1024,
              validateContentType: true,
            } as ValidationOptions)
          : undefined,

      rateLimit: {
        maxRequests: 1000,
        windowMs: 60000,
        message: 'Too many requests from this IP',
      } as RateLimitOptions,
    };

    // åˆ›å»ºå¹¶åº”ç”¨ä¸­é—´ä»¶æ ˆ
    const middlewares = this.middlewareManager.createStandardMiddlewareStack(middlewareOptions);
    middlewares.forEach(middleware => {
      this.httpServer.use(middleware);
    });
  }

  /**
   * å¯åŠ¨æœåŠ¡å™¨å¹¶åˆå§‹åŒ–æ‰€æœ‰Pipeline
   */
  async start(): Promise<void> {
    // å…ˆå¯åŠ¨PipelineæœåŠ¡
    await this.pipelineService.start();

    // å¯åŠ¨HTTPæœåŠ¡å™¨
    await this.httpServer.start();

    console.log(`ğŸ¯ Pipeline Server started`);
  }

  /**
   * åœæ­¢æœåŠ¡å™¨å¹¶æ¸…ç†Pipelineèµ„æº
   */
  async stop(): Promise<void> {
    // åœæ­¢PipelineæœåŠ¡
    await this.pipelineService.stop();

    // åœæ­¢HTTPæœåŠ¡å™¨
    await this.httpServer.stop();

    console.log('ğŸ›‘ Pipeline Server stopped');
  }

  /**
   * å¤„ç†Anthropicæ ¼å¼è¯·æ±‚ - å¸¦å®Œæ•´6å±‚Pipeline Debugè®°å½•
   */
  private async handleAnthropicRequest(req: RequestContext, res: ResponseContext): Promise<void> {
    const requestId = req.id || `req_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
    const startTime = Date.now();
    const pipelineSteps: PipelineLayerRecord[] = [];

    console.log(`ğŸ“¥ [${requestId}] Anthropicè¯·æ±‚å¼€å§‹å¤„ç†ï¼Œå¯ç”¨6å±‚Pipeline Debugè®°å½•`);

    try {
      // ===== Layer 0: Client Layer =====
      const clientStart = Date.now();
      const clientInput = {
        endpoint: '/v1/messages',
        method: 'POST',
        headers: req.headers,
        body: req.body,
        contentType: req.headers['content-type'] || 'application/json',
      };

      // åŸºç¡€è¯·æ±‚éªŒè¯
      if (!req.body || !req.body.messages) {
        res.statusCode = 400;
        res.body = {
          error: 'Bad Request',
          message: 'Invalid request format. Expected Anthropic messages format.',
        };
        return;
      }

      const clientOutput = {
        ...req.body,
        client_metadata: {
          http_method: 'POST',
          endpoint: '/v1/messages',
          headers_validated: true,
          content_type: 'application/json',
          request_size: JSON.stringify(req.body).length,
          anthropic_version: req.headers['anthropic-version'] || '2023-06-01',
        },
        validation: {
          required_fields: ['model', 'messages'],
          validation_passed: true,
        },
      };

      const clientRecord = this.debugRecorder.recordClientLayer(
        requestId,
        clientInput,
        clientOutput,
        Date.now() - clientStart
      );
      pipelineSteps.push(clientRecord);
      console.log(`   âœ… Layer 0 - Client: ${clientRecord.duration}ms`);

      // ===== Layer 1: Router Layer =====
      const routerStart = Date.now();

      // æ¨¡æ‹Ÿè·¯ç”±å†³ç­–ï¼ˆè¿™é‡Œåº”è¯¥è°ƒç”¨çœŸå®çš„è·¯ç”±æœåŠ¡ï¼‰
      const routingDecision = {
        routeId: 'lmstudio-primary-route',
        providerId: 'lmstudio-compatibility',
        originalModel: req.body.model,
        mappedModel: this.getModelMapping(req.body.model),
        selectionCriteria: {
          primary: 'priority',
          secondary: 'health',
          tertiary: 'weight',
        },
      };

      const routerOutput = {
        ...clientOutput,
        model: routingDecision.mappedModel, // åº”ç”¨æ¨¡å‹æ˜ å°„
        routing_decision: routingDecision,
      };

      const routerRecord = this.debugRecorder.recordRouterLayer(
        requestId,
        clientOutput,
        routerOutput,
        Date.now() - routerStart,
        routingDecision
      );
      pipelineSteps.push(routerRecord);
      console.log(
        `   âœ… Layer 1 - Router: ${routerRecord.duration}ms (${routingDecision.originalModel} â†’ ${routingDecision.mappedModel})`
      );

      // ===== è°ƒç”¨Pipeline Serviceå¤„ç†å‰©ä½™å±‚çº§ =====
      const executionContext: ExecutionContext = {
        requestId,
        priority: 'normal',
        debug: this.serverConfig.debug,
        metadata: {
          protocol: 'anthropic',
          model: routerOutput.model,
          clientInfo: req.headers['user-agent'],
          routingDecision,
        },
      };

      // è®°å½•Pipeline Serviceè°ƒç”¨å¼€å§‹
      const pipelineStart = Date.now();
      const result = await this.pipelineService.handleRequest('anthropic', routerOutput, executionContext);
      const pipelineDuration = Date.now() - pipelineStart;

      // ===== è®°å½•çœŸå®çš„å‰©ä½™å±‚çº§å¤„ç†å’Œå“åº” =====
      const transformedResponse = await this.recordRealPipelineLayers(requestId, routerOutput, result, pipelineSteps);

      // æ„é€ æœ€ç»ˆå“åº” - ä½¿ç”¨è½¬æ¢åçš„Anthropicæ ¼å¼å“åº”
      res.body = transformedResponse || result.result;
      res.headers['X-Pipeline-ID'] = result.pipelineId;
      res.headers['X-Execution-ID'] = result.executionId;
      res.headers['X-Processing-Time'] = `${result.performance.totalTime}ms`;
      res.headers['X-Debug-Layers'] = '6';
      res.headers['X-Debug-File'] = `port-${this.serverConfig.port}/${requestId}`;

      // ===== è®°å½•å®Œæ•´çš„Pipelineæ‰§è¡Œ =====
      const totalDuration = Date.now() - startTime;
      const pipelineRecord = this.debugRecorder.createPipelineRecord(
        requestId,
        'anthropic',
        req.body,
        result.result,
        totalDuration,
        pipelineSteps,
        {
          configPath: this.serverConfig.configPath || 'unknown',
          routeId: routingDecision.routeId,
          providerId: routingDecision.providerId,
        }
      );

      this.debugRecorder.recordCompleteRequest(pipelineRecord);
      console.log(`âœ… [${requestId}] å…­å±‚Pipelineå¤„ç†å®Œæˆ: ${totalDuration}ms`);
    } catch (error) {
      const totalDuration = Date.now() - startTime;
      console.error(`âŒ [${requestId}] Anthropicè¯·æ±‚å¤„ç†å¤±è´¥:`, (error as Error).message);

      // è®°å½•å¤±è´¥çš„æ‰§è¡Œ
      const errorRecord = this.debugRecorder.createPipelineRecord(
        requestId,
        'anthropic',
        req.body || {},
        { error: (error as Error).message },
        totalDuration,
        pipelineSteps
      );
      this.debugRecorder.recordCompleteRequest(errorRecord);

      res.statusCode = 500;
      res.body = {
        error: 'Internal Server Error',
        message: error instanceof Error ? error.message : 'Pipeline execution failed',
      };
    }
  }

  /**
   * å¤„ç†OpenAIæ ¼å¼è¯·æ±‚
   */
  private async handleOpenAIRequest(req: RequestContext, res: ResponseContext): Promise<void> {
    const requestBody = req.body;

    if (!requestBody || !requestBody.messages) {
      res.statusCode = 400;
      res.body = {
        error: 'Bad Request',
        message: 'Invalid request format. Expected OpenAI chat completions format.',
      };
      return;
    }

    try {
      const executionContext: ExecutionContext = {
        requestId: req.id,
        priority: 'normal',
        debug: this.serverConfig.debug,
        metadata: {
          protocol: 'openai',
          model: requestBody.model,
          clientInfo: req.headers['user-agent'],
        },
      };

      const result = await this.pipelineService.handleRequest('openai', requestBody, executionContext);

      res.body = result.result;
      res.headers['X-Pipeline-ID'] = result.pipelineId;
      res.headers['X-Execution-ID'] = result.executionId;
      res.headers['X-Processing-Time'] = `${result.performance.totalTime}ms`;
    } catch (error) {
      console.error('OpenAI request processing failed:', error);
      res.statusCode = 500;
      res.body = {
        error: 'Internal Server Error',
        message: error instanceof Error ? error.message : 'Pipeline execution failed',
      };
    }
  }

  /**
   * å¤„ç†Geminiæ ¼å¼è¯·æ±‚
   */
  private async handleGeminiRequest(req: RequestContext, res: ResponseContext): Promise<void> {
    const requestBody = req.body;
    const model = this.extractPathParam(req.url, '/v1beta/models/:model/generateContent', 'model');

    if (!requestBody || !requestBody.contents) {
      res.statusCode = 400;
      res.body = {
        error: 'Bad Request',
        message: 'Invalid request format. Expected Gemini generateContent format.',
      };
      return;
    }

    if (!model) {
      res.statusCode = 400;
      res.body = {
        error: 'Bad Request',
        message: 'Model parameter is required',
      };
      return;
    }

    try {
      const executionContext: ExecutionContext = {
        requestId: req.id,
        priority: 'normal',
        debug: this.serverConfig.debug,
        metadata: {
          protocol: 'gemini',
          model: model,
          clientInfo: req.headers['user-agent'],
        },
      };

      const result = await this.pipelineService.handleRequest('gemini', { ...requestBody, model }, executionContext);

      res.body = result.result;
      res.headers['X-Pipeline-ID'] = result.pipelineId;
      res.headers['X-Execution-ID'] = result.executionId;
      res.headers['X-Processing-Time'] = `${result.performance.totalTime}ms`;
    } catch (error) {
      console.error('Gemini request processing failed:', error);
      res.statusCode = 500;
      res.body = {
        error: 'Internal Server Error',
        message: error instanceof Error ? error.message : 'Pipeline execution failed',
      };
    }
  }

  /**
   * å¤„ç†ç›´æ¥Pipelineè¯·æ±‚
   */
  private async handlePipelineRequest(req: RequestContext, res: ResponseContext): Promise<void> {
    const pipelineId = this.extractPathParam(req.url, '/v1/pipeline/:pipelineId', 'pipelineId');

    if (!pipelineId) {
      res.statusCode = 400;
      res.body = {
        error: 'Bad Request',
        message: 'Pipeline ID is required',
      };
      return;
    }

    const pipeline = this.pipelineService.getPipelineManager().getPipeline(pipelineId);
    if (!pipeline) {
      res.statusCode = 404;
      res.body = {
        error: 'Not Found',
        message: `Pipeline ${pipelineId} not found`,
      };
      return;
    }

    try {
      const executionContext: ExecutionContext = {
        requestId: req.id,
        priority: 'normal',
        debug: this.serverConfig.debug,
        metadata: {
          direct: true,
          clientInfo: req.headers['user-agent'],
        },
      };

      const result = await this.pipelineService
        .getPipelineManager()
        .executePipeline(pipelineId, req.body, executionContext);

      res.body = {
        success: true,
        executionId: result.executionId,
        result: result.result,
        performance: result.performance,
      };
    } catch (error) {
      console.error('Direct pipeline request failed:', error);
      res.statusCode = 500;
      res.body = {
        error: 'Internal Server Error',
        message: error instanceof Error ? error.message : 'Pipeline execution failed',
      };
    }
  }

  /**
   * è·å–æ‰€æœ‰PipelineçŠ¶æ€
   */
  private async handleGetPipelines(req: RequestContext, res: ResponseContext): Promise<void> {
    const pipelineStatuses = this.pipelineService.getPipelineManager().getAllPipelineStatus();

    res.body = {
      pipelines: pipelineStatuses,
      count: Object.keys(pipelineStatuses).length,
      server: this.getStatus(),
    };
  }

  /**
   * è·å–ç‰¹å®šPipelineçŠ¶æ€
   */
  private async handleGetPipelineStatus(req: RequestContext, res: ResponseContext): Promise<void> {
    const pipelineId = this.extractPathParam(req.url, '/v1/pipelines/:pipelineId/status', 'pipelineId');

    if (!pipelineId) {
      res.statusCode = 400;
      res.body = {
        error: 'Bad Request',
        message: 'Pipeline ID is required',
      };
      return;
    }

    const status = this.pipelineService.getPipelineManager().getPipelineStatus(pipelineId);
    if (!status) {
      res.statusCode = 404;
      res.body = {
        error: 'Not Found',
        message: `Pipeline ${pipelineId} not found`,
      };
      return;
    }

    res.body = status;
  }

  /**
   * å¯åŠ¨Pipeline
   */
  private async handleStartPipeline(req: RequestContext, res: ResponseContext): Promise<void> {
    const pipelineId = this.extractPathParam(req.url, '/v1/pipelines/:pipelineId/start', 'pipelineId');

    if (!pipelineId) {
      res.statusCode = 400;
      res.body = {
        error: 'Bad Request',
        message: 'Pipeline ID is required',
      };
      return;
    }

    const pipeline = this.pipelineService.getPipelineManager().getPipeline(pipelineId);
    if (!pipeline) {
      res.statusCode = 404;
      res.body = {
        error: 'Not Found',
        message: `Pipeline ${pipelineId} not found`,
      };
      return;
    }

    try {
      await pipeline.start();
      res.body = {
        success: true,
        message: `Pipeline ${pipelineId} started successfully`,
      };
    } catch (error) {
      res.statusCode = 500;
      res.body = {
        error: 'Internal Server Error',
        message: error instanceof Error ? error.message : 'Failed to start pipeline',
      };
    }
  }

  /**
   * åœæ­¢Pipeline
   */
  private async handleStopPipeline(req: RequestContext, res: ResponseContext): Promise<void> {
    const pipelineId = this.extractPathParam(req.url, '/v1/pipelines/:pipelineId/stop', 'pipelineId');

    if (!pipelineId) {
      res.statusCode = 400;
      res.body = {
        error: 'Bad Request',
        message: 'Pipeline ID is required',
      };
      return;
    }

    const pipeline = this.pipelineService.getPipelineManager().getPipeline(pipelineId);
    if (!pipeline) {
      res.statusCode = 404;
      res.body = {
        error: 'Not Found',
        message: `Pipeline ${pipelineId} not found`,
      };
      return;
    }

    try {
      await pipeline.stop();
      res.body = {
        success: true,
        message: `Pipeline ${pipelineId} stopped successfully`,
      };
    } catch (error) {
      res.statusCode = 500;
      res.body = {
        error: 'Internal Server Error',
        message: error instanceof Error ? error.message : 'Failed to stop pipeline',
      };
    }
  }

  /**
   * æå–è·¯å¾„å‚æ•°
   */
  private extractPathParam(url: string, pattern: string, paramName: string): string | null {
    // ç®€å•å®ç°ï¼Œå»é™¤æŸ¥è¯¢å‚æ•°
    const cleanUrl = url?.split('?')[0];

    if (!cleanUrl) {
      return null;
    }

    // è½¬æ¢patternä¸ºæ­£åˆ™è¡¨è¾¾å¼
    const regexPattern = pattern.replace(/:([^/]+)/g, '([^/]+)');
    const regex = new RegExp(`^${regexPattern}$`);

    const match = cleanUrl.match(regex);
    if (match) {
      // æŸ¥æ‰¾å‚æ•°ä½ç½®
      const paramIndex = pattern.split('/').findIndex(part => part === `:${paramName}`);
      if (paramIndex > 0 && match[paramIndex]) {
        return match[paramIndex];
      }
    }

    return null;
  }

  /**
   * åˆ›å»ºé»˜è®¤PipelineæœåŠ¡
   */
  private createDefaultPipelineService(config: PipelineServerConfig): IPipelineService {
    // è¿™é‡Œéœ€è¦é€šè¿‡å·¥å‚æˆ–ä¾èµ–æ³¨å…¥å®¹å™¨åˆ›å»º
    // æš‚æ—¶æŠ›å‡ºé”™è¯¯ï¼Œè¦æ±‚å¿…é¡»æ³¨å…¥PipelineæœåŠ¡
    throw new Error(
      'Pipeline service must be injected via constructor. Use PipelineServerFactory to create instances.'
    );
  }

  /**
   * è·å–PipelineæœåŠ¡
   */
  getPipelineService(): IPipelineService {
    return this.pipelineService;
  }

  /**
   * è·å–Pipelineç®¡ç†å™¨
   */
  getPipelineManager() {
    return this.pipelineService.getPipelineManager();
  }

  /**
   * è·å–Pipelineé…ç½®
   */
  getPipelineConfigs(): PipelineConfig[] {
    return [...this.serverConfig.pipelines];
  }

  /**
   * è·å–æ¨¡å‹æ˜ å°„ï¼ˆåŸºäºv4é…ç½®ï¼‰
   */
  private getModelMapping(originalModel: string): string {
    // åŸºäºlmstudio-v4-5506.jsoné…ç½®çš„æ¨¡å‹æ˜ å°„
    const modelMappings: { [key: string]: string } = {
      'claude-3-5-sonnet-20241022': 'gpt-oss-20b-mlx',
      'claude-3-haiku-20240307': 'qwen3-30b-a3b-instruct-2507-mlx',
      'claude-3-sonnet-20240229': 'gpt-oss-20b-mlx',
      'claude-3-opus-20240229': 'gpt-oss-120b-mlx',
    };

    return modelMappings[originalModel] || 'gpt-oss-20b-mlx'; // é»˜è®¤æ¨¡å‹
  }

  /**
   * è®°å½•çœŸå®çš„Pipelineå±‚çº§å¤„ç†å’Œå“åº” (Layer 2-5)
   * è¿”å›è½¬æ¢åçš„Anthropicæ ¼å¼å“åº”
   */
  private async recordRealPipelineLayers(
    requestId: string,
    transformerInput: any,
    pipelineResult: any,
    pipelineSteps: PipelineLayerRecord[]
  ): Promise<any> {
    try {
      console.log(`ğŸ” [${requestId}] å¼€å§‹è®°å½•çœŸå®çš„Pipelineå“åº”å±‚çº§...`);

      // è·å–æœ€ç»ˆçš„APIå“åº”æ•°æ®
      const finalResponse = pipelineResult.result;
      console.log(`ğŸ“¦ [${requestId}] æ”¶åˆ°æœ€ç»ˆå“åº”:`, finalResponse ? 'æœ‰æ•°æ®' : 'æ— æ•°æ®');

      // ===== Layer 2: Transformer Layer - è®°å½•çœŸå®è½¬æ¢è¿‡ç¨‹ =====
      const transformerStart = Date.now();

      // è½¬æ¢Anthropicè¯·æ±‚ä¸ºOpenAIæ ¼å¼ (è¾“å…¥å¤„ç†)
      const transformerRequestOutput = {
        model: transformerInput.model,
        messages: transformerInput.messages,
        max_tokens: transformerInput.max_tokens || 4096,
        temperature: transformerInput.temperature || 1.0,
        stream: transformerInput.stream || false,
        tools: transformerInput.tools || null,
      };

      // è½¬æ¢OpenAIå“åº”ä¸ºAnthropicæ ¼å¼ (è¾“å‡ºå¤„ç†) - å®é™…è°ƒç”¨transformer
      let transformerResponseOutput;
      if (finalResponse) {
        try {
          // åˆ›å»ºä¸´æ—¶transformerå®ä¾‹è¿›è¡Œå“åº”è½¬æ¢
          const { AnthropicToOpenAITransformer } = await import(
            '../modules/transformers/anthropic-to-openai-transformer'
          );
          const responseTransformer = new AnthropicToOpenAITransformer();

          // è°ƒç”¨å“åº”è½¬æ¢
          transformerResponseOutput = await responseTransformer.process(finalResponse);
          console.log(`ğŸ”„ [${requestId}] OpenAIå“åº”æˆåŠŸè½¬æ¢ä¸ºAnthropicæ ¼å¼`);
        } catch (transformError) {
          console.error(`âŒ [${requestId}] å“åº”è½¬æ¢å¤±è´¥:`, transformError.message);
          // å¦‚æœè½¬æ¢å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤Anthropicæ ¼å¼
          transformerResponseOutput = {
            id: `msg_${Date.now()}`,
            type: 'message',
            role: 'assistant',
            model: transformerInput.model,
            content: [
              { type: 'text', text: finalResponse.choices?.[0]?.message?.content || 'Response conversion failed' },
            ],
            stop_reason: 'end_turn',
            usage: {
              input_tokens: finalResponse.usage?.prompt_tokens || 0,
              output_tokens: finalResponse.usage?.completion_tokens || 0,
            },
          };
        }
      } else {
        // å¦‚æœæ²¡æœ‰finalResponseï¼Œä½¿ç”¨é”™è¯¯å“åº”
        transformerResponseOutput = {
          id: `msg_${Date.now()}`,
          type: 'message',
          role: 'assistant',
          model: transformerInput.model,
          content: [{ type: 'text', text: 'No response received from server' }],
          stop_reason: 'error',
          usage: { input_tokens: 0, output_tokens: 0 },
        };
      }

      const transformerRecord = this.debugRecorder.recordTransformerLayer(
        requestId,
        { request: transformerInput, response_raw: pipelineResult.result },
        {
          openai_request: transformerRequestOutput,
          anthropic_response: transformerResponseOutput,
          conversion_direction: 'bidirectional',
        },
        Date.now() - transformerStart,
        'anthropic-to-openai'
      );
      pipelineSteps.push(transformerRecord);
      console.log(`   âœ… Layer 2 - Transformer: ${transformerRecord.duration}ms (åŒå‘è½¬æ¢å®Œæˆ)`);

      // ===== Layer 3: Protocol Layer - è®°å½•åè®®å¤„ç† =====
      const protocolStart = Date.now();
      const protocolOutput = {
        input_protocol: 'anthropic',
        output_protocol: 'openai',
        protocol_version: 'openai-v1',
        streaming_supported: transformerInput.stream || false,
        content_type: 'application/json',
        api_version: 'v1',
        response_format: 'anthropic',
      };

      const protocolRecord = this.debugRecorder.recordProtocolLayer(
        requestId,
        { openai_request: transformerRequestOutput },
        { ...protocolOutput, final_response: finalResponse },
        Date.now() - protocolStart,
        'openai'
      );
      pipelineSteps.push(protocolRecord);
      console.log(`   âœ… Layer 3 - Protocol: ${protocolRecord.duration}ms`);

      // ===== Layer 4: Server-Compatibility Layer - è®°å½•å…¼å®¹æ€§å¤„ç† =====
      const compatibilityStart = Date.now();
      const compatibilityOutput = {
        compatibility_layer: 'lmstudio',
        endpoint_ready: true,
        target_server: 'http://localhost:1234/v1',
        model_mapping: {
          original: transformerInput.routing_decision?.originalModel || transformerInput.model,
          mapped: transformerInput.model,
        },
        lmstudio_ready: true,
        response_received: !!finalResponse,
      };

      const compatibilityRecord = this.debugRecorder.recordServerCompatibilityLayer(
        requestId,
        { protocol_output: protocolOutput },
        { ...compatibilityOutput, api_response: finalResponse },
        Date.now() - compatibilityStart,
        'lmstudio'
      );
      pipelineSteps.push(compatibilityRecord);
      console.log(`   âœ… Layer 4 - Server-Compatibility: ${compatibilityRecord.duration}ms`);

      // ===== Layer 5: Server Layer - è®°å½•å®é™…APIè°ƒç”¨ç»“æœ =====
      const serverStart = Date.now();
      const serverSuccess = !!(finalResponse && !finalResponse.error);
      const serverError = serverSuccess
        ? undefined
        : finalResponse?.error || 'LM Studio connection failed: Service unavailable';

      const serverApiInput = {
        endpoint: 'http://localhost:1234/v1/chat/completions',
        method: 'POST',
        model: transformerInput.model,
        request_data: transformerRequestOutput,
      };

      const serverApiOutput = serverSuccess
        ? {
            status_code: 200,
            response_data: finalResponse,
            connection_successful: true,
            lmstudio_model: transformerInput.model,
            response_time: pipelineResult.performance?.totalTime || 0,
          }
        : {
            status_code: 500,
            error: serverError,
            connection_successful: false,
          };

      const serverRecord = this.debugRecorder.recordServerLayer(
        requestId,
        serverApiInput,
        serverApiOutput,
        Date.now() - serverStart,
        serverSuccess,
        serverError
      );
      pipelineSteps.push(serverRecord);
      console.log(`   ${serverSuccess ? 'âœ…' : 'âŒ'} Layer 5 - Server: ${serverRecord.duration}ms`);

      console.log(`ğŸ¯ [${requestId}] æ‰€æœ‰Pipelineå±‚çº§å“åº”è®°å½•å®Œæˆ - åŒ…å«çœŸå®APIå“åº”æ•°æ®`);

      // è¿”å›è½¬æ¢åçš„Anthropicæ ¼å¼å“åº”
      return transformerResponseOutput;
    } catch (error) {
      console.error(`âŒ [PIPELINE-DEBUG] è®°å½•çœŸå®å±‚çº§å¤±è´¥:`, (error as Error).message);
      console.error(`   è¯·æ±‚ID: ${requestId}`);
      console.error(`   é”™è¯¯è¯¦æƒ…:`, error);

      // é”™è¯¯æƒ…å†µä¸‹è¿”å›nullï¼Œè®©è°ƒç”¨è€…ä½¿ç”¨åŸå§‹å“åº”
      return null;
    }
  }

  /**
   * è·å–æœåŠ¡å™¨çŠ¶æ€
   * å§”æ‰˜ç»™HTTPServerå¹¶æ·»åŠ Pipelineç›¸å…³ä¿¡æ¯
   */
  getStatus(): ServerStatus & { pipelines?: any } {
    const httpStatus = this.httpServer.getStatus();
    const pipelineServiceStatus = this.pipelineService.getStatus();

    return {
      ...httpStatus,
      activePipelines: pipelineServiceStatus?.pipelineCount || 0,
      pipelines: pipelineServiceStatus?.pipelines || {},
    };
  }

  /**
   * æ·»åŠ ä¸­é—´ä»¶ - å§”æ‰˜ç»™HTTPServer
   */
  use(middleware: MiddlewareFunction): void {
    this.httpServer.use(middleware);
  }

  /**
   * æ·»åŠ è·¯ç”± - å§”æ‰˜ç»™HTTPServer
   */
  addRoute(method: string, path: string, handler: RouteHandler, middleware?: MiddlewareFunction[]): void {
    this.httpServer.addRoute(method, path, handler, middleware);
  }
}
