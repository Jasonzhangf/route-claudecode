/**
 * Anthropicåˆ°OpenAIæ ¼å¼è½¬æ¢å™¨
 *
 * å°†Anthropicæ ¼å¼çš„è¯·æ±‚è½¬æ¢ä¸ºOpenAIå…¼å®¹æ ¼å¼
 *
 * @author Jason Zhang
 */

import {
  IModuleInterface,
  ModuleType,
  IModuleStatus,
  IModuleMetrics,
} from '../../interfaces/core/module-implementation-interface';
import { EventEmitter } from 'events';
import { modelMappingService } from '../../router/model-mapping-service';

/**
 * Anthropicåˆ°OpenAIè½¬æ¢å™¨é…ç½®
 */
export interface AnthropicToOpenAITransformerConfig {
  model: string;
  preserveToolCalls: boolean;
  mapSystemMessage: boolean;
  defaultMaxTokens: number;
}

/**
 * Anthropicåˆ°OpenAIæ ¼å¼è½¬æ¢å™¨
 */
export class AnthropicToOpenAITransformer extends EventEmitter implements IModuleInterface {
  protected readonly id: string = 'anthropic-to-openai-transformer';
  protected readonly name: string = 'Anthropic to OpenAI Transformer';
  protected readonly type: ModuleType = ModuleType.TRANSFORMER;
  protected readonly version: string = '1.0.0';
  protected status: 'stopped' | 'starting' | 'running' | 'stopping' | 'error' = 'stopped';
  protected metrics: IModuleMetrics = {
    requestsProcessed: 0,
    averageProcessingTime: 0,
    errorRate: 0,
    memoryUsage: 0,
    cpuUsage: 0,
  };

  getId(): string {
    return this.id;
  }
  getName(): string {
    return this.name;
  }
  getType(): ModuleType {
    return this.type;
  }
  getVersion(): string {
    return this.version;
  }
  getStatus(): IModuleStatus {
    return { id: this.id, name: this.name, type: this.type, status: this.status, health: 'healthy' };
  }
  getMetrics(): IModuleMetrics {
    return { ...this.metrics };
  }
  async configure(config: any): Promise<void> {}
  async start(): Promise<void> {
    this.status = 'running';
  }
  async stop(): Promise<void> {
    this.status = 'stopped';
  }
  async reset(): Promise<void> {}
  async cleanup(): Promise<void> {}
  async healthCheck(): Promise<{ healthy: boolean; details: any }> {
    return { healthy: true, details: {} };
  }
  async process(input: any): Promise<any> {
    return this.onProcess(input);
  }
  private transformerConfig: AnthropicToOpenAITransformerConfig;

  constructor(
    id: string = 'anthropic-to-openai-transformer',
    config: Partial<AnthropicToOpenAITransformerConfig> = {}
  ) {
    super();

    this.transformerConfig = {
      model: 'gpt-3.5-turbo',
      preserveToolCalls: true,
      mapSystemMessage: true,
      defaultMaxTokens: 4096,
      ...config,
    };
  }

  /**
   * é…ç½®å¤„ç†
   */
  protected async onConfigure(config: Partial<AnthropicToOpenAITransformerConfig>): Promise<void> {
    this.transformerConfig = { ...this.transformerConfig, ...config };
  }

  /**
   * å¤„ç†æ ¼å¼è½¬æ¢ - æ”¯æŒè¯·æ±‚å’Œå“åº”åŒå‘è½¬æ¢
   */
  protected async onProcess(input: any): Promise<any> {
    // æ£€æµ‹è¾“å…¥æ˜¯è¯·æ±‚è¿˜æ˜¯å“åº”
    if (this.isAnthropicRequest(input)) {
      return this.convertRequestToOpenAI(input);
    } else if (this.isOpenAIResponse(input)) {
      return this.convertResponseToAnthropic(input);
    } else {
      throw new Error('ä¸æ”¯æŒçš„è¾“å…¥æ ¼å¼ï¼šæ—¢ä¸æ˜¯Anthropicè¯·æ±‚ä¹Ÿä¸æ˜¯OpenAIå“åº”');
    }
  }

  /**
   * åˆ¤æ–­æ˜¯å¦ä¸ºAnthropicè¯·æ±‚
   */
  private isAnthropicRequest(input: any): boolean {
    return input && Array.isArray(input.messages) && !input.choices && !input.usage;
  }

  /**
   * åˆ¤æ–­æ˜¯å¦ä¸ºOpenAIå“åº”
   */
  private isOpenAIResponse(input: any): boolean {
    return input && input.object === 'chat.completion' && Array.isArray(input.choices) && input.usage;
  }

  /**
   * è½¬æ¢Anthropicè¯·æ±‚ä¸ºOpenAIæ ¼å¼
   */
  private convertRequestToOpenAI(input: any): any {
    const openaiRequest: any = {};

    // ğŸ” Transformerå±‚è¾“å…¥æ—¥å¿—
    console.log(`ğŸ”„ [Transformerå±‚] æ¥æ”¶Anthropicè¯·æ±‚:`);
    console.log(`   è¾“å…¥æ¨¡å‹: ${input.model || '(æœªæŒ‡å®š)'}`);
    console.log(`   æ¶ˆæ¯æ•°é‡: ${input.messages?.length || 0}`);
    console.log(`   ç³»ç»Ÿæ¶ˆæ¯: ${input.system ? 'å­˜åœ¨' : 'æ— '}`);
    console.log(`   å·¥å…·å®šä¹‰: ${input.tools?.length || 0} ä¸ª`);

    // åŠ¨æ€æ¨¡å‹æ˜ å°„ï¼šä½¿ç”¨ModelMappingService
    const inputModel = input.model || 'claude-3-5-sonnet-20241022'; // é»˜è®¤æ¨¡å‹
    console.log(`ğŸ¯ [Transformerå±‚] å‡†å¤‡æ‰§è¡ŒåŠ¨æ€æ¨¡å‹æ˜ å°„: ${inputModel}`);

    // è·å–LM Studioå¯ç”¨æ¨¡å‹åˆ—è¡¨ï¼ˆä»é…ç½®æˆ–å®æ—¶è·å–ï¼‰
    const availableModels = [
      'gpt-oss-20b-mlx',
      'text-embedding-nomic-embed-text-v1.5',
      'gpt-oss-120b-mlx',
      'qwen3-4b-thinking-2507-mlx',
      'qwen3-30b-a3b-instruct-2507-mlx',
      'glm-4.5-air@3bit',
      'glm-4.5-air@8bit',
      'qwen3-235b-a22b-instruct-2507-mlx',
      'gemma-3n-e2b-it-mlx',
      'bge-small-en-v1.5',
      'nextcoder-32b-mlx',
      'qwq-32b-mlx',
      'gemma-3-27b-it-ud-q4_k_xl',
      'qwen2.5-vl-72b-instruct',
      'qwen3-30b-a3b-python-coder-mlx',
    ];

    // æ‰§è¡ŒåŠ¨æ€æ˜ å°„
    const mappingResult = modelMappingService.performMapping(inputModel, availableModels);

    if (!mappingResult.isValid) {
      console.error(`ğŸš¨ æ¨¡å‹æ˜ å°„å¤±è´¥: ${mappingResult.error}`);
      throw new Error(`Model mapping failed: ${mappingResult.error}`);
    }

    console.log(
      `âœ… [Transformerå±‚] æ¨¡å‹æ˜ å°„æˆåŠŸ: ${inputModel} -> ${mappingResult.targetModel} (åˆ†ç±»: ${mappingResult.category})`
    );
    openaiRequest.model = mappingResult.targetModel;

    // è½¬æ¢æ¶ˆæ¯æ ¼å¼
    openaiRequest.messages = this.convertMessages(input.messages);

    // è½¬æ¢å‚æ•°
    if (input.max_tokens) {
      openaiRequest.max_tokens = input.max_tokens;
    } else {
      openaiRequest.max_tokens = this.transformerConfig.defaultMaxTokens;
    }

    if (input.temperature !== undefined) {
      openaiRequest.temperature = input.temperature;
    }

    if (input.top_p !== undefined) {
      openaiRequest.top_p = input.top_p;
    }

    // è½¬æ¢åœæ­¢åºåˆ—
    if (input.stop) {
      openaiRequest.stop = Array.isArray(input.stop) ? input.stop : [input.stop];
    }

    // è½¬æ¢æµå¼è®¾ç½®
    if (input.stream !== undefined) {
      openaiRequest.stream = input.stream;
    }

    // è½¬æ¢ç³»ç»Ÿæ¶ˆæ¯ï¼ˆå¦‚æœéœ€è¦ï¼‰
    if (input.system && this.transformerConfig.mapSystemMessage) {
      // åœ¨OpenAIæ ¼å¼ä¸­ï¼Œç³»ç»Ÿæ¶ˆæ¯æ˜¯messagesæ•°ç»„çš„ç¬¬ä¸€ä¸ªå…ƒç´ 
      openaiRequest.messages.unshift({
        role: 'system',
        content: input.system,
      });
    }

    // è½¬æ¢å·¥å…·å®šä¹‰
    if (input.tools && Array.isArray(input.tools) && this.transformerConfig.preserveToolCalls) {
      openaiRequest.tools = this.convertTools(input.tools);

      if (input.tool_choice) {
        openaiRequest.tool_choice = this.convertToolChoice(input.tool_choice);
      }
    }

    // ğŸ” Transformerå±‚è¾“å‡ºæ—¥å¿—
    console.log(`ğŸ“¤ [Transformerå±‚] OpenAIè¯·æ±‚è½¬æ¢å®Œæˆ:`);
    console.log(`   ç›®æ ‡æ¨¡å‹: ${openaiRequest.model}`);
    console.log(`   æ¶ˆæ¯æ•°é‡: ${openaiRequest.messages?.length || 0}`);
    console.log(`   max_tokens: ${openaiRequest.max_tokens}`);
    console.log(`   temperature: ${openaiRequest.temperature}`);
    console.log(`   stream: ${openaiRequest.stream}`);
    console.log(`   å·¥å…·æ•°é‡: ${openaiRequest.tools?.length || 0}`);

    return openaiRequest;
  }

  /**
   * è½¬æ¢OpenAIå“åº”ä¸ºAnthropicæ ¼å¼
   */
  private convertResponseToAnthropic(openaiResponse: any): any {
    // å®‰å…¨æ£€æŸ¥ï¼šç¡®ä¿OpenAIå“åº”ç»“æ„å®Œæ•´
    if (
      !openaiResponse ||
      !openaiResponse.choices ||
      !Array.isArray(openaiResponse.choices) ||
      openaiResponse.choices.length === 0
    ) {
      throw new Error('OpenAIå“åº”æ ¼å¼æ— æ•ˆï¼šç¼ºå°‘choicesæ•°ç»„æˆ–choicesä¸ºç©º');
    }

    const choice = openaiResponse.choices[0];
    if (!choice || !choice.message) {
      throw new Error('OpenAIå“åº”æ ¼å¼æ— æ•ˆï¼šchoiceæˆ–messageç»“æ„ç¼ºå¤±');
    }

    const message = choice.message;

    // Anthropicå“åº”åŸºç¡€ç»“æ„
    const anthropicResponse: any = {
      id: openaiResponse.id,
      type: 'message',
      role: 'assistant',
      model: openaiResponse.model,
      content: [],
      stop_reason: this.convertStopReason(choice.finish_reason),
      stop_sequence: null,
      usage: {
        input_tokens: openaiResponse.usage.prompt_tokens,
        output_tokens: openaiResponse.usage.completion_tokens,
      },
    };

    // å¤„ç†æ–‡æœ¬å†…å®¹
    if (message.content) {
      anthropicResponse.content.push({
        type: 'text',
        text: message.content,
      });
    }

    // å¤„ç†å·¥å…·è°ƒç”¨
    if (message.tool_calls && Array.isArray(message.tool_calls)) {
      for (const toolCall of message.tool_calls) {
        anthropicResponse.content.push({
          type: 'tool_use',
          id: toolCall.id,
          name: toolCall.function.name,
          input: JSON.parse(toolCall.function.arguments || '{}'),
        });
      }
      anthropicResponse.stop_reason = 'tool_use';
    }

    console.log(`ğŸ”„ OpenAI â†’ Anthropicå“åº”è½¬æ¢å®Œæˆ`);
    return anthropicResponse;
  }

  /**
   * è½¬æ¢åœæ­¢åŸå› 
   */
  private convertStopReason(finishReason: string): string {
    switch (finishReason) {
      case 'stop':
        return 'end_turn';
      case 'length':
        return 'max_tokens';
      case 'tool_calls':
        return 'tool_use';
      case 'content_filter':
        return 'stop_sequence';
      default:
        return 'end_turn';
    }
  }

  /**
   * è½¬æ¢æ¶ˆæ¯æ ¼å¼
   */
  private convertMessages(messages: any[]): any[] {
    const convertedMessages: any[] = [];

    for (const message of messages) {
      const convertedMessage: any = {
        role: message.role,
        content: this.convertMessageContent(message.content),
      };

      // å¤„ç†åŠ©æ‰‹æ¶ˆæ¯ä¸­çš„tool_calls
      if (message.role === 'assistant' && message.content) {
        const toolCalls = this.extractToolCallsFromContent(message.content);
        if (toolCalls.length > 0) {
          convertedMessage.tool_calls = toolCalls;
        }
      }

      convertedMessages.push(convertedMessage);
    }

    return convertedMessages;
  }

  /**
   * è½¬æ¢æ¶ˆæ¯å†…å®¹
   */
  private convertMessageContent(content: any): any {
    if (typeof content === 'string') {
      return content;
    }

    if (Array.isArray(content)) {
      // å¯¹äºå¤æ‚å†…å®¹ï¼Œåˆå¹¶æ–‡æœ¬éƒ¨åˆ†ï¼Œå•ç‹¬å¤„ç†å·¥å…·è°ƒç”¨
      const textParts: string[] = [];

      for (const block of content) {
        if (block.type === 'text') {
          textParts.push(block.text);
        }
        // tool_use å’Œ tool_result ä¼šåœ¨å…¶ä»–åœ°æ–¹å¤„ç†
      }

      return textParts.join('\n').trim() || null;
    }

    return content;
  }

  /**
   * ä»Anthropicå†…å®¹ä¸­æå–å·¥å…·è°ƒç”¨
   */
  private extractToolCallsFromContent(content: any[]): any[] {
    if (!Array.isArray(content)) {
      return [];
    }

    const toolCalls: any[] = [];

    for (const block of content) {
      if (block.type === 'tool_use') {
        toolCalls.push({
          id: block.id,
          type: 'function',
          function: {
            name: block.name,
            arguments: JSON.stringify(block.input || {}),
          },
        });
      }
    }

    return toolCalls;
  }

  /**
   * è½¬æ¢å·¥å…·å®šä¹‰
   */
  private convertTools(tools: any[]): any[] {
    if (!tools || !Array.isArray(tools)) {
      return [];
    }
    return tools.map(tool => ({
      type: 'function',
      function: {
        name: tool.name,
        description: tool.description,
        parameters: tool.input_schema,
      },
    }));
  }

  /**
   * è½¬æ¢å·¥å…·é€‰æ‹©
   */
  private convertToolChoice(toolChoice: any): any {
    if (typeof toolChoice === 'string') {
      switch (toolChoice) {
        case 'auto':
          return 'auto';
        case 'none':
          return 'none';
        case 'required':
          return 'required';
        default:
          return 'auto';
      }
    }

    if (typeof toolChoice === 'object' && toolChoice.type === 'tool') {
      return {
        type: 'function',
        function: {
          name: toolChoice.name,
        },
      };
    }

    return 'auto';
  }
}
