/**
 * LM Studio Server Compatibility Module
 *
 * æŒ‰ç…§RCC v4.0æ¶æ„è§„èŒƒå®ç°çš„LM Studioå…¼å®¹æ€§æ¨¡å—
 * ä½œä¸ºServer-Compatibilityå±‚å¤„ç†LM Studioç‰¹å®šçš„OpenAI APIå˜ç§
 *
 * @author Jason Zhang
 */

import { ModuleInterface, ModuleStatus, ModuleType, ModuleMetrics } from '../../../interfaces/module/base-module';
import { EventEmitter } from 'events';
import { OpenAI } from 'openai';

/**
 * LM Studioé…ç½®æ¥å£
 */
export interface LMStudioCompatibilityConfig {
  baseUrl: string;
  apiKey?: string;
  timeout: number;
  maxRetries: number;
  retryDelay: number;
  models: string[];
  maxTokens?: Record<string, number>; // æ¯ä¸ªæ¨¡å‹çš„æœ€å¤§tokené™åˆ¶
}

/**
 * æ ‡å‡†åè®®è¯·æ±‚æ¥å£ï¼ˆOpenAIæ ¼å¼ï¼‰
 */
export interface StandardRequest {
  model: string;
  messages: Array<{
    role: 'system' | 'user' | 'assistant' | 'tool';
    content: string;
    name?: string;
    tool_call_id?: string;
  }>;
  max_tokens?: number;
  temperature?: number;
  top_p?: number;
  frequency_penalty?: number;
  presence_penalty?: number;
  stop?: string | string[];
  stream?: boolean;
  tools?: Array<{
    type: 'function';
    function: {
      name: string;
      description: string;
      parameters: any;
    };
  }>;
  tool_choice?: 'none' | 'auto' | 'required' | { type: 'function'; function: { name: string } };
}

/**
 * LM Studioç‰¹å®šè¯·æ±‚æ ¼å¼
 */
export interface LMStudioRequest extends StandardRequest {
  // LM Studioå¯èƒ½æœ‰ä¸€äº›ç‰¹å®šçš„å‚æ•°
  top_k?: number;
  repeat_penalty?: number;
  system_prompt?: string;
}

/**
 * æ ‡å‡†åè®®å“åº”æ¥å£
 */
export interface StandardResponse {
  id: string;
  object: string;
  created: number;
  model: string;
  choices: Array<{
    index: number;
    message: {
      role: 'assistant';
      content?: string;
      tool_calls?: Array<{
        id: string;
        type: 'function';
        function: {
          name: string;
          arguments: string;
        };
      }>;
    };
    finish_reason: 'stop' | 'length' | 'tool_calls' | 'content_filter';
  }>;
  usage: {
    prompt_tokens: number;
    completion_tokens: number;
    total_tokens: number;
  };
}

/**
 * LM Studioç‰¹å®šå“åº”æ ¼å¼
 */
export interface LMStudioResponse extends StandardResponse {
  // LM Studioå¯èƒ½æœ‰é¢å¤–çš„å“åº”å­—æ®µ
  metadata?: {
    server_version?: string;
    model_path?: string;
  };
}

/**
 * LM Studio Server Compatibility Moduleå®ç°
 */
export class LMStudioCompatibilityModule extends EventEmitter implements ModuleInterface {
  private readonly id: string = 'lmstudio-compatibility';
  private readonly name: string = 'LM Studio Compatibility Module';
  private readonly type: any = 'server-compatibility';
  private readonly version: string = '1.0.0';
  private readonly config: LMStudioCompatibilityConfig;
  private openaiClient: OpenAI;
  private status: any = 'healthy';
  private isInitialized = false;

  constructor(config: LMStudioCompatibilityConfig) {
    super();
    this.config = config;

    // ä½¿ç”¨å®˜æ–¹OpenAI SDKè¿æ¥LM Studio
    this.openaiClient = new OpenAI({
      baseURL: config.baseUrl,
      apiKey: config.apiKey || 'lm-studio', // LM Studioé€šå¸¸ä¸éœ€è¦çœŸå®çš„API Key
      timeout: config.timeout,
    });

    console.log(`ğŸ”§ åˆå§‹åŒ–LM Studioå…¼å®¹æ¨¡å—: ${config.baseUrl}`);
  }

  // ModuleInterfaceå®ç°

  getId(): string {
    return this.id;
  }

  getName(): string {
    return this.name;
  }

  getType(): ModuleType {
    return this.type;
  }

  getVersion(): string {
    return this.version;
  }

  getStatus(): ModuleStatus {
    return {
      id: this.id,
      name: this.name,
      type: ModuleType.SERVER_COMPATIBILITY,
      status: 'running',
      health: this.status,
    };
  }

  /**
   * åˆå§‹åŒ–æ¨¡å—
   */
  async initialize(): Promise<void> {
    if (this.isInitialized) {
      return;
    }

    console.log(`ğŸš€ åˆå§‹åŒ–LM Studioå…¼å®¹æ¨¡å—...`);
    console.log(`   ç«¯ç‚¹: ${this.config.baseUrl}`);
    console.log(`   æ”¯æŒæ¨¡å‹: ${this.config.models.join(', ')}`);

    try {
      // æµ‹è¯•è¿æ¥LM Studio
      await this.testConnection();

      this.status = 'healthy';
      this.isInitialized = true;

      this.emit('statusChanged', { health: this.status });
      console.log(`âœ… LM Studioå…¼å®¹æ¨¡å—åˆå§‹åŒ–å®Œæˆ`);
    } catch (error) {
      this.status = 'unhealthy';
      this.emit('statusChanged', { health: this.status });
      console.error(`âŒ LM Studioå…¼å®¹æ¨¡å—åˆå§‹åŒ–å¤±è´¥:`, error.message);
      throw error;
    }
  }

  /**
   * å¯åŠ¨æ¨¡å—
   */
  async start(): Promise<void> {
    if (!this.isInitialized) {
      await this.initialize();
    }
    console.log(`â–¶ï¸ LM Studioå…¼å®¹æ¨¡å—å·²å¯åŠ¨`);
  }

  /**
   * åœæ­¢æ¨¡å—
   */
  async stop(): Promise<void> {
    this.status = 'unhealthy';
    this.emit('statusChanged', { health: this.status });
    console.log(`â¹ï¸ LM Studioå…¼å®¹æ¨¡å—å·²åœæ­¢`);
  }

  /**
   * å¤„ç†è¯·æ±‚ - æ ¸å¿ƒåŠŸèƒ½
   * å°†æ ‡å‡†OpenAIåè®®è¯·æ±‚é€‚é…ä¸ºLM Studioå…¼å®¹æ ¼å¼ï¼Œä½†ä»è¿”å›è¯·æ±‚æ ¼å¼ç»™ä¸‹ä¸€å±‚
   */
  async process(input: StandardRequest): Promise<StandardRequest> {
    if (!this.isInitialized) {
      throw new Error('LM Studioå…¼å®¹æ¨¡å—æœªåˆå§‹åŒ–');
    }

    const startTime = Date.now();
    console.log(`ğŸ”„ LM Studioå…¼å®¹å¤„ç†: ${input.model}`);

    try {
      // éªŒè¯è¾“å…¥
      this.validateStandardRequest(input);

      // é€‚é…è¯·æ±‚ä»¥ç¡®ä¿LM Studioå…¼å®¹æ€§
      const adaptedRequest = this.adaptRequestForLMStudio(input);

      const processingTime = Date.now() - startTime;
      console.log(`âœ… LM Studioå…¼å®¹å¤„ç†å®Œæˆ (${processingTime}ms)`);

      this.emit('requestProcessed', {
        processingTime,
        success: true,
        model: input.model,
      });

      // è¿”å›é€‚é…åçš„è¯·æ±‚æ ¼å¼ï¼Œè®©Serverå±‚è´Ÿè´£å®é™…APIè°ƒç”¨
      return adaptedRequest;
    } catch (error) {
      const processingTime = Date.now() - startTime;
      console.error(`âŒ LM Studioå…¼å®¹å¤„ç†å¤±è´¥ (${processingTime}ms):`, error.message);

      this.emit('requestProcessed', {
        processingTime,
        success: false,
        error: error.message,
        model: input.model,
      });

      throw error;
    }
  }

  /**
   * é€‚é…è¯·æ±‚ä»¥ç¡®ä¿LM Studioå…¼å®¹æ€§
   */
  private adaptRequestForLMStudio(input: StandardRequest): StandardRequest {
    // åº”ç”¨max_tokensé™åˆ¶
    const modelMaxTokens = this.getModelMaxTokens(input.model);

    // å…‹éš†è¾“å…¥ä»¥é¿å…ä¿®æ”¹åŸå§‹å¯¹è±¡
    const adaptedRequest: StandardRequest = {
      ...input,
      max_tokens: Math.min(input.max_tokens || modelMaxTokens, modelMaxTokens),
    };

    // ç¡®ä¿messagesæ ¼å¼æ­£ç¡®
    if (adaptedRequest.messages && Array.isArray(adaptedRequest.messages)) {
      adaptedRequest.messages = adaptedRequest.messages.filter(msg => {
        // å®‰å…¨æ£€æŸ¥ï¼šç¡®ä¿msgå¯¹è±¡å­˜åœ¨ä¸”ä¸ä¸ºnull/undefined
        if (!msg || typeof msg !== 'object') {
          return false;
        }
        return msg.content && typeof msg.content === 'string' && msg.content.trim() && msg.role;
      });
    } else {
      // å¦‚æœmessagesä¸æ˜¯æ•°ç»„ï¼Œåˆå§‹åŒ–ä¸ºç©ºæ•°ç»„
      adaptedRequest.messages = [];
    }

    console.log(
      `ğŸ”§ LM Studioé€‚é…å®Œæˆ: max_tokens=${adaptedRequest.max_tokens}, messages=${adaptedRequest.messages?.length || 0}`
    );
    return adaptedRequest;
  }

  /**
   * éªŒè¯æ ‡å‡†åè®®è¯·æ±‚
   */
  private validateStandardRequest(request: StandardRequest): void {
    if (!request.model) {
      throw new Error('ç¼ºå°‘modelå‚æ•°');
    }

    if (!request.messages || !Array.isArray(request.messages) || request.messages.length === 0) {
      throw new Error('ç¼ºå°‘messageså‚æ•°æˆ–æ ¼å¼æ— æ•ˆ');
    }

    // æ£€æŸ¥æ¨¡å‹æ˜¯å¦æ”¯æŒ
    if (!this.config.models.includes(request.model)) {
      throw new Error(`æ¨¡å‹ ${request.model} ä¸åœ¨æ”¯æŒåˆ—è¡¨ä¸­: ${this.config.models.join(', ')}`);
    }
  }

  /**
   * æ ‡å‡†åè®® â†’ LM Studioç‰¹å®šæ ¼å¼
   */
  private adaptRequest(standardRequest: StandardRequest): LMStudioRequest {
    const lmstudioRequest: LMStudioRequest = {
      ...standardRequest,
    };

    // LM Studioç‰¹å®šçš„å‚æ•°æ˜ å°„
    if (standardRequest.temperature !== undefined) {
      // LM Studioå¯èƒ½å¯¹temperatureæœ‰ç‰¹å®šçš„èŒƒå›´è¦æ±‚
      lmstudioRequest.temperature = Math.max(0.01, Math.min(2.0, standardRequest.temperature));
    }

    // å¦‚æœæœ‰ç³»ç»Ÿæ¶ˆæ¯ï¼Œå¯èƒ½éœ€è¦ç‰¹æ®Šå¤„ç†
    const systemMessage = standardRequest.messages.find(m => m.role === 'system');
    if (systemMessage) {
      lmstudioRequest.system_prompt = systemMessage.content;
    }

    return lmstudioRequest;
  }

  /**
   * ä»é…ç½®æ–‡ä»¶è·å–æ¨¡å‹çš„æœ€å¤§è¾“å‡ºtokené™åˆ¶
   */
  private getModelMaxTokens(model: string): number {
    // ä»é…ç½®ä¸­è·å–æ¨¡å‹çš„maxTokensè®¾ç½®
    if (this.config && this.config.maxTokens && this.config.maxTokens[model]) {
      // ä½¿ç”¨ä¿å®ˆçš„è¾“å‡ºtokené™åˆ¶ï¼Œçº¦ä¸ºæ€»ä¸Šä¸‹æ–‡çš„1/4ï¼Œç¡®ä¿ä¸è¶…é™
      const contextLimit = this.config.maxTokens[model];
      return Math.min(contextLimit / 4, 4096); // æœ€å¤§4096è¾“å‡ºtokens
    }

    // å¦‚æœé…ç½®ä¸­æ²¡æœ‰æ‰¾åˆ°ï¼Œä½¿ç”¨ä¿å®ˆçš„é»˜è®¤å€¼
    return 1024;
  }

  /**
   * è°ƒç”¨LM Studio APIï¼ˆä½¿ç”¨å®˜æ–¹OpenAI SDKï¼‰
   */
  private async callLMStudio(request: LMStudioRequest): Promise<LMStudioResponse> {
    try {
      if (request.stream) {
        // æµå¼å¤„ç†
        throw new Error('æµå¼å¤„ç†æš‚æœªå®ç°'); // TODO: å®ç°æµå¼å¤„ç†
      } else {
        // éæµå¼å¤„ç†
        // é™åˆ¶max_tokensé˜²æ­¢è¶…å‡ºLM Studioä¸Šä¸‹æ–‡é•¿åº¦
        const modelMaxTokens = this.getModelMaxTokens(request.model);
        const limitedMaxTokens = request.max_tokens ? Math.min(request.max_tokens, modelMaxTokens) : modelMaxTokens;

        const response = await this.openaiClient.chat.completions.create({
          model: request.model,
          messages: request.messages as any,
          max_tokens: limitedMaxTokens,
          temperature: request.temperature,
          top_p: request.top_p,
          frequency_penalty: request.frequency_penalty,
          presence_penalty: request.presence_penalty,
          stop: request.stop,
          tools: request.tools,
          tool_choice: request.tool_choice,
          stream: false,
        });

        return response as LMStudioResponse;
      }
    } catch (error) {
      if (error.name === 'APIError') {
        throw new Error(`LM Studio APIé”™è¯¯: ${error.message}`);
      } else if (error.name === 'APIConnectionError') {
        throw new Error(`LM Studioè¿æ¥é”™è¯¯: ${error.message}`);
      } else if (error.name === 'APITimeoutError') {
        throw new Error(`LM Studioè¯·æ±‚è¶…æ—¶: ${error.message}`);
      } else {
        throw new Error(`LM StudioæœªçŸ¥é”™è¯¯: ${error.message}`);
      }
    }
  }

  /**
   * LM Studioå“åº” â†’ æ ‡å‡†åè®®æ ¼å¼
   */
  private adaptResponse(lmstudioResponse: LMStudioResponse): StandardResponse {
    // LM Studioçš„å“åº”é€šå¸¸å·²ç»ç¬¦åˆOpenAIæ ‡å‡†ï¼Œä½†å¯èƒ½éœ€è¦ä¸€äº›æ¸…ç†
    const standardResponse: StandardResponse = {
      id: lmstudioResponse.id,
      object: lmstudioResponse.object,
      created: lmstudioResponse.created,
      model: lmstudioResponse.model,
      choices: lmstudioResponse.choices.map(choice => ({
        index: choice.index,
        message: {
          role: choice.message.role,
          content: choice.message.content,
          tool_calls: choice.message.tool_calls,
        },
        finish_reason: choice.finish_reason,
      })),
      usage: {
        prompt_tokens: lmstudioResponse.usage.prompt_tokens,
        completion_tokens: lmstudioResponse.usage.completion_tokens,
        total_tokens: lmstudioResponse.usage.total_tokens,
      },
    };

    return standardResponse;
  }

  /**
   * æµ‹è¯•ä¸LM Studioçš„è¿æ¥
   */
  private async testConnection(): Promise<void> {
    try {
      // è·å–æ¨¡å‹åˆ—è¡¨æ¥æµ‹è¯•è¿æ¥
      const models = await this.openaiClient.models.list();
      console.log(`ğŸ” æ£€æµ‹åˆ° ${models.data.length} ä¸ªLM Studioæ¨¡å‹`);

      if (models.data.length === 0) {
        throw new Error('LM Studioæ²¡æœ‰åŠ è½½ä»»ä½•æ¨¡å‹');
      }
    } catch (error) {
      throw new Error(`LM Studioè¿æ¥æµ‹è¯•å¤±è´¥: ${error.message}`);
    }
  }

  /**
   * å¥åº·æ£€æŸ¥
   */
  async healthCheck(): Promise<{ healthy: boolean; details: any }> {
    const startTime = Date.now();

    try {
      await this.testConnection();
      const responseTime = Date.now() - startTime;

      this.status = 'healthy';
      this.emit('statusChanged', { health: this.status });

      return { healthy: true, details: { responseTime } };
    } catch (error) {
      const responseTime = Date.now() - startTime;
      this.status = 'unhealthy';
      this.emit('statusChanged', { health: this.status });

      return { healthy: false, details: { responseTime, error: error.message } };
    }
  }

  /**
   * è·å–æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨
   */
  async getSupportedModels(): Promise<string[]> {
    try {
      const models = await this.openaiClient.models.list();
      return models.data.map(model => model.id);
    } catch (error) {
      console.warn('è·å–LM Studioæ¨¡å‹åˆ—è¡¨å¤±è´¥ï¼Œä½¿ç”¨é…ç½®ä¸­çš„æ¨¡å‹åˆ—è¡¨');
      return this.config.models;
    }
  }

  // Missing ModuleInterface methods
  getMetrics(): ModuleMetrics {
    return {
      requestsProcessed: 0,
      averageProcessingTime: 0,
      errorRate: 0,
      memoryUsage: 0,
      cpuUsage: 0,
    };
  }

  async configure(config: any): Promise<void> {
    // Configuration logic
  }

  async reset(): Promise<void> {
    // Reset logic
  }

  async cleanup(): Promise<void> {
    // Cleanup logic
  }
}
