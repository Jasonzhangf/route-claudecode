/**
 * âš ï¸ DEPRECATED - SECURITY VULNERABILITIES FOUND âš ï¸
 *
 * This transformer implementation has been deprecated due to critical security vulnerabilities
 * identified in the security audit report. DO NOT USE in production.
 *
 * Security Issues:
 * - Unsafe JSON parsing without try-catch (line 375)
 * - No input validation or boundary checks
 * - Resource consumption without limits
 * - Duplicate implementation causing inconsistencies
 * - Architecture layer violations (business logic in transformer)
 * - Missing authentication and authorization
 *
 * Migration Path:
 * Use SecureAnthropicToOpenAITransformer instead:
 * import { SecureAnthropicToOpenAITransformer } from '../../transformers/secure-anthropic-openai-transformer';
 *
 * @deprecated Use SecureAnthropicToOpenAITransformer instead
 * @security-risk HIGH - Multiple critical vulnerabilities
 * @author Jason Zhang
 */

import { ModuleInterface, ModuleStatus, ModuleType, ModuleMetrics } from '../../../interfaces/module/base-module';
import { EventEmitter } from 'events';

/**
 * Transformeré…ç½®æ¥å£
 */
export interface TransformerConfig {
  targetModel?: string; // ç›®æ ‡æ¨¡å‹åï¼Œç”±Routerå±‚ç¡®å®š
  model?: string;
  preserveToolCalls?: boolean;
  mapSystemMessage?: boolean;
  defaultMaxTokens?: number;
  apiMaxTokens?: number; // APIæä¾›å•†çš„æœ€å¤§tokené™åˆ¶ï¼ˆå¦‚ModelScopeçš„8192ï¼‰
  modelMaxTokens?: { [key: string]: number }; // å„æ¨¡å‹çš„æœ€å¤§tokené…ç½®
  modelMapping?: { [key: string]: string }; // æ¨¡å‹æ˜ å°„ä¿¡æ¯
}

/**
 * Anthropicè¯·æ±‚æ ¼å¼
 */
export interface AnthropicRequest {
  model: string;
  max_tokens: number;
  messages: Array<{
    role: 'user' | 'assistant';
    content:
      | string
      | Array<{
          type: 'text' | 'image';
          text?: string;
          source?: {
            type: 'base64';
            media_type: string;
            data: string;
          };
        }>;
  }>;
  temperature?: number;
  top_p?: number;
  top_k?: number;
  stop_sequences?: string[];
  stream?: boolean;
  system?: string;
  tools?: Array<{
    name: string;
    description: string;
    input_schema: any;
  }>;
}

/**
 * OpenAIåè®®è¯·æ±‚æ ¼å¼
 */
export interface OpenAIRequest {
  model: string;
  messages: Array<{
    role: 'system' | 'user' | 'assistant' | 'tool';
    content: string;
    name?: string;
    tool_call_id?: string;
  }>;
  max_tokens?: number;
  temperature?: number;
  top_p?: number;
  frequency_penalty?: number;
  presence_penalty?: number;
  stop?: string | string[];
  stream?: boolean;
  tools?: Array<{
    type: 'function';
    function: {
      name: string;
      description: string;
      parameters: any;
    };
  }>;
  tool_choice?: 'none' | 'auto' | 'required' | { type: 'function'; function: { name: string } };
}

/**
 * Anthropicå“åº”æ ¼å¼
 */
export interface AnthropicResponse {
  id: string;
  type: 'message';
  role: 'assistant';
  content: Array<{
    type: 'text' | 'tool_use';
    text?: string;
    id?: string;
    name?: string;
    input?: any;
  }>;
  model: string;
  stop_reason: 'end_turn' | 'max_tokens' | 'stop_sequence' | 'tool_use';
  stop_sequence?: string;
  usage: {
    input_tokens: number;
    output_tokens: number;
  };
}

/**
 * OpenAIåè®®å“åº”æ ¼å¼
 */
export interface OpenAIResponse {
  id: string;
  object: 'chat.completion';
  created: number;
  model: string;
  choices: Array<{
    index: number;
    message: {
      role: 'assistant';
      content?: string;
      tool_calls?: Array<{
        id: string;
        type: 'function';
        function: {
          name: string;
          arguments: string;
        };
      }>;
    };
    finish_reason: 'stop' | 'length' | 'tool_calls' | 'content_filter';
  }>;
  usage: {
    prompt_tokens: number;
    completion_tokens: number;
    total_tokens: number;
  };
}

/**
 * Anthropicåˆ°OpenAIè½¬æ¢å™¨æ¨¡å—
 */
export class AnthropicToOpenAITransformer extends EventEmitter implements ModuleInterface {
  private readonly id: string = 'anthropic-to-openai-transformer';
  private readonly name: string = 'Anthropic to OpenAI Transformer';
  private readonly type: any = 'transformer';
  private readonly version: string = '1.0.0';
  private status: ModuleStatus['health'] = 'healthy';
  private targetModel: string = ''; // ç›®æ ‡æ¨¡å‹å
  private transformerConfig: TransformerConfig;

  constructor(config?: TransformerConfig) {
    super();

    // è®¾ç½®é»˜è®¤é…ç½®
    this.transformerConfig = {
      model: 'gpt-3.5-turbo',
      preserveToolCalls: true,
      mapSystemMessage: true,
      defaultMaxTokens: 4096,
      apiMaxTokens: 8192,
      modelMaxTokens: {},
      modelMapping: {},
      ...config, // è¦†ç›–ä¼ å…¥çš„é…ç½®
    };

    if (this.transformerConfig.targetModel) {
      this.targetModel = this.transformerConfig.targetModel;
    }

    console.log(`ğŸ”„ åˆå§‹åŒ–Anthropicâ†’OpenAIè½¬æ¢å™¨æ¨¡å—`);
    console.log(`   ç›®æ ‡æ¨¡å‹: ${this.targetModel || 'æœªæŒ‡å®š'}`);
    console.log(`   APIæœ€å¤§tokens: ${this.transformerConfig.apiMaxTokens}`);
    console.log(`   é»˜è®¤tokens: ${this.transformerConfig.defaultMaxTokens}`);
    console.log(`   æ¨¡å‹é™åˆ¶é…ç½®: ${Object.keys(this.transformerConfig.modelMaxTokens || {}).length} ä¸ªæ¨¡å‹`);
  }

  // ç§»é™¤é‡å¤çš„ModuleInterfaceå®ç°

  // ç§»é™¤é‡å¤çš„æ–¹æ³•å®ç°ï¼Œä½¿ç”¨ä¸‹é¢çš„å®Œæ•´å®ç°

  /**
   * å¤„ç†è¯·æ±‚è½¬æ¢
   * æ”¯æŒåŒå‘è½¬æ¢ï¼šAnthropic â†’ OpenAI å’Œ OpenAI â†’ Anthropic
   *
   * æ³¨æ„ï¼šæœ¬æ¨¡å—åªè´Ÿè´£åè®®æ ¼å¼è½¬æ¢ï¼Œæ¨¡å‹æ˜ å°„ç”±Routerå±‚å®Œæˆ
   * ç›®æ ‡æ¨¡å‹åé€šè¿‡é…ç½®ä¼ å…¥ï¼Œç¡®ä¿èŒè´£åˆ†ç¦»
   */
  async process(input: AnthropicRequest | OpenAIResponse): Promise<OpenAIRequest | AnthropicResponse> {
    const startTime = Date.now();

    try {
      // åˆ¤æ–­è¾“å…¥ç±»å‹å¹¶æ‰§è¡Œç›¸åº”è½¬æ¢
      if (this.isAnthropicRequest(input)) {
        console.log(`ğŸ”„ è½¬æ¢Anthropicè¯·æ±‚ â†’ OpenAIæ ¼å¼`);
        const result = this.transformAnthropicToOpenAI(input as AnthropicRequest);
        const processingTime = Date.now() - startTime;
        console.log(`âœ… è¯·æ±‚è½¬æ¢å®Œæˆ (${processingTime}ms)`);
        return result;
      } else if (this.isOpenAIResponse(input)) {
        console.log(`ğŸ”„ è½¬æ¢OpenAIå“åº” â†’ Anthropicæ ¼å¼`);
        const result = this.transformOpenAIToAnthropic(input as OpenAIResponse);
        const processingTime = Date.now() - startTime;
        console.log(`âœ… å“åº”è½¬æ¢å®Œæˆ (${processingTime}ms)`);
        return result;
      } else {
        throw new Error('ä¸æ”¯æŒçš„è¾“å…¥æ ¼å¼');
      }
    } catch (error) {
      const processingTime = Date.now() - startTime;
      console.error(`âŒ è½¬æ¢å¤±è´¥ (${processingTime}ms):`, error.message);
      throw error;
    }
  }

  /**
   * åˆ¤æ–­æ˜¯å¦ä¸ºAnthropicè¯·æ±‚æ ¼å¼
   */
  private isAnthropicRequest(input: any): boolean {
    return (
      input &&
      typeof input.model === 'string' &&
      typeof input.max_tokens === 'number' &&
      Array.isArray(input.messages) &&
      input.messages.every((msg: any) => msg.role === 'user' || msg.role === 'assistant')
    );
  }

  /**
   * åˆ¤æ–­æ˜¯å¦ä¸ºOpenAIå“åº”æ ¼å¼
   */
  private isOpenAIResponse(input: any): boolean {
    return (
      input &&
      input.object === 'chat.completion' &&
      Array.isArray(input.choices) &&
      input.usage &&
      typeof input.usage.total_tokens === 'number'
    );
  }

  /**
   * Anthropicè¯·æ±‚ â†’ OpenAIè¯·æ±‚è½¬æ¢
   *
   * Transformeræ¨¡å—åªè´Ÿè´£åè®®æ ¼å¼è½¬æ¢ï¼Œæ¨¡å‹æ˜ å°„ç”±Routerå±‚å®Œæˆ
   * æœ¬æ¨¡å—ä½¿ç”¨Routerå±‚ç¡®å®šçš„ç›®æ ‡æ¨¡å‹åè¿›è¡Œè½¬æ¢
   */
  private transformAnthropicToOpenAI(anthropicRequest: AnthropicRequest): OpenAIRequest {
    // ä½¿ç”¨ç”±Routerå±‚ç¡®å®šçš„ç›®æ ‡æ¨¡å‹åï¼Œç¡®ä¿æ¨¡å‹æ˜ å°„åœ¨Routerå±‚å®Œæˆ
    const targetModel = this.targetModel || anthropicRequest.model;

    const openaiRequest: OpenAIRequest = {
      model: targetModel, // ä¼˜å…ˆä½¿ç”¨é…ç½®çš„ç›®æ ‡æ¨¡å‹ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨æºæ¨¡å‹ï¼ˆç”¨äºå‘åå…¼å®¹ï¼‰
      messages: [],
      temperature: anthropicRequest.temperature,
      top_p: anthropicRequest.top_p,
      stream: anthropicRequest.stream || false,
    };

    // æ™ºèƒ½max_tokenså¤„ç†
    if (anthropicRequest.max_tokens) {
      // ç”¨æˆ·æŒ‡å®šäº†max_tokensï¼Œéœ€è¦æ£€æŸ¥æ˜¯å¦è¶…å‡ºAPIé™åˆ¶
      openaiRequest.max_tokens = this.clampMaxTokens(anthropicRequest.max_tokens, targetModel);
    } else {
      // ç”¨æˆ·æœªæŒ‡å®šmax_tokensï¼Œä½¿ç”¨æ™ºèƒ½é»˜è®¤å€¼
      openaiRequest.max_tokens = this.getOptimalMaxTokens(targetModel);
    }

    // æ·»åŠ ç³»ç»Ÿæ¶ˆæ¯ï¼ˆå¦‚æœæœ‰ä¸”ä¸ä¸ºç©ºï¼‰
    if (anthropicRequest.system && typeof anthropicRequest.system === 'string' && anthropicRequest.system.trim()) {
      openaiRequest.messages.push({
        role: 'system',
        content: anthropicRequest.system,
      });
    }

    // è½¬æ¢æ¶ˆæ¯
    for (const message of anthropicRequest.messages) {
      if (typeof message.content === 'string') {
        // ç®€å•æ–‡æœ¬æ¶ˆæ¯ - ç¡®ä¿å†…å®¹ä¸ä¸ºç©º
        if (message.content && message.content.trim()) {
          openaiRequest.messages.push({
            role: message.role === 'user' ? 'user' : 'assistant',
            content: message.content,
          });
        }
      } else if (Array.isArray(message.content)) {
        // å¤šæ¨¡æ€æ¶ˆæ¯ - æå–æ–‡æœ¬å†…å®¹
        const textContent = message.content
          .filter(item => item && typeof item === 'object' && item.type === 'text' && item.text && item.text.trim())
          .map(item => item.text)
          .join('\n');

        // åªæœ‰åœ¨æœ‰æœ‰æ•ˆæ–‡æœ¬å†…å®¹æ—¶æ‰æ·»åŠ æ¶ˆæ¯
        if (textContent.trim()) {
          openaiRequest.messages.push({
            role: message.role === 'user' ? 'user' : 'assistant',
            content: textContent,
          });
        }
      }
    }

    // ç¡®ä¿è‡³å°‘æœ‰ä¸€æ¡æ¶ˆæ¯ï¼ˆé™¤äº†å¯èƒ½çš„ç³»ç»Ÿæ¶ˆæ¯ï¼‰
    const nonSystemMessages = openaiRequest.messages.filter(
      msg => msg && typeof msg === 'object' && msg.role !== 'system'
    );
    if (nonSystemMessages.length === 0) {
      // å¦‚æœæ²¡æœ‰æœ‰æ•ˆçš„ç”¨æˆ·æ¶ˆæ¯ï¼Œåˆ›å»ºä¸€ä¸ªé»˜è®¤æ¶ˆæ¯
      openaiRequest.messages.push({
        role: 'user',
        content: 'Hello', // ç®€å•çš„é»˜è®¤æ¶ˆæ¯
      });
    }

    // è½¬æ¢åœæ­¢åºåˆ—
    if (anthropicRequest.stop_sequences) {
      openaiRequest.stop = anthropicRequest.stop_sequences;
    }

    // è½¬æ¢å·¥å…·å®šä¹‰
    if (anthropicRequest.tools) {
      openaiRequest.tools = anthropicRequest.tools
        .filter(tool => tool && typeof tool === 'object' && tool.name) // è¿‡æ»¤æœ‰æ•ˆçš„tools
        .map(tool => ({
          type: 'function',
          function: {
            name: tool.name,
            description: tool.description,
            parameters: tool.input_schema,
          },
        }));
    }

    return openaiRequest;
  }

  /**
   * OpenAIå“åº” â†’ Anthropicå“åº”è½¬æ¢
   */
  private transformOpenAIToAnthropic(openaiResponse: OpenAIResponse): AnthropicResponse {
    const choice = openaiResponse.choices[0]; // å–ç¬¬ä¸€ä¸ªé€‰æ‹©

    const anthropicResponse: AnthropicResponse = {
      id: openaiResponse.id,
      type: 'message',
      role: 'assistant',
      content: [],
      model: openaiResponse.model, // ç›´æ¥ä½¿ç”¨æ¨¡å‹åï¼Œä¸è¿›è¡Œåå‘æ˜ å°„
      stop_reason: this.mapFinishReason(choice.finish_reason),
      usage: {
        input_tokens: openaiResponse.usage.prompt_tokens,
        output_tokens: openaiResponse.usage.completion_tokens,
      },
    };

    // è½¬æ¢æ¶ˆæ¯å†…å®¹
    if (choice.message.content) {
      anthropicResponse.content.push({
        type: 'text',
        text: choice.message.content,
      });
    }

    // è½¬æ¢å·¥å…·è°ƒç”¨
    if (choice.message.tool_calls) {
      for (const toolCall of choice.message.tool_calls) {
        anthropicResponse.content.push({
          type: 'tool_use',
          id: toolCall.id,
          name: toolCall.function.name,
          input: JSON.parse(toolCall.function.arguments),
        });
      }
    }

    return anthropicResponse;
  }

  /**
   * æ˜ å°„å®ŒæˆåŸå› 
   */
  private mapFinishReason(finishReason: string): AnthropicResponse['stop_reason'] {
    const reasonMapping: Record<string, AnthropicResponse['stop_reason']> = {
      stop: 'end_turn',
      length: 'max_tokens',
      tool_calls: 'tool_use',
      content_filter: 'end_turn',
    };

    return reasonMapping[finishReason] || 'end_turn';
  }

  /**
   * é™åˆ¶max_tokensåœ¨APIå…è®¸èŒƒå›´å†…
   */
  private clampMaxTokens(requestedTokens: number, targetModel: string): number {
    const apiLimit = this.transformerConfig.apiMaxTokens || 8192;
    const modelConfigLimit = this.getModelMaxTokensFromConfig(targetModel);

    // ä½¿ç”¨è¾ƒå°çš„é™åˆ¶å€¼
    const effectiveLimit = Math.min(apiLimit, modelConfigLimit);
    const clampedTokens = Math.min(requestedTokens, effectiveLimit);

    if (clampedTokens !== requestedTokens) {
      console.log(
        `ğŸ”§ [Transformer] max_tokensä»${requestedTokens}è°ƒæ•´åˆ°${clampedTokens} (APIé™åˆ¶: ${apiLimit}, æ¨¡å‹é™åˆ¶: ${modelConfigLimit})`
      );
    }

    return clampedTokens;
  }

  /**
   * è·å–æœ€ä¼˜çš„max_tokensé»˜è®¤å€¼
   */
  private getOptimalMaxTokens(targetModel: string): number {
    const apiLimit = this.transformerConfig.apiMaxTokens || 8192;
    const modelConfigLimit = this.getModelMaxTokensFromConfig(targetModel);
    const defaultLimit = this.transformerConfig.defaultMaxTokens || 4096;

    // é€‰æ‹©ä¸€ä¸ªå®‰å…¨çš„é»˜è®¤å€¼ï¼šAPIé™åˆ¶çš„ä¸€åŠï¼Œä½†ä¸è¶…è¿‡é…ç½®çš„é»˜è®¤å€¼
    const safeDefault = Math.min(
      Math.floor(apiLimit / 2), // APIé™åˆ¶çš„ä¸€åŠ
      modelConfigLimit, // æ¨¡å‹é…ç½®é™åˆ¶
      defaultLimit // é…ç½®çš„é»˜è®¤å€¼
    );

    console.log(
      `ğŸ¯ [Transformer] ä¸ºæ¨¡å‹${targetModel}é€‰æ‹©æœ€ä¼˜max_tokens: ${safeDefault} (API: ${apiLimit}, æ¨¡å‹: ${modelConfigLimit}, é»˜è®¤: ${defaultLimit})`
    );

    return safeDefault;
  }

  /**
   * ä»é…ç½®ä¸­è·å–æ¨¡å‹çš„æœ€å¤§tokené™åˆ¶
   */
  private getModelMaxTokensFromConfig(targetModel: string): number {
    if (this.transformerConfig.modelMaxTokens && this.transformerConfig.modelMaxTokens[targetModel]) {
      return this.transformerConfig.modelMaxTokens[targetModel];
    }

    // å¦‚æœé…ç½®ä¸­æ²¡æœ‰æ‰¾åˆ°ï¼Œè¿”å›ä¸€ä¸ªä¿å®ˆçš„é»˜è®¤å€¼
    return this.transformerConfig.apiMaxTokens || 8192;
  }

  /**
   * éªŒè¯Anthropicè¯·æ±‚æ ¼å¼
   */
  validateAnthropicRequest(request: AnthropicRequest): boolean {
    if (!request.model || typeof request.model !== 'string') {
      return false;
    }

    if (!request.max_tokens || typeof request.max_tokens !== 'number') {
      return false;
    }

    if (!Array.isArray(request.messages) || request.messages.length === 0) {
      return false;
    }

    return true;
  }

  /**
   * éªŒè¯OpenAIå“åº”æ ¼å¼
   */
  validateOpenAIResponse(response: OpenAIResponse): boolean {
    if (!response.id || typeof response.id !== 'string') {
      return false;
    }

    if (!Array.isArray(response.choices) || response.choices.length === 0) {
      return false;
    }

    if (!response.usage || typeof response.usage.total_tokens !== 'number') {
      return false;
    }

    return true;
  }

  // ModuleInterface å®ç°
  getId(): string {
    return this.id;
  }

  getName(): string {
    return this.name;
  }

  getType(): ModuleType {
    return ModuleType.TRANSFORMER;
  }

  getVersion(): string {
    return this.version;
  }

  getStatus(): ModuleStatus {
    return {
      id: this.id,
      name: this.name,
      type: ModuleType.TRANSFORMER,
      status: 'running',
      health: this.status,
    };
  }

  getMetrics(): ModuleMetrics {
    return {
      requestsProcessed: 0,
      averageProcessingTime: 0,
      errorRate: 0,
      memoryUsage: 0,
      cpuUsage: 0,
    };
  }

  async configure(config: TransformerConfig): Promise<void> {
    if (config && config.targetModel) {
      this.targetModel = config.targetModel;
      console.log(`ğŸ”§ Transformeré…ç½®æ›´æ–°: ç›®æ ‡æ¨¡å‹è®¾ç½®ä¸º ${this.targetModel}`);
    }
  }

  async start(): Promise<void> {
    // Start logic
  }

  async stop(): Promise<void> {
    // Stop logic
  }

  async reset(): Promise<void> {
    // Reset logic
  }

  async cleanup(): Promise<void> {
    // Cleanup logic
  }

  async healthCheck(): Promise<{ healthy: boolean; details: any }> {
    return { healthy: true, details: {} };
  }

  // ç§»é™¤é‡å¤çš„processæ–¹æ³•
}
