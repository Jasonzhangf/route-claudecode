/**
 * ç»Ÿä¸€è½¬æ¢OpenAI Client
 * åœ¨OpenAIæ ‡å‡†providerå±‚é¢å®ç°ç»Ÿä¸€è½¬æ¢å±‚ï¼š
 * 1. æ‰€æœ‰è¯·æ±‚ï¼ˆæµå¼/éæµå¼ï¼‰ç»Ÿä¸€è½¬ä¸ºéæµå¼å‘é€åˆ°ä¾›åº”å•†
 * 2. é›†ä¸­æ¨¡æ‹Ÿæµå¼å“åº”ï¼Œä¸å…·ä½“ä¾›åº”å•†æ— å…³
 * 3. ç»Ÿä¸€finish reasonè®°å½•ç‚¹ï¼Œé¿å…é‡å¤è®°å½•
 * 4. å®Œæ•´è®°å½•è½¬æ¢è·¯å¾„ï¼ˆæµæ°´çº¿æ¯ä¸ªæ¨¡å—ä¸€ä¸ªè®°å½•ç‚¹ï¼‰
 * 5. å®ç°transformeråçš„å¤„ç†å±‚guardæœºåˆ¶
 * Project owner: Jason Zhang
 */

import axios, { AxiosInstance } from 'axios';
import { BaseRequest, BaseResponse, Provider, ProviderConfig, ProviderError } from '@/types';
import { getLogger } from '@/logging';
interface TransformationStep {
  step: string;
  timestamp: number;
  data: any;
  status: 'success' | 'error';
  duration?: number;
}

interface ConversionContext {
  requestId: string;
  originalRequestType: 'streaming' | 'non-streaming';
  transformationSteps: TransformationStep[];
  startTime: number;
}

export class UnifiedConversionOpenAIClient implements Provider {
  public readonly name: string;
  public readonly type = 'openai';
  
  private httpClient: AxiosInstance;
  private endpoint: string;
  private apiKey: string;
  private logger: ReturnType<typeof getLogger>;
  private preprocessor: ReturnType<typeof getUnifiedPatchPreprocessor>;
  private consistencyValidator: ReturnType<typeof getConsistencyValidator>;

  constructor(public config: ProviderConfig, providerId: string, port?: number) {
    this.name = providerId;
    this.endpoint = config.endpoint;
    
    const credentials = config.authentication.credentials;
    const apiKey = credentials ? (credentials.apiKey || credentials.api_key) : '';
    this.apiKey = Array.isArray(apiKey) ? apiKey[0] : apiKey;
    
    if (!this.endpoint) {
      throw new Error(`OpenAI-compatible provider ${providerId} requires endpoint configuration`);
    }

    if (config.authentication.type !== 'none' && !this.apiKey) {
      throw new Error(`OpenAI-compatible provider ${providerId} requires API key configuration`);
    }

    // åˆå§‹åŒ–ç»„ä»¶
    this.logger = getLogger(port);
    this.preprocessor = getUnifiedPatchPreprocessor(port);
    this.consistencyValidator = getConsistencyValidator(port);

    this.httpClient = axios.create({
      baseURL: this.endpoint,
      timeout: 300000,
      headers: {
        'Content-Type': 'application/json',
        'User-Agent': 'claude-code-router/2.8.0',
        'Authorization': `Bearer ${this.apiKey}`
      }
    });
  }

  /**
   * ğŸ¯ æ ¸å¿ƒç»Ÿä¸€è½¬æ¢æ–¹æ³•ï¼šå°†æ‰€æœ‰è¯·æ±‚è½¬ä¸ºéæµå¼å‘é€
   * æ— è®ºåŸå§‹è¯·æ±‚æ˜¯æµå¼è¿˜æ˜¯éæµå¼ï¼Œéƒ½ç»Ÿä¸€è½¬æ¢ä¸ºéæµå¼å‘é€
   */
  async sendRequest(request: BaseRequest): Promise<BaseResponse> {
    const context = this.createConversionContext(request, 'non-streaming');
    
    try {
      // ğŸ”„ Step 1: é¢„å¤„ç†è½¬æ¢
      const preprocessedRequest = await this.applyPreprocessing(request, context);
      
      // ğŸ”„ Step 2: ç»Ÿä¸€è½¬æ¢ä¸ºéæµå¼OpenAIæ ¼å¼
      const openaiRequest = await this.convertToUnifiedNonStreaming(preprocessedRequest, context);
      
      // ğŸ”„ Step 3: å‘é€éæµå¼è¯·æ±‚åˆ°ä¾›åº”å•†
      const rawResponse = await this.sendNonStreamingRequest(openaiRequest, context);
      
      // ğŸ”„ Step 4: Post-processing and consistency validation
      const processedResponse = await this.applyPostprocessing(rawResponse, context);
      
      // ğŸ”„ Step 5: ç»Ÿä¸€finish reasonè®°å½•
      this.recordUnifiedFinishReason(processedResponse, context);
      
      return processedResponse;

    } catch (error) {
      this.recordTransformationError(error, context);
      throw error;
    } finally {
      this.logTransformationSummary(context);
    }
  }

  /**
   * ğŸ¯ ç»Ÿä¸€æµå¼å“åº”å¤„ç†ï¼šé›†ä¸­æ¨¡æ‹Ÿæµå¼å“åº”
   * å°†éæµå¼å“åº”æ¨¡æ‹Ÿä¸ºæµå¼å“åº”ï¼Œä¸å…·ä½“ä¾›åº”å•†æ— å…³
   */
  async *sendStreamRequest(request: BaseRequest): AsyncIterable<any> {
    const context = this.createConversionContext(request, 'streaming');
    
    try {
      // ğŸ”„ Step 1: ç»Ÿä¸€è½¬æ¢ - æ‰€æœ‰æµå¼è¯·æ±‚éƒ½è½¬ä¸ºéæµå¼å‘é€
      const nonStreamingResponse = await this.sendRequest({
        ...request,
        stream: false // å¼ºåˆ¶è½¬æ¢ä¸ºéæµå¼
      });
      
      // ğŸ”„ Step 2: é›†ä¸­æ¨¡æ‹Ÿæµå¼å“åº”
      yield* this.simulateStreamingResponse(nonStreamingResponse, context);
      
    } catch (error) {
      this.recordTransformationError(error, context);
      // æµå¼é”™è¯¯ä¹Ÿè¦æ¨¡æ‹Ÿä¸ºæµå¼æ ¼å¼
      yield this.createErrorStreamChunk(error, context);
    } finally {
      this.logTransformationSummary(context);
    }
  }

  /**
   * åˆ›å»ºè½¬æ¢ä¸Šä¸‹æ–‡
   */
  private createConversionContext(request: BaseRequest, type: 'streaming' | 'non-streaming'): ConversionContext {
    return {
      requestId: request.metadata?.requestId || `req_${Date.now()}`,
      originalRequestType: type,
      transformationSteps: [],
      startTime: Date.now()
    };
  }

  /**
   * ğŸ”„ Step 1: é¢„å¤„ç†è½¬æ¢
   */
  private async applyPreprocessing(request: BaseRequest, context: ConversionContext): Promise<BaseRequest> {
    const stepStart = Date.now();
    
    try {
      const preprocessedRequest = await this.preprocessor.preprocessInput(
        request,
        'openai-compatible' as any,
        request.model,
        context.requestId
      );

      this.recordTransformationStep(context, 'preprocessing', {
        originalRequest: this.sanitizeForLog(request),
        preprocessedRequest: this.sanitizeForLog(preprocessedRequest)
      }, 'success', Date.now() - stepStart);

      return preprocessedRequest;
    } catch (error) {
      this.recordTransformationStep(context, 'preprocessing', {
        error: error instanceof Error ? error.message : String(error)
      }, 'error', Date.now() - stepStart);
      throw error;
    }
  }

  /**
   * ğŸ”„ Step 2: ç»Ÿä¸€è½¬æ¢ä¸ºéæµå¼OpenAIæ ¼å¼
   */
  private async convertToUnifiedNonStreaming(request: BaseRequest, context: ConversionContext): Promise<any> {
    const stepStart = Date.now();
    
    try {
      const openaiRequest = {
        model: request.model,
        messages: this.convertMessages(request.messages),
        max_tokens: request.max_tokens || 131072,
        temperature: request.temperature,
        stream: false // ğŸ¯ æ ¸å¿ƒï¼šç»Ÿä¸€å¼ºåˆ¶è®¾ç½®ä¸ºéæµå¼
      };

      // Add system message if present
      if (request.system) {
        const systemContent = Array.isArray(request.system) 
          ? request.system.map((s: any) => s.text || s).join('\n')
          : request.system;
        openaiRequest.messages.unshift({
          role: 'system',
          content: systemContent
        });
      }

      // Add tools if present - check multiple sources
      const tools = request.tools || request.metadata?.tools;
      if (tools && Array.isArray(tools)) {
        (openaiRequest as any).tools = tools.map((tool: any) => ({
          type: 'function',
          function: {
            name: tool.name,
            description: tool.description,
            parameters: tool.input_schema
          }
        }));
        
        this.logger.debug('ğŸ› ï¸ Tools converted for OpenAI', {
          toolCount: tools.length,
          toolNames: tools.map((t: any) => t.name),
          requestId: context.requestId
        });
      } else {
        this.logger.debug('ğŸš« No tools found in request', {
          hasTools: !!request.tools,
          hasMetadataTools: !!request.metadata?.tools,
          requestId: context.requestId
        });
      }

      this.recordTransformationStep(context, 'conversion', {
        inputFormat: 'anthropic',
        outputFormat: 'openai-non-streaming',
        streamForced: false,
        toolCount: tools?.length || 0,
        hasTools: !!(tools && tools.length > 0)
      }, 'success', Date.now() - stepStart);

      return openaiRequest;
    } catch (error) {
      this.recordTransformationStep(context, 'conversion', {
        error: error instanceof Error ? error.message : String(error)
      }, 'error', Date.now() - stepStart);
      throw error;
    }
  }

  /**
   * ğŸ”„ Step 3: å‘é€éæµå¼è¯·æ±‚åˆ°ä¾›åº”å•†
   */
  private async sendNonStreamingRequest(openaiRequest: any, context: ConversionContext): Promise<any> {
    const stepStart = Date.now();
    
    try {
      this.logger.debug('ğŸ“¤ Sending request to provider', {
        provider: this.name,
        model: openaiRequest.model,
        hasTools: !!openaiRequest.tools,
        toolCount: openaiRequest.tools?.length || 0,
        requestId: context.requestId
      });

      const response = await this.httpClient.post('', openaiRequest);
      
      // è¯¦ç»†æ£€æŸ¥å“åº”
      const responseData = response.data;
      const firstChoice = responseData?.choices?.[0];
      const hasToolCalls = !!(firstChoice?.message?.tool_calls);
      
      this.logger.debug('ğŸ“¥ Received response from provider', {
        provider: this.name,
        statusCode: response.status,
        hasChoices: !!responseData?.choices,
        choiceCount: responseData?.choices?.length || 0,
        hasToolCalls,
        toolCallCount: firstChoice?.message?.tool_calls?.length || 0,
        finishReason: firstChoice?.finish_reason,
        requestId: context.requestId
      });
      
      // ğŸ” Debug: è¯¦ç»†è®°å½•åŸå§‹å“åº”ä¿¡æ¯
      this.logger.debug('ğŸ” Raw OpenAI response analysis', {
        rawFinishReason: firstChoice?.finish_reason,
        messageContent: firstChoice?.message?.content?.substring(0, 100),
        toolCalls: firstChoice?.message?.tool_calls?.map((tc: any) => ({ 
          id: tc.id, 
          name: tc.function?.name, 
          args_preview: tc.function?.arguments?.substring(0, 50) 
        })),
        requestId: context.requestId
      });
      
      this.recordTransformationStep(context, 'provider-request', {
        provider: this.name,
        model: openaiRequest.model,
        statusCode: response.status,
        hasChoices: !!responseData?.choices,
        choiceCount: responseData?.choices?.length || 0,
        hasToolCalls,
        toolCallCount: firstChoice?.message?.tool_calls?.length || 0,
        finishReason: firstChoice?.finish_reason
      }, 'success', Date.now() - stepStart);

      return responseData;
    } catch (error) {
      this.recordTransformationStep(context, 'provider-request', {
        provider: this.name,
        error: error instanceof Error ? error.message : String(error),
        status: (error as any)?.response?.status
      }, 'error', Date.now() - stepStart);
      throw error;
    }
  }

   /**
   * Step 4: Post-processing and consistency validation
   */
  private async applyPostprocessing(rawResponse: any, context: ConversionContext): Promise<BaseResponse> {
    const stepStart = Date.now();
    
    // åªåœ¨è¿™ä¸€ä¸ªåœ°æ–¹è®°å½•finish reasonï¼Œé¿å…é‡å¤è®°å½•
    this.logger.logFinishReason(response.stop_reason || 'unknown', {
      provider: this.name,
      model: response.model || 'unknown',
      responseType: context.originalRequestType,
      transformationSteps: context.transformationSteps.length,
      totalDuration: Date.now() - context.startTime,
      action: 'unified-recording',
      toolCount: this.countToolUse(response)
    }, context.requestId, 'unified-conversion');

    this.recordTransformationStep(context, 'finish-reason-recording', {
      finishReason: response.stop_reason,
      unifiedPoint: true,
      avoidedDuplication: true
    }, 'success', Date.now() - stepStart);
  }

  /**
   * ğŸ¯ é›†ä¸­æ¨¡æ‹Ÿæµå¼å“åº”
   */
  private async *simulateStreamingResponse(response: BaseResponse, context: ConversionContext): AsyncIterable<any> {
    const stepStart = Date.now();
    
    try {
      // å‘é€å¼€å§‹äº‹ä»¶
      yield {
        event: 'message_start',
        data: {
          type: 'message_start',
          message: {
            id: context.requestId,
            type: 'message',
            role: 'assistant',
            content: [],
            model: response.model,
            stop_reason: null,
            stop_sequence: null,
            usage: response.usage
          }
        }
      };

      // æ¨¡æ‹Ÿå†…å®¹å—
      if (response.content && Array.isArray(response.content)) {
        for (let i = 0; i < response.content.length; i++) {
          const block: any = response.content[i];
          
          // å†…å®¹å—å¼€å§‹
          yield {
            event: 'content_block_start',
            data: {
              type: 'content_block_start',
              index: i,
              content_block: block
            }
          };

          // æ¨¡æ‹Ÿæ–‡æœ¬å¢é‡
          if (block.type === 'text' && block.text) {
            const text = block.text;
            const chunkSize = Math.max(1, Math.floor(text.length / 10)); // åˆ†æˆ10ä¸ªå—
            
            for (let j = 0; j < text.length; j += chunkSize) {
              const chunk = text.slice(j, Math.min(j + chunkSize, text.length));
              yield {
                event: 'content_block_delta',
                data: {
                  type: 'content_block_delta',
                  index: i,
                  delta: { type: 'text_delta', text: chunk }
                }
              };
              // æ¨¡æ‹Ÿç½‘ç»œå»¶è¿Ÿ
              await this.sleep(50);
            }
          }

          // å†…å®¹å—ç»“æŸ
          yield {
            event: 'content_block_stop',
            data: {
              type: 'content_block_stop',
              index: i
            }
          };
        }
      }

      // å‘é€ç»“æŸäº‹ä»¶
      yield {
        event: 'message_delta',
        data: {
          type: 'message_delta',
          delta: { stop_reason: response.stop_reason },
          usage: response.usage
        }
      };

      yield {
        event: 'message_stop',
        data: { type: 'message_stop' }
      };

      this.recordTransformationStep(context, 'streaming-simulation', {
        originalResponseType: 'non-streaming',
        simulatedAsStreaming: true,
        blockCount: response.content?.length || 0,
        finalStopReason: response.stop_reason
      }, 'success', Date.now() - stepStart);

    } catch (error) {
      this.recordTransformationStep(context, 'streaming-simulation', {
        error: error instanceof Error ? error.message : String(error)
      }, 'error', Date.now() - stepStart);
      throw error;
    }
  }

  /**
   * è½¬æ¢æ¶ˆæ¯æ ¼å¼
   */
  private convertMessages(messages: any[]): any[] {
    return messages.map(msg => ({
      role: msg.role,
      content: typeof msg.content === 'string' ? msg.content : 
               Array.isArray(msg.content) ? msg.content.map((block: any) => 
                 block.type === 'text' ? block.text : block
               ).join('') : msg.content
    }));
  }

  /**
   * è½¬æ¢ä¸ºAnthropicå“åº”æ ¼å¼
   */
  private convertToAnthropicResponse(openaiResponse: any, context: ConversionContext): any {
    if (!openaiResponse.choices || !openaiResponse.choices[0]) {
      throw new Error('Invalid OpenAI response: missing choices');
    }

    const choice = openaiResponse.choices[0];
    const message = choice.message;

    this.logger.debug('ğŸ”„ Converting OpenAI response to Anthropic format', {
      hasContent: !!message.content,
      hasToolCalls: !!message.tool_calls,
      toolCallCount: message.tool_calls?.length || 0,
      finishReason: choice.finish_reason,
      requestId: context.requestId
    });

    // æ„å»ºå†…å®¹å—
    const content: any[] = [];
    
    if (message.content) {
      content.push({
        type: 'text',
        text: message.content
      });
      this.logger.debug('ğŸ“„ Added text content block', {
        textLength: message.content.length,
        requestId: context.requestId
      });
    }

    if (message.tool_calls) {
      message.tool_calls.forEach((toolCall: any, index: number) => {
        try {
          const input = JSON.parse(toolCall.function.arguments || '{}');
          content.push({
            type: 'tool_use',
            id: toolCall.id,
            name: toolCall.function.name,
            input: input
          });
          
          this.logger.debug(`ğŸ› ï¸ Added tool_use block ${index + 1}`, {
            toolName: toolCall.function.name,
            toolId: toolCall.id,
            hasArguments: !!toolCall.function.arguments,
            requestId: context.requestId
          });
        } catch (parseError) {
          this.logger.error('âŒ Failed to parse tool arguments', {
            toolName: toolCall.function.name,
            toolId: toolCall.id,
            arguments: toolCall.function.arguments,
            error: parseError instanceof Error ? parseError.message : String(parseError),
            requestId: context.requestId
          });
          
          // ä½¿ç”¨ç©ºå¯¹è±¡ä½œä¸ºfallback
          content.push({
            type: 'tool_use',
            id: toolCall.id,
            name: toolCall.function.name,
            input: {}
          });
        }
      });
    }

    return {
      id: openaiResponse.id || context.requestId,
      type: 'message',
      role: 'assistant',
      content,
      model: openaiResponse.model || 'unknown',
      stop_reason: this.preserveOriginalFinishReason(choice.finish_reason),
      stop_sequence: null,
      usage: {
        input_tokens: openaiResponse.usage?.prompt_tokens || 0,
        output_tokens: openaiResponse.usage?.completion_tokens || 0
      }
    };
  }

  /**
   * ä¿æŒåŸå§‹OpenAI finish_reasonï¼Œè®©é¢„å¤„ç†å™¨å¤„ç†æ˜ å°„
   * ğŸ¯ å…³é”®ä¿®å¤ï¼šä¸åœ¨è¿™é‡Œè¿›è¡Œæ˜ å°„ï¼Œé¿å…ä¸é¢„å¤„ç†å™¨å†²çª
   */
  private preserveOriginalFinishReason(finishReason: string): string {
    // ç›´æ¥è¿”å›åŸå§‹çš„finish_reasonï¼Œè®©é¢„å¤„ç†å™¨é“¾å¤„ç†è½¬æ¢
    return finishReason;
  }

  /**
   * è®¡ç®—å·¥å…·ä½¿ç”¨æ•°é‡
   */
  private countToolUse(response: BaseResponse): number {
    if (!response.content || !Array.isArray(response.content)) {
      return 0;
    }
    return response.content.filter(block => block.type === 'tool_use').length;
  }

  /**
   * è®°å½•è½¬æ¢æ­¥éª¤
   */
  private recordTransformationStep(
    context: ConversionContext,
    step: string,
    data: any,
    status: 'success' | 'error',
    duration?: number
  ): void {
    context.transformationSteps.push({
      step,
      timestamp: Date.now(),
      data,
      status,
      duration
    });
  }

  /**
   * è®°å½•è½¬æ¢é”™è¯¯
   */
  private recordTransformationError(error: any, context: ConversionContext): void {
    this.logger.error(`Unified conversion error at step`, {
      error: error instanceof Error ? error.message : String(error),
      requestId: context.requestId,
      step: context.transformationSteps.length + 1,
      totalSteps: context.transformationSteps.length
    }, context.requestId, 'unified-conversion');
  }

  /**
   * è®°å½•è½¬æ¢è·¯å¾„æ€»ç»“
   */
  private logTransformationSummary(context: ConversionContext): void {
    const totalDuration = Date.now() - context.startTime;
    const successSteps = context.transformationSteps.filter(s => s.status === 'success').length;
    const errorSteps = context.transformationSteps.filter(s => s.status === 'error').length;

    this.logger.info('ğŸ”„ Unified conversion pipeline completed', {
      requestId: context.requestId,
      originalType: context.originalRequestType,
      totalDuration,
      totalSteps: context.transformationSteps.length,
      successSteps,
      errorSteps,
      pipeline: context.transformationSteps.map(s => ({
        step: s.step,
        status: s.status,
        duration: s.duration
      }))
    }, context.requestId, 'unified-conversion-summary');
  }

  /**
   * åˆ›å»ºé”™è¯¯æµå¼å—
   */
  private createErrorStreamChunk(error: any, context: ConversionContext): any {
    return {
      event: 'error',
      data: {
        type: 'error',
        error: {
          type: 'api_error',
          message: error instanceof Error ? error.message : String(error)
        }
      }
    };
  }

  /**
   * æ¸…ç†æ—¥å¿—æ•°æ®
   */
  private sanitizeForLog(data: any): any {
    const sanitized = { ...data };
    if (sanitized.metadata?.apiKey) delete sanitized.metadata.apiKey;
    if (sanitized.apiKey) delete sanitized.apiKey;
    return sanitized;
  }

  /**
   * ç¡çœ å·¥å…·å‡½æ•°
   */
  private sleep(ms: number): Promise<void> {
    return new Promise(resolve => setTimeout(resolve, ms));
  }

  /**
   * å¥åº·æ£€æŸ¥
   */
  async isHealthy(): Promise<boolean> {
    try {
      const response = await this.httpClient.get('/models', { timeout: 5000 });
      return response.status === 200;
    } catch {
      return false;
    }
  }
}