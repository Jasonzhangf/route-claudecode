/**
 * ç»Ÿä¸€å…¼å®¹æ€§é¢„å¤„ç†å™¨
 * å°†æ‰€æœ‰AIæœåŠ¡çš„å…¼å®¹æ€§å¤„ç†é€»è¾‘æ•´åˆåˆ°é¢„å¤„ç†é˜¶æ®µ
 * æ›¿ä»£åŸæœ‰çš„è¡¥ä¸ç³»ç»Ÿï¼Œæä¾›æ›´æ¸…æ™°çš„æ¶æ„
 */

import { getLogger } from '../logging';

interface PreprocessingContext {
  requestId: string;
  provider: string;
  model: string;
  stage: 'input' | 'response' | 'streaming';
  timestamp: number;
  metadata?: any;
}

export interface UnifiedCompatibilityConfig {
  enabled: boolean;
  debugMode: boolean;
  forceAllInputs: boolean;
  performanceTracking: boolean;
  cacheResults: boolean;
  validateFinishReason: boolean;
  strictFinishReasonValidation: boolean;
}

export class UnifiedCompatibilityPreprocessor {
  private logger: ReturnType<typeof getLogger>;
  private config: UnifiedCompatibilityConfig;
  private processedCache: Map<string, any> = new Map();
  private performanceMetrics = {
    totalProcessed: 0,
    totalDuration: 0,
    byStage: {
      input: { count: 0, duration: 0 },
      response: { count: 0, duration: 0 },
      streaming: { count: 0, duration: 0 }
    }
  };

  constructor(port?: number, config?: Partial<UnifiedCompatibilityConfig>) {
    this.config = {
      enabled: process.env.RCC_UNIFIED_PREPROCESSING !== 'false',
      debugMode: process.env.RCC_PREPROCESSING_DEBUG === 'true',
      forceAllInputs: process.env.RCC_FORCE_ALL_INPUTS === 'true',
      performanceTracking: true,
      cacheResults: process.env.RCC_CACHE_PREPROCESSING === 'true',
      validateFinishReason: true,
      strictFinishReasonValidation: process.env.RCC_STRICT_FINISH_REASON === 'true',
      ...config
    };

    this.logger = getLogger(port);

    if (this.config.debugMode) {
      this.logger.info('UnifiedCompatibilityPreprocessor initialized', {
        config: this.config,
        port
      });
    }
  }

  /**
   * ç»Ÿä¸€é¢„å¤„ç†å…¥å£ï¼šå¤„ç†è¾“å…¥é˜¶æ®µæ•°æ®
   */
  async preprocessInput(
    inputData: any,
    provider: string,
    model: string,
    requestId: string
  ): Promise<any> {
    const context: PreprocessingContext = {
      requestId,
      provider,
      model,
      stage: 'input',
      timestamp: Date.now(),
      metadata: inputData.metadata
    };

    return this.processWithUnifiedPipeline(inputData, context);
  }

  /**
   * ç»Ÿä¸€é¢„å¤„ç†å…¥å£ï¼šå¤„ç†å“åº”é˜¶æ®µæ•°æ®
   */
  async preprocessResponse(
    responseData: any,
    provider: string,
    model: string,
    requestId: string
  ): Promise<any> {
    const context: PreprocessingContext = {
      requestId,
      provider,
      model,
      stage: 'response',
      timestamp: Date.now(),
      metadata: responseData.metadata
    };

    return this.processWithUnifiedPipeline(responseData, context);
  }

  /**
   * ç»Ÿä¸€é¢„å¤„ç†å…¥å£ï¼šå¤„ç†æµå¼æ•°æ®å—
   */
  async preprocessStreaming(
    chunkData: any,
    provider: string,
    model: string,
    requestId: string
  ): Promise<any> {
    const context: PreprocessingContext = {
      requestId,
      provider,
      model,
      stage: 'streaming',
      timestamp: Date.now(),
      metadata: chunkData.metadata
    };

    return this.processWithUnifiedPipeline(chunkData, context);
  }

  /**
   * ç»Ÿä¸€å¤„ç†ç®¡é“
   */
  private async processWithUnifiedPipeline(
    data: any,
    context: PreprocessingContext
  ): Promise<any> {
    const startTime = Date.now();
    let processedData = data;

    try {
      // æ€§èƒ½è¿½è¸ª
      if (this.config.performanceTracking) {
        this.performanceMetrics.totalProcessed++;
        this.performanceMetrics.byStage[context.stage].count++;
      }

      // 1. æ£€æŸ¥æ˜¯å¦å¯ç”¨
      if (!this.config.enabled) {
        if (this.config.debugMode) {
          this.logger.debug('UnifiedCompatibilityPreprocessor disabled, skipping', {
            requestId: context.requestId,
            provider: context.provider,
            model: context.model
          });
        }
        return data;
      }

      // 2. ç¼“å­˜æ£€æŸ¥
      const cacheKey = this.generateCacheKey(data, context);
      if (this.config.cacheResults && this.processedCache.has(cacheKey)) {
        if (this.config.debugMode) {
          this.logger.debug('Using cached result', { cacheKey });
        }
        return this.processedCache.get(cacheKey);
      }

      // 3. æ ¹æ®é˜¶æ®µè¿›è¡Œä¸åŒçš„å¤„ç†
      if (context.stage === 'response') {
        // å“åº”é˜¶æ®µå¤„ç†
        processedData = await this.processResponse(data, context);
      } else if (context.stage === 'input') {
        // è¾“å…¥é˜¶æ®µå¤„ç†
        processedData = await this.processInput(data, context);
      } else if (context.stage === 'streaming') {
        // æµå¼å¤„ç†
        processedData = await this.processStreaming(data, context);
      }

      // 4. ç¼“å­˜ç»“æœ
      if (this.config.cacheResults) {
        this.processedCache.set(cacheKey, processedData);
      }

      return processedData;

    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : String(error);
      this.logger.error('UnifiedCompatibilityPreprocessor processing failed', {
        error: errorMessage,
        requestId: context.requestId,
        provider: context.provider,
        model: context.model,
        stage: context.stage
      }, context.requestId, 'preprocessing');
      
      // å‘ç”Ÿé”™è¯¯æ—¶è¿”å›åŸå§‹æ•°æ®
      return data;
    } finally {
      // æ€§èƒ½ç»Ÿè®¡
      const duration = Date.now() - startTime;
      if (this.config.performanceTracking) {
        this.performanceMetrics.totalDuration += duration;
        this.performanceMetrics.byStage[context.stage].duration += duration;
      }
    }
  }

  /**
   * å¤„ç†å“åº”æ•°æ®
   */
  private async processResponse(data: any, context: PreprocessingContext): Promise<any> {
    let processedData = data;

    // 1. OpenAIå…¼å®¹æ€§å¤„ç† (ModelScope, ShuaiHong, LMStudioç­‰)
    if (this.isOpenAICompatibleProvider(context.provider)) {
      processedData = await this.processOpenAICompatibleResponse(processedData, context);
    }

    // 2. Geminiæ ¼å¼ä¿®å¤
    if (this.isGeminiProvider(context.provider)) {
      processedData = await this.processGeminiResponse(processedData, context);
    }

    // 3. Anthropicå·¥å…·è°ƒç”¨æ–‡æœ¬ä¿®å¤
    if (this.needsAnthropicToolTextFix(processedData, context)) {
      processedData = await this.processAnthropicToolTextFix(processedData, context);
    }

    // 4. å¼ºåˆ¶å·¥å…·è°ƒç”¨æ£€æµ‹å’Œfinish reasonä¿®å¤
    const toolDetectionResult = await this.forceToolCallDetection(processedData, context);
    if (toolDetectionResult.hasTools) {
      processedData = this.forceFinishReasonOverride(processedData, 'tool_calls', context);
      console.log(`ğŸ”§ [COMPATIBILITY] Forced finish_reason override for ${toolDetectionResult.toolCount} tools`);
    }

    // 5. éªŒè¯å“åº”æœ‰æ•ˆæ€§
    if (this.config.validateFinishReason) {
      this.validateFinishReason(processedData, context);
    }

    return processedData;
  }

  /**
   * å¤„ç†è¾“å…¥æ•°æ®
   */
  private async processInput(data: any, context: PreprocessingContext): Promise<any> {
    let processedData = data;

    // 1. ModelScopeè¯·æ±‚æ ¼å¼ä¿®å¤
    if (this.isModelScopeCompatible(context.provider, context.model)) {
      processedData = await this.processModelScopeRequest(processedData, context);
    }

    // 2. Geminiè¯·æ±‚æ ¼å¼ä¿®å¤
    if (this.isGeminiProvider(context.provider)) {
      processedData = await this.processGeminiRequest(processedData, context);
    }

    // 3. å·¥å…·å®šä¹‰æ ‡å‡†åŒ–
    if (processedData.tools && Array.isArray(processedData.tools)) {
      processedData.tools = this.standardizeToolDefinitions(processedData.tools, context);
    }

    return processedData;
  }

  /**
   * å¤„ç†æµå¼æ•°æ®
   */
  private async processStreaming(data: any, context: PreprocessingContext): Promise<any> {
    let processedData = data;

    // æµå¼æ•°æ®ä¸­çš„å·¥å…·è°ƒç”¨æ£€æµ‹
    if (this.hasStreamingToolCalls(data)) {
      processedData = await this.processStreamingToolCalls(processedData, context);
    }

    return processedData;
  }

  // ====================
  // OpenAIå…¼å®¹æ€§å¤„ç†
  // ====================

  /**
   * å¤„ç†OpenAIå…¼å®¹æœåŠ¡çš„å“åº”æ ¼å¼é—®é¢˜
   */
  private async processOpenAICompatibleResponse(data: any, context: PreprocessingContext): Promise<any> {
    // ModelScope/ShuaiHongæ ¼å¼ä¿®å¤ï¼šè§£å†³"OpenAI response missing choices"é”™è¯¯
    if (data && typeof data === 'object' && !data.choices) {
      console.log(`ğŸ”§ [COMPATIBILITY] Applying OpenAI format patch for missing choices field`);
      console.log(`ğŸ“ [MODEL-MATCH] ${context.model} on ${context.provider}`);

      const fixedData = {
        id: data.id || `msg_${Date.now()}_${context.requestId.slice(-8)}`,
        object: 'chat.completion',
        created: data.created || Math.floor(Date.now() / 1000),
        model: context.model,
        choices: [{
          index: 0,
          message: {
            role: 'assistant',
            content: this.extractContent(data) || '',
            tool_calls: this.extractToolCalls(data) || null
          },
          finish_reason: this.extractFinishReason(data) || 'stop'
        }],
        usage: data.usage || {
          prompt_tokens: 0,
          completion_tokens: 0,
          total_tokens: 0
        }
      };

      // å¦‚æœæœ‰å·¥å…·è°ƒç”¨ä½†æ²¡æœ‰å†…å®¹ï¼Œè®¾ç½®contentä¸ºnull
      if (fixedData.choices[0].message.tool_calls && !fixedData.choices[0].message.content) {
        (fixedData.choices[0].message as any).content = null;
      }

      return fixedData;
    }

    // LMStudioç‰¹æ®Šå¤„ç†ï¼šè§£æåµŒå…¥çš„å·¥å…·è°ƒç”¨æ–‡æœ¬
    if (this.isLMStudioProvider(context.provider)) {
      return await this.processLMStudioResponse(data, context);
    }

    // æ£€æŸ¥choiceså­˜åœ¨ä½†æ ¼å¼ä¸å®Œæ•´çš„æƒ…å†µ
    if (data && data.choices && Array.isArray(data.choices)) {
      let needsFix = false;
      const fixedChoices = data.choices.map((choice: any) => {
        if (!choice.message) {
          needsFix = true;
          return {
            ...choice,
            index: choice.index || 0,
            message: {
              role: 'assistant',
              content: choice.content || choice.text || '',
              tool_calls: choice.tool_calls || null
            },
            finish_reason: choice.finish_reason || 'stop'
          };
        }
        return choice;
      });

      if (needsFix) {
        console.log(`ğŸ”§ [COMPATIBILITY] Fixing incomplete choices format for ${context.provider}`);
        return {
          ...data,
          choices: fixedChoices
        };
      }
    }

    return data;
  }

  /**
   * LMStudioå“åº”å¤„ç†
   */
  private async processLMStudioResponse(data: any, context: PreprocessingContext): Promise<any> {
    // å¤„ç†OpenAIå’ŒAnthropicä¸¤ç§æ ¼å¼
    let textContent = '';
    let isOpenAIFormat = false;

    // æ£€æŸ¥OpenAIæ ¼å¼
    if (data.choices && Array.isArray(data.choices) && data.choices.length > 0) {
      const choice = data.choices[0];
      textContent = choice.message?.content;
      isOpenAIFormat = true;
    }
    // æ£€æŸ¥Anthropicæ ¼å¼  
    else if (data.content && Array.isArray(data.content)) {
      const textBlock = data.content.find((block: any) => block.type === 'text');
      textContent = textBlock?.text;
      isOpenAIFormat = false;
    }

    if (typeof textContent === 'string' && textContent.length > 0) {
      const lmstudioToolCalls = this.parseLMStudioToolCalls(textContent, context);

      if (lmstudioToolCalls.length > 0) {
        console.log(`ğŸ”§ [COMPATIBILITY] Parsed ${lmstudioToolCalls.length} LMStudio tool calls (${isOpenAIFormat ? 'OpenAI' : 'Anthropic'} format)`);

        // æ¸…ç†å·¥å…·è°ƒç”¨æ ‡è®°
        let newContent = textContent;
        const lmstudioPattern = /<\|start\|>assistant<\|channel\|>commentary to=functions\.[^<]*\s*<\|constrain\|>[^<]*<\|message\|>\{[^}]*\}/g;
        newContent = newContent.replace(lmstudioPattern, '').trim();

        if (isOpenAIFormat) {
          // è¿”å›OpenAIæ ¼å¼
          const choice = data.choices[0];
          return {
            ...data,
            choices: [{
              ...choice,
              message: {
                ...choice.message,
                content: newContent || null,
                tool_calls: lmstudioToolCalls
              },
              finish_reason: 'tool_calls'
            }]
          };
        } else {
          // è¿”å›Anthropicæ ¼å¼
          const toolUseBlocks = lmstudioToolCalls.map(toolCall => ({
            type: 'tool_use',
            id: toolCall.id,
            name: toolCall.function.name,
            input: JSON.parse(toolCall.function.arguments)
          }));

          const newContentBlocks = [];
          if (newContent) {
            newContentBlocks.push({
              type: 'text',
              text: newContent
            });
          }
          newContentBlocks.push(...toolUseBlocks);

          return {
            ...data,
            content: newContentBlocks,
            stop_reason: 'tool_use'
          };
        }
      }
    }

    return data;
  }

  /**
   * ModelScopeè¯·æ±‚æ ¼å¼å¤„ç†
   */
  private async processModelScopeRequest(data: any, context: PreprocessingContext): Promise<any> {
    if (!data) return data;

    let patchedRequest = { ...data };

    // ç¡®ä¿æ¶ˆæ¯æ ¼å¼æ­£ç¡®ï¼Œç‰¹æ®Šå¤„ç†GLM-4.5å’ŒQwen3-Coder
    if (patchedRequest.messages && Array.isArray(patchedRequest.messages)) {
      patchedRequest.messages = patchedRequest.messages.map((msg: any) => ({
        role: msg.role,
        content: this.ensureStringContentForModelScope(msg.content, context.model)
      }));

      // GLM-4.5ç‰¹æ®Šå¤„ç†
      if (this.isGLMModel(context.model)) {
        patchedRequest = this.applyGLMSpecificPatches(patchedRequest, context);
      } 
      // Qwen3-Coderç‰¹æ®Šå¤„ç†
      else if (this.isQwen3CoderModel(context.model)) {
        patchedRequest = this.applyQwen3CoderSpecificPatches(patchedRequest, context);
      }

      // æ„å»ºpromptå­—ç¬¦ä¸²ä½œä¸ºå¤‡ç”¨
      const promptText = this.buildPromptFromMessages(patchedRequest.messages);
      if (promptText) {
        patchedRequest.prompt = promptText;
      }
    }

    // ç¡®ä¿å¿…è¦å‚æ•°
    if (!patchedRequest.max_tokens) {
      patchedRequest.max_tokens = 4096;
    }
    if (typeof patchedRequest.temperature === 'undefined') {
      patchedRequest.temperature = 0.7;
    }
    if (typeof patchedRequest.stream === 'undefined') {
      patchedRequest.stream = true;
    }

    return patchedRequest;
  }

  // ====================
  // Geminiæ ¼å¼å¤„ç†
  // ====================

  /**
   * Geminiå“åº”æ ¼å¼ä¿®å¤
   */
  private async processGeminiResponse(data: any, context: PreprocessingContext): Promise<any> {
    // å¦‚æœå·²ç»æ˜¯æ ‡å‡†æ ¼å¼ï¼Œç›´æ¥è¿”å›
    if (data.choices && Array.isArray(data.choices)) {
      return data;
    }

    const fixedData: any = {
      id: data.id || `gemini-${Date.now()}`,
      object: 'chat.completion',
      created: Math.floor(Date.now() / 1000),
      model: context.model,
      choices: []
    };

    // å¤„ç†candidateså­—æ®µ
    if (data.candidates && Array.isArray(data.candidates)) {
      fixedData.choices = data.candidates.map((candidate: any, index: number) => {
        const choice: any = {
          index,
          message: {
            role: 'assistant',
            content: ''
          },
          finish_reason: this.mapGeminiFinishReason(candidate.finishReason)
        };

        // å¤„ç†content
        if (candidate.content && candidate.content.parts) {
          const textParts = candidate.content.parts
            .filter((part: any) => part.text)
            .map((part: any) => part.text);
          
          choice.message.content = textParts.join('\n');

          // å¤„ç†function calls
          const functionCalls = candidate.content.parts
            .filter((part: any) => part.functionCall);
          
          if (functionCalls.length > 0) {
            choice.message.tool_calls = functionCalls.map((part: any) => ({
              id: `call_${Math.random().toString(36).substr(2, 9)}`,
              type: 'function',
              function: {
                name: part.functionCall.name,
                arguments: JSON.stringify(part.functionCall.args || {})
              }
            }));
            choice.finish_reason = 'tool_calls';
          }
        }

        return choice;
      });
    }

    // å¤„ç†usageä¿¡æ¯
    if (data.usageMetadata) {
      fixedData.usage = {
        prompt_tokens: data.usageMetadata.promptTokenCount || 0,
        completion_tokens: data.usageMetadata.candidatesTokenCount || 0,
        total_tokens: data.usageMetadata.totalTokenCount || 0
      };
    }

    return fixedData;
  }

  /**
   * Geminiè¯·æ±‚æ ¼å¼å¤„ç†
   */
  private async processGeminiRequest(data: any, context: PreprocessingContext): Promise<any> {
    // Geminiè¯·æ±‚æ ¼å¼è½¬æ¢é€»è¾‘
    return data; // TODO: å®ç°Geminiè¯·æ±‚æ ¼å¼è½¬æ¢
  }

  // ====================
  // Anthropicå·¥å…·è°ƒç”¨æ–‡æœ¬ä¿®å¤
  // ====================

  /**
   * Anthropicå·¥å…·è°ƒç”¨æ–‡æœ¬ä¿®å¤
   */
  private async processAnthropicToolTextFix(data: any, context: PreprocessingContext): Promise<any> {
    if (!data.content || !Array.isArray(data.content)) {
      return data;
    }

    const fixedContent: any[] = [];
    let extractedToolCalls = 0;

    // æ”¶é›†æ‰€æœ‰æ–‡æœ¬å—åˆ°ç¼“å†²åŒºè¿›è¡Œæ‰¹é‡å¤„ç†
    const textBuffer: string[] = [];
    const nonTextBlocks: any[] = [];

    for (const block of data.content) {
      if (block.type === 'text' && block.text) {
        textBuffer.push(block.text);
      } else {
        nonTextBlocks.push(block);
      }
    }

    // æ‰¹é‡å¤„ç†æ–‡æœ¬å†…å®¹
    if (textBuffer.length > 0) {
      const combinedText = textBuffer.join('\n');
      const { textParts, toolCalls } = this.extractToolCallsFromText(combinedText);

      // æ·»åŠ æ¸…ç†åçš„æ–‡æœ¬
      if (textParts.length > 0) {
        const cleanText = textParts.join('\n').trim();
        if (cleanText) {
          fixedContent.push({
            type: 'text',
            text: cleanText
          });
        }
      }

      // æ·»åŠ æå–çš„å·¥å…·è°ƒç”¨
      fixedContent.push(...toolCalls);
      extractedToolCalls += toolCalls.length;
    }

    // æ·»åŠ éæ–‡æœ¬å—
    fixedContent.push(...nonTextBlocks);

    const result = {
      ...data,
      content: fixedContent
    };

    // æ›´æ–°finish reason
    if (extractedToolCalls > 0) {
      result.stop_reason = 'tool_use';
      console.log(`ğŸ”§ [COMPATIBILITY] Extracted ${extractedToolCalls} tool calls from text content`);
    }

    return result;
  }

  // ====================
  // å·¥å…·è°ƒç”¨æ£€æµ‹å’Œä¿®å¤
  // ====================

  /**
   * å¼ºåˆ¶å·¥å…·è°ƒç”¨æ£€æµ‹
   */
  private async forceToolCallDetection(data: any, context: PreprocessingContext): Promise<{
    hasTools: boolean;
    toolCount: number;
  }> {
    let hasTools = false;
    let toolCount = 0;

    // 1. æ£€æŸ¥Anthropicæ ¼å¼çš„å·¥å…·è°ƒç”¨
    if (data.content && Array.isArray(data.content)) {
      const directToolCalls = data.content.filter((block: any) => block.type === 'tool_use');
      toolCount += directToolCalls.length;

      // æ£€æŸ¥æ–‡æœ¬æ ¼å¼çš„å·¥å…·è°ƒç”¨
      const textBlocks = data.content.filter((block: any) => block.type === 'text');
      for (const block of textBlocks) {
        if (block.text && this.hasTextToolCallsSimplified(block.text)) {
          hasTools = true;
        }
      }
    }

    // 2. æ£€æŸ¥OpenAIæ ¼å¼çš„å·¥å…·è°ƒç”¨
    if (data.choices && Array.isArray(data.choices)) {
      for (const choice of data.choices) {
        if (choice.message?.tool_calls) {
          toolCount += choice.message.tool_calls.length;
          hasTools = true;
        }
        
        if (choice.message?.content && this.hasTextToolCallsSimplified(choice.message.content)) {
          hasTools = true;
        }
      }
    }

    // 3. æ£€æŸ¥Geminiæ ¼å¼çš„å·¥å…·è°ƒç”¨
    if (data.candidates && Array.isArray(data.candidates)) {
      for (const candidate of data.candidates) {
        if (candidate.content?.parts) {
          const functionCalls = candidate.content.parts.filter((part: any) => part.functionCall);
          toolCount += functionCalls.length;
          hasTools = hasTools || functionCalls.length > 0;
        }
      }
    }

    hasTools = hasTools || toolCount > 0;

    return { hasTools, toolCount };
  }

  /**
   * å¼ºåˆ¶finish reasonè¦†ç›–
   */
  private forceFinishReasonOverride(data: any, targetReason: string, context: PreprocessingContext): any {
    const result = { ...data };

    // OpenAIæ ¼å¼
    if (data.choices && Array.isArray(data.choices)) {
      result.choices = data.choices.map((choice: any) => ({
        ...choice,
        finish_reason: targetReason
      }));
    }

    // Anthropicæ ¼å¼
    if (data.stop_reason !== undefined) {
      result.stop_reason = targetReason === 'tool_calls' ? 'tool_use' : targetReason;
    }

    return result;
  }

  // ====================
  // è¾…åŠ©æ–¹æ³•
  // ====================

  /**
   * æ£€æŸ¥æ˜¯å¦ä¸ºOpenAIå…¼å®¹Provider
   */
  private isOpenAICompatibleProvider(provider: string): boolean {
    return provider.includes('openai') || 
           provider.includes('lmstudio') ||
           provider.includes('modelscope') ||
           provider.includes('shuaihong') ||
           provider.includes('deepseek');
  }

  /**
   * æ£€æŸ¥æ˜¯å¦ä¸ºLMStudio Provider
   */
  private isLMStudioProvider(provider: string): boolean {
    return provider.includes('lmstudio') || provider.includes('LMStudio');
  }

  /**
   * æ£€æŸ¥æ˜¯å¦ä¸ºGemini Provider
   */
  private isGeminiProvider(provider: string): boolean {
    return provider.includes('gemini') || provider.includes('palm') || provider.includes('bison');
  }

  /**
   * æ£€æŸ¥æ˜¯å¦éœ€è¦Anthropicå·¥å…·æ–‡æœ¬ä¿®å¤
   */
  private needsAnthropicToolTextFix(data: any, context: PreprocessingContext): boolean {
    if (!data.content || !Array.isArray(data.content)) {
      return false;
    }

    return data.content.some((block: any) => {
      if (block.type !== 'text' || !block.text) {
        return false;
      }

      // æ£€æŸ¥æ˜¯å¦åŒ…å«å·¥å…·è°ƒç”¨æ–‡æœ¬æ¨¡å¼
      const toolCallPatterns = [
        /\{\s*"type"\s*:\s*"tool_use"\s*,/i,
        /\{\s*"id"\s*:\s*"toolu_[^"]+"\s*,/i,
        /"name"\s*:\s*"[^"]+"\s*,\s*"input"\s*:\s*\{/i,
        /Tool\s+call:\s*\w+\s*\(\s*\{[^}]*"[^"]*":[^}]*\}/i,
        /\w+\s*\(\s*\{\s*"[^"]+"\s*:\s*"[^"]*"/i
      ];

      return toolCallPatterns.some(pattern => pattern.test(block.text));
    });
  }

  /**
   * æ£€æŸ¥æ˜¯å¦ä¸ºModelScopeå…¼å®¹çš„provider/modelç»„åˆ
   */
  private isModelScopeCompatible(provider: string, model: string): boolean {
    if (provider.includes('modelscope') || provider.includes('shuaihong')) {
      return true;
    }

    const modelLower = model.toLowerCase();
    return modelLower.includes('qwen') || 
           modelLower.includes('glm') || 
           modelLower.includes('zhipuai') ||
           modelLower.includes('coder');
  }

  /**
   * æ£€æŸ¥æ˜¯å¦ä¸ºGLMæ¨¡å‹
   */
  private isGLMModel(model: string): boolean {
    const modelLower = model.toLowerCase();
    return modelLower.includes('glm') || modelLower.includes('zhipuai');
  }

  /**
   * æ£€æŸ¥æ˜¯å¦ä¸ºQwen3-Coderæ¨¡å‹
   */
  private isQwen3CoderModel(model: string): boolean {
    const modelLower = model.toLowerCase();
    return modelLower.includes('qwen3') ||
           modelLower.includes('coder') ||
           modelLower.includes('480b');
  }

  /**
   * è§£æLMStudioå·¥å…·è°ƒç”¨æ ¼å¼
   */
  private parseLMStudioToolCalls(content: string, context: PreprocessingContext): any[] {
    const toolCalls: any[] = [];
    
    const lmstudioPattern = /<\|start\|>assistant<\|channel\|>commentary to=functions\.(\w+)\s*<\|constrain\|>(?:JSON|json)<\|message\|>(\{[^}]*\})/g;
    
    let match;
    while ((match = lmstudioPattern.exec(content)) !== null) {
      try {
        const functionName = match[1];
        const argsJson = match[2];
        const args = JSON.parse(argsJson);
        
        toolCalls.push({
          id: `call_${Date.now()}_${toolCalls.length}`,
          type: 'function',
          function: {
            name: functionName,
            arguments: JSON.stringify(args)
          }
        });
      } catch (error) {
        console.warn('Failed to parse LMStudio tool call:', error);
      }
    }
    
    return toolCalls;
  }

  /**
   * ä»æ–‡æœ¬ä¸­æå–å·¥å…·è°ƒç”¨
   */
  private extractToolCallsFromText(text: string): { textParts: string[], toolCalls: any[] } {
    const textParts: string[] = [];
    const toolCalls: any[] = [];

    // 1. GLM-4.5æ ¼å¼ï¼šTool call: FunctionName({...})
    const glmPattern = /Tool\s+call:\s*(\w+)\s*\((\{[^}]*\})\)/gi;
    let match;
    while ((match = glmPattern.exec(text)) !== null) {
      try {
        const toolName = match[1];
        const jsonStr = match[2];
        const args = JSON.parse(jsonStr);
        
        toolCalls.push({
          type: 'tool_use',
          id: `toolu_${Date.now()}_${Math.random().toString(36).substr(2, 8)}`,
          name: toolName,
          input: args
        });
      } catch (error) {
        console.warn('Failed to parse GLM tool call:', match[2]);
      }
    }

    // 2. JSONæ ¼å¼ï¼š{"type": "tool_use", ...}
    const jsonPattern = /\{\s*"type"\s*:\s*"tool_use"[^}]*\}/gi;
    while ((match = jsonPattern.exec(text)) !== null) {
      try {
        const toolCallJson = JSON.parse(match[0]);
        if (this.isValidToolCall(toolCallJson)) {
          toolCalls.push({
            type: 'tool_use',
            id: toolCallJson.id,
            name: toolCallJson.name,
            input: toolCallJson.input
          });
        }
      } catch (error) {
        console.warn('Failed to parse JSON tool call:', match[0].substring(0, 50));
      }
    }

    // æ¸…ç†æ–‡æœ¬å†…å®¹
    if (toolCalls.length > 0) {
      let cleanedText = text;
      cleanedText = cleanedText.replace(/Tool\s+call:\s*\w+\s*\([^)]*\)/gi, '');
      cleanedText = cleanedText.replace(/\{\s*"type"\s*:\s*"tool_use"[^}]*\}/gi, '');
      cleanedText = cleanedText.replace(/\n\s*\n/g, '\n').trim();
      
      if (cleanedText && cleanedText.length > 10) {
        textParts.push(cleanedText);
      }
    } else {
      textParts.push(text);
    }

    return { textParts, toolCalls };
  }

  /**
   * ç®€åŒ–çš„æ–‡æœ¬å·¥å…·è°ƒç”¨æ£€æµ‹
   */
  private hasTextToolCallsSimplified(text: string): boolean {
    const patterns = [
      /Tool\s+call:\s*\w+\s*\(/i,
      /"type"\s*:\s*"tool_use"/i,
      /"name"\s*:\s*"\w+"/i
    ];

    return patterns.some(pattern => pattern.test(text));
  }

  /**
   * éªŒè¯æ˜¯å¦ä¸ºæœ‰æ•ˆçš„å·¥å…·è°ƒç”¨
   */
  private isValidToolCall(obj: any): boolean {
    return obj &&
           typeof obj === 'object' &&
           obj.type === 'tool_use' &&
           typeof obj.id === 'string' &&
           typeof obj.name === 'string' &&
           obj.input !== undefined;
  }

  /**
   * æ ‡å‡†åŒ–å·¥å…·å®šä¹‰
   */
  private standardizeToolDefinitions(tools: any[], context: PreprocessingContext): any[] {
    return tools.map((tool: any) => ({
      type: 'function', // ç¡®ä¿æœ‰typeå­—æ®µ
      ...tool,
      function: {
        ...tool.function,
        description: tool.function?.description || `Function: ${tool.function?.name || 'unknown'}`
      }
    }));
  }

  /**
   * æ£€æŸ¥æµå¼æ•°æ®ä¸­æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
   */
  private hasStreamingToolCalls(data: any): boolean {
    return data?.event && data?.data && (
      data.event.includes('tool') ||
      data.data.tool_calls ||
      data.data.function_call
    );
  }

  /**
   * å¤„ç†æµå¼å·¥å…·è°ƒç”¨
   */
  private async processStreamingToolCalls(data: any, context: PreprocessingContext): Promise<any> {
    // TODO: å®ç°æµå¼å·¥å…·è°ƒç”¨å¤„ç†
    return data;
  }

  /**
   * ä»éæ ‡å‡†å“åº”ä¸­æå–å†…å®¹
   */
  private extractContent(data: any): string | null {
    if (data.content) return data.content;
    if (data.message && typeof data.message === 'string') return data.message;
    if (data.text) return data.text;
    if (data.response) return data.response;
    if (data.output) return data.output;
    if (data.result?.content) return data.result.content;
    if (data.data?.content) return data.data.content;
    return null;
  }

  /**
   * ä»éæ ‡å‡†å“åº”ä¸­æå–å·¥å…·è°ƒç”¨
   */
  private extractToolCalls(data: any): any[] | null {
    if (data.tool_calls && Array.isArray(data.tool_calls)) return data.tool_calls;
    if (data.message?.tool_calls) return data.message.tool_calls;
    if (data.choices?.[0]?.message?.tool_calls) return data.choices[0].message.tool_calls;
    return null;
  }

  /**
   * ä»éæ ‡å‡†å“åº”ä¸­æå–finish_reason
   */
  private extractFinishReason(data: any): string {
    if (data.finish_reason) return data.finish_reason;
    if (data.stop_reason) return data.stop_reason;
    if (data.finishReason) return data.finishReason;
    if (data.status) return data.status;
    if (data.result?.finish_reason) return data.result.finish_reason;
    if (data.choices?.[0]?.finish_reason) return data.choices[0].finish_reason;
    if (this.extractToolCalls(data)) return 'tool_calls';
    return 'stop';
  }

  /**
   * æ˜ å°„Gemini finish reason
   */
  private mapGeminiFinishReason(geminiReason: string): string {
    const reasonMap: Record<string, string> = {
      'STOP': 'stop',
      'MAX_TOKENS': 'length',
      'SAFETY': 'content_filter',
      'RECITATION': 'content_filter',
      'OTHER': 'stop'
    };
    return reasonMap[geminiReason] || 'stop';
  }

  /**
   * ç¡®ä¿ModelScopeå†…å®¹ä¸ºå­—ç¬¦ä¸²æ ¼å¼
   */
  private ensureStringContentForModelScope(content: any, model: string): string {
    if (typeof content === 'string') return content;
    
    if (Array.isArray(content)) {
      return content.map(block => {
        if (block.type === 'text' && block.text) return block.text;
        if (block.type === 'tool_use') {
          return this.convertToolUseToModelScopeFormat(block, model);
        }
        return '';
      }).filter(text => text.trim()).join('\n');
    }

    if (typeof content === 'object' && content !== null) {
      if (content.text) return content.text;
      return JSON.stringify(content);
    }

    return String(content);
  }

  /**
   * è½¬æ¢å·¥å…·è°ƒç”¨ä¸ºModelScopeæ ¼å¼
   */
  private convertToolUseToModelScopeFormat(toolBlock: any, model: string): string {
    if (this.isGLMModel(model)) {
      const functionName = toolBlock.name || 'unknown';
      const inputData = JSON.stringify(toolBlock.input || {});
      return `Tool call: ${functionName}(${inputData})`;
    } else if (this.isQwen3CoderModel(model)) {
      return JSON.stringify({
        type: 'tool_use',
        name: toolBlock.name,
        input: toolBlock.input
      });
    }
    return JSON.stringify(toolBlock);
  }

  /**
   * åº”ç”¨GLMç‰¹å®šçš„è¡¥ä¸
   */
  private applyGLMSpecificPatches(request: any, context: PreprocessingContext): any {
    const patchedRequest = { ...request };
    
    if (!patchedRequest.temperature) {
      patchedRequest.temperature = 0.8;
    }
    
    if (patchedRequest.tools && Array.isArray(patchedRequest.tools)) {
      patchedRequest.tools = patchedRequest.tools.map((tool: any) => ({
        ...tool,
        function: {
          ...tool.function,
          description: tool.function?.description || `Function: ${tool.function?.name || 'unknown'}`
        }
      }));
    }

    return patchedRequest;
  }

  /**
   * åº”ç”¨Qwen3-Coderç‰¹å®šçš„è¡¥ä¸
   */
  private applyQwen3CoderSpecificPatches(request: any, context: PreprocessingContext): any {
    const patchedRequest = { ...request };
    
    if (!patchedRequest.temperature) {
      patchedRequest.temperature = 0.7;
    }
    
    if (patchedRequest.messages && Array.isArray(patchedRequest.messages)) {
      patchedRequest.messages = patchedRequest.messages.map((msg: any) => ({
        role: msg.role,
        content: msg.content,
        ...(msg.role === 'system' && { name: 'system' })
      }));
    }

    return patchedRequest;
  }

  /**
   * ä»æ¶ˆæ¯æ„å»ºpromptå­—ç¬¦ä¸²
   */
  private buildPromptFromMessages(messages: any[]): string {
    if (!Array.isArray(messages) || messages.length === 0) return '';

    return messages.map(msg => {
      const role = msg.role;
      const content = msg.content;
      
      switch (role) {
        case 'system': return `System: ${content}`;
        case 'user': return `User: ${content}`;
        case 'assistant': return `Assistant: ${content}`;
        default: return `${role}: ${content}`;
      }
    }).join('\n\n');
  }

  /**
   * éªŒè¯finish reason
   */
  private validateFinishReason(data: any, context: PreprocessingContext): void {
    // æ£€æŸ¥å¼‚å¸¸å“åº”
    const abnormalResponse = this.detectAbnormalResponse(data, context);
    if (abnormalResponse) {
      const errorCode = abnormalResponse.statusCode || 500;
      const errorMessage = this.generateErrorMessage(abnormalResponse, context);
      
      this.logger.error('Abnormal API response detected', {
        error: errorMessage,
        errorCode,
        abnormalResponse,
        provider: context.provider,
        model: context.model,
        requestId: context.requestId
      }, context.requestId, 'preprocessing');

      if (this.config.strictFinishReasonValidation) {
        throw new Error(`${errorMessage} (Error Code: ${errorCode})`);
      }
      return;
    }

    // éªŒè¯æ­£å¸¸å“åº”çš„finish_reason
    this.validateNormalResponseFinishReason(data, context);
  }

  /**
   * æ£€æµ‹å¼‚å¸¸APIå“åº”
   */
  private detectAbnormalResponse(data: any, context: PreprocessingContext): any {
    if (data?.error) {
      return {
        type: 'api_error',
        statusCode: data.error.status || 500,
        message: data.error.message || 'API Error'
      };
    }
    
    if (!data || (typeof data === 'object' && Object.keys(data).length === 0)) {
      return {
        type: 'empty_response',
        statusCode: 502,
        message: 'Empty or invalid response'
      };
    }
    
    if (data.status >= 400) {
      return {
        type: 'http_error',
        statusCode: data.status,
        message: data.message || 'HTTP Error'
      };
    }
    
    return null;
  }

  /**
   * ç”Ÿæˆé”™è¯¯æ¶ˆæ¯
   */
  private generateErrorMessage(abnormalResponse: any, context: PreprocessingContext): string {
    const baseMessage = `Provider returned unknown finish reason, indicating connection or API issue.`;
    const details = [
      `Provider: ${context.provider}`,
      `Model: ${context.model}`,
      `Type: ${abnormalResponse.type}`,
      `Status: ${abnormalResponse.statusCode}`
    ].join(', ');
    
    const fullMessage = `${baseMessage} Details: ${details}`;
    return fullMessage.length > 500 ? fullMessage.substring(0, 497) + '...' : fullMessage;
  }

  /**
   * éªŒè¯æ­£å¸¸å“åº”çš„finish_reason
   */
  private validateNormalResponseFinishReason(data: any, context: PreprocessingContext): void {
    if (data && typeof data === 'object' && 'choices' in data) {
      const choices = data.choices;
      if (Array.isArray(choices) && choices.length > 0) {
        const finishReason = choices[0].finish_reason;
        
        this.logger.info('Raw finish_reason detected', {
          originalFinishReason: finishReason,
          provider: context.provider,
          model: context.model,
          requestId: context.requestId,
          hasChoices: true,
          timestamp: new Date().toISOString()
        }, context.requestId, 'preprocessing');
        
        if (finishReason === 'unknown' && this.config.strictFinishReasonValidation) {
          const error = new Error(`Provider returned explicit unknown finish_reason. Provider: ${context.provider}, Model: ${context.model}`);
          this.logger.error('Strict finish_reason validation failed', {
            finishReason,
            provider: context.provider,
            model: context.model,
            requestId: context.requestId
          }, context.requestId, 'preprocessing');
          throw error;
        }
      }
    }
  }

  /**
   * ç”Ÿæˆç¼“å­˜é”®
   */
  private generateCacheKey(data: any, context: PreprocessingContext): string {
    const dataHash = this.hashObject(data);
    return `${context.provider}-${context.model}-${context.stage}-${dataHash}`;
  }

  /**
   * ç®€å•çš„å¯¹è±¡å“ˆå¸Œ
   */
  private hashObject(obj: any): string {
    const str = JSON.stringify(obj, Object.keys(obj).sort());
    let hash = 0;
    for (let i = 0; i < str.length; i++) {
      const char = str.charCodeAt(i);
      hash = ((hash << 5) - hash) + char;
      hash = hash & hash; // Convert to 32-bit integer
    }
    return hash.toString(36);
  }

  /**
   * æ¸…ç†èµ„æº
   */
  cleanup(): void {
    this.processedCache.clear();
    this.performanceMetrics = {
      totalProcessed: 0,
      totalDuration: 0,
      byStage: {
        input: { count: 0, duration: 0 },
        response: { count: 0, duration: 0 },
        streaming: { count: 0, duration: 0 }
      }
    };
  }

  /**
   * è·å–æ€§èƒ½æŒ‡æ ‡
   */
  getPerformanceMetrics() {
    return { ...this.performanceMetrics };
  }
}

// å•ä¾‹æ¨¡å¼
const preprocessorInstances = new Map<number | string, UnifiedCompatibilityPreprocessor>();

/**
 * è·å–æˆ–åˆ›å»ºç»Ÿä¸€å…¼å®¹æ€§é¢„å¤„ç†å™¨å®ä¾‹
 */
export function getUnifiedCompatibilityPreprocessor(
  port?: number, 
  config?: Partial<UnifiedCompatibilityConfig>
): UnifiedCompatibilityPreprocessor {
  const key = port || 'default';
  if (!preprocessorInstances.has(key)) {
    preprocessorInstances.set(key, new UnifiedCompatibilityPreprocessor(port, config));
  }
  return preprocessorInstances.get(key)!;
}

/**
 * åˆ›å»ºæ–°çš„ç»Ÿä¸€å…¼å®¹æ€§é¢„å¤„ç†å™¨å®ä¾‹
 */
export function createUnifiedCompatibilityPreprocessor(
  port?: number,
  config?: Partial<UnifiedCompatibilityConfig>
): UnifiedCompatibilityPreprocessor {
  const key = port || 'default';
  const instance = new UnifiedCompatibilityPreprocessor(port, config);
  preprocessorInstances.set(key, instance);
  return instance;
}

/**
 * é‡ç½®ç»Ÿä¸€å…¼å®¹æ€§é¢„å¤„ç†å™¨å®ä¾‹
 */
export function resetUnifiedCompatibilityPreprocessor(port?: number) {
  const key = port || 'default';
  if (preprocessorInstances.has(key)) {
    preprocessorInstances.get(key)!.cleanup();
    preprocessorInstances.delete(key);
  }
}