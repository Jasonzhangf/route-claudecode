/**
 * V3.0 Base Provider Implementation - Clean Architecture
 * 
 * LM Studio is now handled as an OpenAI-compatible provider with preprocessor
 * instead of a separate provider class. This follows proper separation of concerns.
 * 
 * Project owner: Jason Zhang
 */

import { Provider, BaseRequest, BaseResponse, ProviderConfig } from '../types/index.js';

export abstract class BaseProvider implements Provider {
  public readonly id: string;
  public readonly type: string;
  public readonly name: string;
  protected config: ProviderConfig;

  constructor(id: string, config: ProviderConfig) {
    this.id = id;
    this.type = config.type;
    this.name = config.name;
    this.config = config;
    
    console.log(`ğŸ”§ V3 ${this.type} provider initialized: ${this.id}`);
  }

  abstract isHealthy(): Promise<boolean>;
  abstract sendRequest(request: BaseRequest): Promise<BaseResponse>;
  
  // Legacy method for backward compatibility
  async processRequest(request: BaseRequest, requestId: string): Promise<BaseResponse> {
    return this.sendRequest(request);
  }

  protected createErrorResponse(request: BaseRequest, error: string): BaseResponse {
    return {
      id: `msg-${this.type}-error-${Date.now()}`,
      type: 'message',
      role: 'assistant',
      content: [{
        type: 'text',
        text: `Error from ${this.type} provider: ${error}`
      }],
      model: request.model,
      stop_reason: 'error',
      usage: {
        input_tokens: 0,
        output_tokens: 0
      }
    };
  }
}

// Mock provider implementations for V3 - these are placeholders
export class CodeWhispererProvider extends BaseProvider {
  private client: any;

  constructor(config: ProviderConfig, id: string) {
    super(id, config);
    this.initializeCodewhispererClient(config, id);
  }

  private async initializeCodewhispererClient(config: ProviderConfig, id: string) {
    try {
      // åŠ¨æ€å¯¼å…¥CodeWhispererå®¢æˆ·ç«¯å·¥å‚
      const { CodewhispererClientFactory } = await import('./codewhisperer/client-factory.js');
      
      // åˆ›å»ºCodeWhispererå®¢æˆ·ç«¯
      this.client = CodewhispererClientFactory.createValidatedClient(config, id);
      
      console.log(`[V3:${process.env.RCC_PORT}] Initialized CodeWhisperer provider ${id}`, {
        type: config.type,
        endpoint: config.endpoint || 'https://codewhisperer.us-east-1.amazonaws.com'
      });
    } catch (error) {
      console.error(`Failed to initialize CodeWhisperer provider ${id}:`, error.message);
      throw error;
    }
  }
  
  async isHealthy(): Promise<boolean> {
    try {
      if (this.client && typeof this.client.healthCheck === 'function') {
        const health = await this.client.healthCheck();
        return health.healthy;
      }
      return false;
    } catch (error) {
      console.warn(`CodeWhisperer provider ${this.id} health check failed:`, error.message);
      return false;
    }
  }
  
  async sendRequest(request: BaseRequest): Promise<BaseResponse> {
    try {
      // Providerå±‚åªè´Ÿè´£APIé€šä¿¡ï¼Œä¸åštransformerè½¬æ¢
      // è½¬æ¢åº”è¯¥åœ¨transformerå±‚å®Œæˆ
      const context = {
        requestId: request.metadata?.requestId || `req_${Date.now()}`,
        providerId: this.id,
        config: this.config
      };
      
      // ç›´æ¥å‘é€åˆ°CodeWhisperer APIï¼ˆå‡è®¾requestå·²ç»è¢«transformerè½¬æ¢è¿‡ï¼‰
      const response = await this.client.sendRequest(request, context);
      return response;
    } catch (error) {
      console.error(`CodeWhisperer provider ${this.id} request failed:`, error.message);
      return this.createErrorResponse(request, error.message);
    }
  }
  
  async *sendStreamRequest?(request: BaseRequest): AsyncIterable<any> {
    try {
      const context = {
        requestId: request.metadata?.requestId || `req_${Date.now()}`,
        providerId: this.id,
        config: this.config
      };
      
      // å‘é€æµå¼è¯·æ±‚
      const stream = this.client.sendStreamRequest(request, context);
      for await (const chunk of stream) {
        yield chunk;
      }
    } catch (error) {
      console.error(`CodeWhisperer provider ${this.id} stream request failed:`, error.message);
      throw error;
    }
  }
}

export class GeminiProvider extends BaseProvider {
  private client: any;
  
  constructor(config: ProviderConfig, id: string) {
    super(id, config);
    this.initializeGeminiClient(config, id);
  }
  
  private async initializeGeminiClient(config: ProviderConfig, id: string) {
    try {
      // åŠ¨æ€å¯¼å…¥Geminiå®¢æˆ·ç«¯å·¥å‚ï¼Œä½¿ç”¨æ”¯æŒapiKeysæ•°ç»„çš„å‡½æ•°
      const { createGeminiClient } = await import('./gemini/client-factory.js');
      
      // åˆ›å»ºGeminiå®¢æˆ·ç«¯ï¼Œæ”¯æŒå¤šAPIå¯†é’¥
      this.client = createGeminiClient(config, id);
      
      console.log(`[V3:${process.env.RCC_PORT}] Initialized Gemini provider ${id}`, {
        type: config.type,
        endpoint: config.endpoint || 'https://generativelanguage.googleapis.com'
      });
      
    } catch (error) {
      console.error(`Failed to initialize Gemini provider ${id}:`, error.message);
      throw error;
    }
  }
  
  async isHealthy(): Promise<boolean> {
    try {
      if (this.client && typeof this.client.healthCheck === 'function') {
        const health = await this.client.healthCheck();
        return health.healthy;
      }
      return false;
    } catch (error) {
      console.warn(`Gemini provider ${this.id} health check failed:`, error.message);
      return false;
    }
  }
  
  async sendRequest(request: BaseRequest): Promise<BaseResponse> {
    try {
      // Providerå±‚åªè´Ÿè´£APIé€šä¿¡ï¼Œä¸åštransformerè½¬æ¢
      // è½¬æ¢åº”è¯¥åœ¨transformerå±‚å®Œæˆ
      const context = {
        requestId: request.metadata?.requestId || `req_${Date.now()}`,
        providerId: this.id,
        config: this.config
      };
      
      // ç›´æ¥å‘é€åˆ°Gemini APIï¼ˆå‡è®¾requestå·²ç»è¢«transformerè½¬æ¢è¿‡ï¼‰
      const response = await this.client.sendRequest(request, context);
      
      return response;
      
    } catch (error) {
      console.error(`Gemini provider ${this.id} request failed:`, error.message);
      return this.createErrorResponse(request, error.message);
    }
  }
  
  async *sendStreamRequest?(request: BaseRequest): AsyncIterable<any> {
    try {
      const context = {
        requestId: request.metadata?.requestId || `req_${Date.now()}`,
        providerId: this.id,
        config: this.config
      };
      
      // å‘é€æµå¼è¯·æ±‚
      const stream = this.client.sendStreamRequest(request, context);
      
      for await (const chunk of stream) {
        yield chunk;
      }
      
    } catch (error) {
      console.error(`Gemini provider ${this.id} stream request failed:`, error.message);
      throw error;
    }
  }
}

export class AnthropicProvider extends BaseProvider {
  constructor(config: ProviderConfig) {
    super('anthropic', config);
  }
  
  async isHealthy(): Promise<boolean> { 
    return false; // Not implemented yet
  }
  
  async sendRequest(request: BaseRequest): Promise<BaseResponse> {
    throw new Error('Anthropic provider not implemented yet');
  }
  
  async *sendStreamRequest?(request: BaseRequest): AsyncIterable<any> {
    throw new Error('Anthropic stream provider not implemented yet');
  }
}

// NOTE: LMStudioClient has been removed - LM Studio is now handled as:
// 1. OpenAI-compatible provider (uses createOpenAIClient)  
// 2. Special preprocessing via LMStudioToolCompatibility preprocessor
// This follows proper separation of concerns and allows unlimited OpenAI-compatible providers