/**
 * Streaming Request Handler Module
 * 
 * å¤„ç†æµå¼è¯·æ±‚çš„ä¸“ç”¨å¤„ç†å™¨
 * æŒ‰ç…§ç»†èŒå¼ç¼–ç¨‹åŸåˆ™ï¼šå°å·§ã€æ¨¡å—åŒ–ã€è‡ªåŒ…å«
 */

import { FastifyReply } from 'fastify';
import { BaseRequest, Provider } from '@/types';
import { v4 as uuidv4 } from 'uuid';
import { ResponsePipeline } from '@/pipeline/response-pipeline';
import { getUnifiedPatchPreprocessor } from '@/preprocessing/unified-patch-preprocessor';
import { handleStreamingError, UnifiedErrorHandler } from '@/utils/error-handler';

export interface StreamingHandlerDependencies {
  logger: any;
  responsePipeline: ResponsePipeline;
  unifiedPreprocessor: ReturnType<typeof getUnifiedPatchPreprocessor>;
  config: {
    debug: {
      enabled: boolean;
    };
    server: {
      port: number;
    };
  };
}

export class StreamingHandler {
  constructor(private deps: StreamingHandlerDependencies) {}

  /**
   * å¤„ç†æµå¼è¯·æ±‚çš„ä¸»è¦å…¥å£
   */
  async handleStreamingRequest(
    request: BaseRequest,
    provider: Provider,
    reply: FastifyReply,
    requestId: string
  ): Promise<void> {
    let outputTokens = 0;
    let chunkCount = 0;
    let streamInitialized = false;
    
    try {
      // 1. éªŒè¯æµå¼å“åº”
      const streamValidation = await this.validateStreamResponse(provider, request);
      
      // 2. åˆå§‹åŒ–æµå¼å“åº”
      this.initializeStreamResponse(reply);
      streamInitialized = true;
      
      // 3. å‘é€message_startäº‹ä»¶
      const messageId = await this.sendMessageStart(reply, request, requestId);
      
      // 4. å¤„ç†æµå¼æ•°æ®
      const streamStats = await this.processStreamData(
        streamValidation.streamIterator,
        streamValidation.firstChunk,
        reply,
        request,
        provider,
        requestId,
        messageId
      );
      
      outputTokens = streamStats.outputTokens;
      chunkCount = streamStats.chunkCount;
      
      // 5. å®Œæˆæµå¼å“åº”
      await this.finalizeStreamResponse(reply, outputTokens, requestId);
      
    } catch (error) {
      await this.handleStreamingError(error, reply, provider, request, requestId, {
        outputTokens,
        chunkCount,
        streamInitialized
      });
    }
  }

  /**
   * éªŒè¯æµå¼å“åº”çš„æœ‰æ•ˆæ€§
   */
  private async validateStreamResponse(provider: Provider, request: BaseRequest) {
    const streamIterable = provider.sendStreamRequest(request);
    const streamIterator = streamIterable[Symbol.asyncIterator]();
    const firstChunk = await streamIterator.next();
    
    if (firstChunk.done && !firstChunk.value) {
      throw new Error('Streaming request failed: No valid response from provider');
    }
    
    return {
      streamIterator,
      firstChunk
    };
  }

  /**
   * åˆå§‹åŒ–æµå¼å“åº”å¤´
   */
  private initializeStreamResponse(reply: FastifyReply): void {
    reply.raw.writeHead(200, {
      'Content-Type': 'text/event-stream',
      'Cache-Control': 'no-cache',
      'Connection': 'keep-alive',
      'Access-Control-Allow-Origin': '*'
    });
  }

  /**
   * å‘é€message_startäº‹ä»¶
   */
  private async sendMessageStart(
    reply: FastifyReply,
    request: BaseRequest,
    requestId: string
  ): Promise<string> {
    const messageId = `msg_${Date.now()}`;
    const modelForStreaming = request.metadata?.originalModel || request.model;
    
    this.deps.logger.debug('Streaming message start', {
      originalRequestModel: request.model,
      originalModelFromMetadata: request.metadata?.originalModel,
      targetModel: request.metadata?.targetModel,
      modelForStreaming,
      hasOriginalModel: !!request.metadata?.originalModel
    }, requestId, 'streaming');
    
    this.sendSSEEvent(reply, 'message_start', {
      type: 'message_start',
      message: {
        id: messageId,
        type: 'message',
        role: 'assistant',
        content: [],
        model: modelForStreaming,
        stop_reason: null,
        stop_sequence: null,
        usage: {
          input_tokens: 0,
          output_tokens: 0
        }
      }
    });
    
    return messageId;
  }

  /**
   * å¤„ç†æµå¼æ•°æ®çš„æ ¸å¿ƒé€»è¾‘
   */
  private async processStreamData(
    streamIterator: AsyncIterator<any>,
    firstChunk: any,
    reply: FastifyReply,
    request: BaseRequest,
    provider: Provider,
    requestId: string,
    messageId: string
  ): Promise<{ outputTokens: number; chunkCount: number; hasToolUse: boolean }> {
    let outputTokens = 0;
    let chunkCount = 0;
    let hasToolUse = false;
    let currentChunk = firstChunk.value;
    let isDone = firstChunk.done;

    // å¤„ç†ç¬¬ä¸€ä¸ªå—
    if (currentChunk) {
      await this.processChunk(currentChunk, reply, request, provider, requestId);
      chunkCount++;
    }

    // å¤„ç†åç»­æ•°æ®å—
    while (!isDone && currentChunk) {
      const processedResult = await this.processChunk(
        currentChunk,
        reply,
        request,
        provider,
        requestId
      );
      
      if (processedResult.hasToolUse) {
        hasToolUse = true;
      }
      
      outputTokens += processedResult.tokens;
      chunkCount++;
      
      const nextResult = await streamIterator.next();
      currentChunk = nextResult.value;
      isDone = nextResult.done;
    }

    return { outputTokens, chunkCount, hasToolUse };
  }

  /**
   * å¤„ç†å•ä¸ªæ•°æ®å—
   */
  private async processChunk(
    chunk: any,
    reply: FastifyReply,
    request: BaseRequest,
    provider: Provider,
    requestId: string
  ): Promise<{ tokens: number; hasToolUse: boolean }> {
    try {
      // åº”ç”¨ç»Ÿä¸€é¢„å¤„ç†
      const preprocessedChunk = await this.deps.unifiedPreprocessor.preprocessStreaming(
        chunk,
        provider as any,
        request.model,
        requestId
      );
      
      // åº”ç”¨å“åº”æµæ°´çº¿å¤„ç†
      let processedChunk = preprocessedChunk;
      if (preprocessedChunk.data) {
        const pipelineContext = {
          provider: provider.name || 'unknown',
          model: request.model,
          requestId,
          isStreaming: true,
          timestamp: Date.now()
        };
        
        const processedData = await this.deps.responsePipeline.process(
          preprocessedChunk.data,
          pipelineContext
        );
        processedChunk = { ...preprocessedChunk, data: processedData };
      }
      
      // å¤„ç†åœæ­¢ä¿¡å·å’Œå·¥å…·è°ƒç”¨
      const chunkResult = this.handleChunkEvents(processedChunk, reply, provider, request, requestId);
      
      // è®¡ç®—tokenæ•°é‡
      const tokens = this.calculateChunkTokens(processedChunk);
      
      return {
        tokens,
        hasToolUse: chunkResult.hasToolUse
      };
      
    } catch (error) {
      this.deps.logger.warn('Chunk processing failed, using original', {
        error: error instanceof Error ? error.message : String(error),
        chunkEvent: chunk.event
      }, requestId, 'streaming-chunk');
      
      this.sendSSEEvent(reply, chunk.event, chunk.data);
      return { tokens: 0, hasToolUse: false };
    }
  }

  /**
   * å¤„ç†å—äº‹ä»¶ï¼ˆåœæ­¢ä¿¡å·ã€å·¥å…·è°ƒç”¨ç­‰ï¼‰
   */
  private handleChunkEvents(
    chunk: any,
    reply: FastifyReply,
    provider: Provider,
    request: BaseRequest,
    requestId: string
  ): { hasToolUse: boolean } {
    let hasToolUse = false;

    if (chunk.event === 'message_delta' && chunk.data?.delta?.stop_reason) {
      const stopReason = chunk.data.delta.stop_reason;
      const isToolUse = stopReason === 'tool_use';
      
      if (isToolUse) {
        hasToolUse = true;
        this.sendSSEEvent(reply, chunk.event, chunk.data);
        this.deps.logger.logFinishReason?.(stopReason, {
          provider: provider.name,
          model: request.model,
          responseType: 'streaming',
          action: 'preserved-for-continuation'
        }, requestId, 'streaming-tool-use');
      } else {
        // ç§»é™¤éå·¥å…·è°ƒç”¨çš„stop_reason
        const filteredData = { ...chunk.data };
        if (filteredData.delta) {
          filteredData.delta = { ...filteredData.delta };
          delete filteredData.delta.stop_reason;
          delete filteredData.delta.stop_sequence;
        }
        this.sendSSEEvent(reply, chunk.event, filteredData);
      }
    } else if (chunk.event === 'message_stop') {
      // ğŸ”§ ä¿®å¤ï¼šå§‹ç»ˆå‘é€message_stopäº‹ä»¶ï¼Œä¸å†è¿›è¡Œæ¡ä»¶è¿‡æ»¤
      this.sendSSEEvent(reply, chunk.event, chunk.data);
    } else {
      // æ­£å¸¸è½¬å‘å…¶ä»–äº‹ä»¶
      this.sendSSEEvent(reply, chunk.event, chunk.data);
    }

    return { hasToolUse };
  }

  /**
   * è®¡ç®—æ•°æ®å—çš„tokenæ•°é‡
   */
  private calculateChunkTokens(chunk: any): number {
    let tokens = 0;
    
    if (chunk.event === 'content_block_delta') {
      if (chunk.data?.delta?.text) {
        tokens += Math.ceil(chunk.data.delta.text.length / 4);
      } else if (chunk.data?.delta?.partial_json) {
        tokens += Math.ceil(chunk.data.delta.partial_json.length / 4);
      }
    } else if (chunk.event === 'content_block_start' && chunk.data?.content_block?.name) {
      tokens += Math.ceil(chunk.data.content_block.name.length / 4);
    }
    
    return tokens;
  }

  /**
   * å®Œæˆæµå¼å“åº”
   */
  private async finalizeStreamResponse(
    reply: FastifyReply,
    outputTokens: number,
    requestId: string
  ): Promise<void> {
    // å‘é€content_block_stopäº‹ä»¶
    this.sendSSEEvent(reply, 'content_block_stop', {
      type: 'content_block_stop',
      index: 0
    });

    // å‘é€usageä¿¡æ¯ï¼ˆä¸åŒ…å«åœæ­¢ä¿¡å·ï¼‰
    this.sendSSEEvent(reply, 'message_delta', {
      type: 'message_delta',
      delta: {},
      usage: {
        output_tokens: outputTokens
      }
    });

    // ç»“æŸHTTPè¿æ¥
    reply.raw.end();
    
    this.deps.logger.debug('Streaming request completed', {
      outputTokens
    }, requestId, 'streaming-finalize');
  }

  /**
   * å¤„ç†æµå¼é”™è¯¯
   */
  private async handleStreamingError(
    error: any,
    reply: FastifyReply,
    provider: Provider,
    request: BaseRequest,
    requestId: string,
    context: {
      outputTokens: number;
      chunkCount: number;
      streamInitialized: boolean;
    }
  ): Promise<void> {
    const errorMessage = error instanceof Error ? error.message : 'Stream processing failed';
    const providerName = provider.name || 'unknown';
    const modelName = request.metadata?.targetModel || request.model || 'unknown';
    
    // è¯¦ç»†é”™è¯¯æ—¥å¿—
    this.deps.logger.error('Streaming request failed', {
      requestId,
      provider: providerName,
      model: modelName,
      error: errorMessage,
      chunkCount: context.chunkCount,
      outputTokens: context.outputTokens,
      streamInitialized: context.streamInitialized
    }, requestId, 'streaming-error');
    
    // ä½¿ç”¨ç»Ÿä¸€é”™è¯¯å¤„ç†
    handleStreamingError(error, reply, {
      requestId,
      providerId: providerName,
      model: modelName
    });
    
    // éªŒè¯é”™è¯¯å¤„ç†
    UnifiedErrorHandler.validateErrorHandling(error, reply, {
      requestId,
      providerId: providerName,
      model: modelName,
      stage: 'streaming',
      isStreaming: true
    });
  }

  /**
   * å‘é€SSEäº‹ä»¶
   */
  private sendSSEEvent(reply: FastifyReply, event: string, data: any): void {
    const eventData = JSON.stringify(data);
    reply.raw.write(`event: ${event}\n`);
    reply.raw.write(`data: ${eventData}\n\n`);
  }
}

/**
 * åˆ›å»ºStreaming Handlerå®ä¾‹çš„å·¥å‚å‡½æ•°
 */
export function createStreamingHandler(deps: StreamingHandlerDependencies): StreamingHandler {
  return new StreamingHandler(deps);
}