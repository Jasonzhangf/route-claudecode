#!/usr/bin/env node

/**
 * å“åº”æ•°æ®æ”¶é›†æµ‹è¯•
 * æ”¶é›†å„ProviderçœŸå®å“åº”æ•°æ®å»ºç«‹å“åº”æ•°æ®åº“
 * 
 * @author Jason Zhang  
 * @version 1.0.0
 */

import fs from 'fs';
import path from 'path';
import { fileURLToPath } from 'url';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

// é…ç½®
const BASE_URL = 'http://localhost';
const PORTS = [5506, 5508, 5509]; // LM Studio, ShuaiHong, ModelScope
const RESPONSE_DB_DIR = '/Users/fanzhang/.route-claudecode/database/response-data';

console.log('ğŸ”„ å¯åŠ¨å“åº”æ•°æ®æ”¶é›†æµ‹è¯•...');

/**
 * åˆ›å»ºå“åº”æ•°æ®ç›®å½•ç»“æ„
 */
async function setupResponseDataDirectory() {
    const directories = [
        `${RESPONSE_DB_DIR}/openai-protocol/lmstudio/qwen3-30b`,
        `${RESPONSE_DB_DIR}/openai-protocol/lmstudio/glm-4.5-air`,
        `${RESPONSE_DB_DIR}/openai-protocol/shuaihong/claude-4-sonnet`,
        `${RESPONSE_DB_DIR}/openai-protocol/shuaihong/gemini-2.5-pro`,
        `${RESPONSE_DB_DIR}/openai-protocol/modelscope/zhipuai-glm-4.5`
    ];

    for (const dir of directories) {
        await fs.promises.mkdir(dir, { recursive: true });
        console.log(`âœ… åˆ›å»ºç›®å½•: ${dir}`);
    }
}

/**
 * æµ‹è¯•è¯·æ±‚é…ç½®
 */
const TEST_REQUESTS = [
    {
        name: 'simple-text',
        request: {
            model: 'gpt-4',
            messages: [
                { role: 'user', content: 'Hello, how are you?' }
            ],
            max_tokens: 100,
            temperature: 0.7
        }
    },
    {
        name: 'tool-call-request',
        request: {
            model: 'gpt-4',
            messages: [
                { role: 'user', content: 'Please create a todo item for me: Review the project documentation.' }
            ],
            tools: [
                {
                    type: 'function',
                    function: {
                        name: 'TodoWrite',
                        description: 'Create and manage todo items',
                        parameters: {
                            type: 'object',
                            properties: {
                                todos: {
                                    type: 'array',
                                    items: {
                                        type: 'object',
                                        properties: {
                                            content: { type: 'string' },
                                            status: { type: 'string', enum: ['pending', 'in_progress', 'completed'] },
                                            priority: { type: 'string', enum: ['high', 'medium', 'low'] }
                                        },
                                        required: ['content', 'status', 'priority']
                                    }
                                }
                            },
                            required: ['todos']
                        }
                    }
                }
            ],
            max_tokens: 500,
            temperature: 0
        }
    },
    {
        name: 'multi-turn-conversation',
        request: {
            model: 'gpt-4',
            messages: [
                { role: 'user', content: 'What is the capital of France?' },
                { role: 'assistant', content: 'The capital of France is Paris.' },
                { role: 'user', content: 'What is its population?' }
            ],
            max_tokens: 150,
            temperature: 0.5
        }
    }
];

/**
 * æ£€æŸ¥æœåŠ¡å¯ç”¨æ€§
 */
async function checkServiceHealth(port) {
    try {
        const response = await fetch(`${BASE_URL}:${port}/health`);
        return response.ok;
    } catch (error) {
        return false;
    }
}

/**
 * å‘é€æµ‹è¯•è¯·æ±‚å¹¶æ”¶é›†å“åº”
 */
async function collectResponseData(port, testRequest) {
    const url = `${BASE_URL}:${port}/v1/chat/completions`;
    
    try {
        console.log(`ğŸ“¤ å‘é€è¯·æ±‚åˆ°ç«¯å£ ${port}: ${testRequest.name}`);
        
        const response = await fetch(url, {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
                'Accept': 'application/json'
            },
            body: JSON.stringify({
                ...testRequest.request,
                stream: false  // å…ˆæ”¶é›†éæµå¼å“åº”
            })
        });

        if (!response.ok) {
            console.log(`âŒ è¯·æ±‚å¤±è´¥ (${port}): ${response.status} ${response.statusText}`);
            return null;
        }

        const responseData = await response.json();
        
        // æ·»åŠ å…ƒæ•°æ®
        const enrichedData = {
            timestamp: new Date().toISOString(),
            port: port,
            testName: testRequest.name,
            responseMetadata: {
                status: response.status,
                statusText: response.statusText,
                headers: Object.fromEntries(response.headers.entries())
            },
            request: testRequest.request,
            response: responseData
        };

        console.log(`âœ… æ”¶åˆ°å“åº” (${port}): ${responseData.model || 'unknown-model'}`);
        
        // æ£€æµ‹å·¥å…·è°ƒç”¨
        if (responseData.choices && responseData.choices[0]) {
            const choice = responseData.choices[0];
            const hasToolCalls = choice.message?.tool_calls && choice.message.tool_calls.length > 0;
            const hasToolCallInContent = choice.message?.content && 
                (choice.message.content.includes('Tool call:') || choice.message.content.includes('function'));
            const finishReason = choice.finish_reason;

            enrichedData.toolCallAnalysis = {
                hasStandardToolCalls: hasToolCalls,
                hasToolCallInContent: hasToolCallInContent,
                finishReason: finishReason,
                needsFix: (hasToolCalls || hasToolCallInContent) && finishReason !== 'tool_calls'
            };

            if (hasToolCalls || hasToolCallInContent) {
                console.log(`ğŸ”§ æ£€æµ‹åˆ°å·¥å…·è°ƒç”¨ (${port}): finish_reason=${finishReason}`);
            }
        }

        return enrichedData;

    } catch (error) {
        console.log(`âŒ è¯·æ±‚å¼‚å¸¸ (${port}): ${error.message}`);
        return null;
    }
}

/**
 * ç¡®å®šä¿å­˜è·¯å¾„
 */
function determineResponseDataPath(port, responseData) {
    const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
    
    // æ ¹æ®ç«¯å£ç¡®å®šproviderè·¯å¾„
    let providerPath;
    switch (port) {
        case 5506:
            // LM Studio - éœ€è¦æ ¹æ®å®é™…è¿”å›çš„æ¨¡å‹åç¡®å®š
            if (responseData.response.model?.includes('glm')) {
                providerPath = 'openai-protocol/lmstudio/glm-4.5-air';
            } else {
                providerPath = 'openai-protocol/lmstudio/qwen3-30b';
            }
            break;
        case 5508:
            providerPath = 'openai-protocol/shuaihong/claude-4-sonnet';
            break;
        case 5509:
            providerPath = 'openai-protocol/modelscope/zhipuai-glm-4.5';
            break;
        default:
            providerPath = `unknown-provider/port-${port}`;
    }

    const filename = `response-${responseData.testName}-${timestamp}.json`;
    return path.join(RESPONSE_DB_DIR, providerPath, filename);
}

/**
 * ä¿å­˜å“åº”æ•°æ®
 */
async function saveResponseData(responseData) {
    if (!responseData) return null;
    
    const filePath = determineResponseDataPath(responseData.port, responseData);
    
    // ç¡®ä¿ç›®å½•å­˜åœ¨
    await fs.promises.mkdir(path.dirname(filePath), { recursive: true });
    
    // ä¿å­˜æ•°æ®
    await fs.promises.writeFile(filePath, JSON.stringify(responseData, null, 2));
    
    console.log(`ğŸ’¾ ä¿å­˜å“åº”æ•°æ®: ${filePath}`);
    return filePath;
}

/**
 * ä¸»æ”¶é›†æµç¨‹
 */
async function runResponseDataCollection() {
    console.log('ğŸš€ å¼€å§‹å“åº”æ•°æ®æ”¶é›†...\n');

    const collectionResults = {
        timestamp: new Date().toISOString(),
        totalRequests: 0,
        successfulResponses: 0,
        toolCallResponses: 0,
        savedFiles: [],
        errors: []
    };

    // è®¾ç½®ç›®å½•ç»“æ„
    await setupResponseDataDirectory();

    // æ£€æŸ¥æœåŠ¡å¯ç”¨æ€§
    const availablePorts = [];
    for (const port of PORTS) {
        const isHealthy = await checkServiceHealth(port);
        if (isHealthy) {
            availablePorts.push(port);
            console.log(`âœ… ç«¯å£ ${port} æœåŠ¡æ­£å¸¸`);
        } else {
            console.log(`âŒ ç«¯å£ ${port} æœåŠ¡ä¸å¯ç”¨`);
            collectionResults.errors.push(`Port ${port} service unavailable`);
        }
    }

    if (availablePorts.length === 0) {
        console.log('âŒ æ²¡æœ‰å¯ç”¨çš„æœåŠ¡ç«¯å£');
        return collectionResults;
    }

    // å¯¹æ¯ä¸ªå¯ç”¨ç«¯å£æ‰§è¡Œæ‰€æœ‰æµ‹è¯•è¯·æ±‚
    for (const port of availablePorts) {
        console.log(`\nğŸ”„ æµ‹è¯•ç«¯å£ ${port}...`);
        
        for (const testRequest of TEST_REQUESTS) {
            collectionResults.totalRequests++;
            
            const responseData = await collectResponseData(port, testRequest);
            if (responseData) {
                collectionResults.successfulResponses++;
                
                if (responseData.toolCallAnalysis?.hasStandardToolCalls || 
                    responseData.toolCallAnalysis?.hasToolCallInContent) {
                    collectionResults.toolCallResponses++;
                }
                
                const savedPath = await saveResponseData(responseData);
                if (savedPath) {
                    collectionResults.savedFiles.push(savedPath);
                }
            } else {
                collectionResults.errors.push(`Failed to collect data from port ${port} for test ${testRequest.name}`);
            }
            
            // çŸ­æš‚å»¶è¿Ÿé¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
            await new Promise(resolve => setTimeout(resolve, 1000));
        }
    }

    // ä¿å­˜æ”¶é›†æŠ¥å‘Š
    const reportPath = path.join(__dirname, '../output/functional', `response-data-collection-${Date.now()}.json`);
    await fs.promises.mkdir(path.dirname(reportPath), { recursive: true });
    await fs.promises.writeFile(reportPath, JSON.stringify(collectionResults, null, 2));

    // è¾“å‡ºç»“æœ
    console.log('\n' + '='.repeat(80));
    console.log('ğŸ§ª å“åº”æ•°æ®æ”¶é›†æµ‹è¯•ç»“æœ');
    console.log('='.repeat(80));
    console.log(`ğŸ“Š æ€»è¯·æ±‚æ•°: ${collectionResults.totalRequests}`);
    console.log(`âœ… æˆåŠŸå“åº”: ${collectionResults.successfulResponses}`);
    console.log(`ğŸ”§ å·¥å…·è°ƒç”¨å“åº”: ${collectionResults.toolCallResponses}`);
    console.log(`ğŸ’¾ ä¿å­˜æ–‡ä»¶æ•°: ${collectionResults.savedFiles.length}`);
    console.log(`âŒ é”™è¯¯æ•°é‡: ${collectionResults.errors.length}`);
    console.log(`ğŸ“„ è¯¦ç»†æŠ¥å‘Š: ${reportPath}`);

    if (collectionResults.errors.length > 0) {
        console.log('\nğŸš¨ é”™è¯¯åˆ—è¡¨:');
        collectionResults.errors.forEach((error, index) => {
            console.log(`   ${index + 1}. ${error}`);
        });
    }

    console.log('\nğŸ’¡ æ”¶é›†çš„å“åº”æ•°æ®ä¿å­˜åœ¨:');
    console.log(`   ${RESPONSE_DB_DIR}`);
    console.log('\nğŸ¯ ä¸‹ä¸€æ­¥: ä½¿ç”¨æ”¶é›†çš„å“åº”æ•°æ®æ›´æ–°å·¥å…·è°ƒç”¨æ£€æµ‹æµ‹è¯•');

    return collectionResults;
}

// æ‰§è¡Œæµ‹è¯•
if (import.meta.url === `file://${process.argv[1]}`) {
    runResponseDataCollection()
        .then(results => {
            process.exit(results.errors.length > 0 ? 1 : 0);
        })
        .catch(error => {
            console.error('ğŸ’¥ å“åº”æ•°æ®æ”¶é›†å¤±è´¥:', error);
            process.exit(1);
        });
}

export { runResponseDataCollection };