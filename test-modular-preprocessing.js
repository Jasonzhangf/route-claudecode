#!/usr/bin/env node

/**
 * æ¨¡å—åŒ–é¢„å¤„ç†åŠŸèƒ½æµ‹è¯•
 * æµ‹è¯•æ‹†åˆ†åçš„å„ä¸ªé¢„å¤„ç†æ¨¡å—
 * @author Jason Zhang
 */

import { 
    OpenAICompatiblePreprocessor,
    FeatureDetector,
    TextToolParser,
    JSONToolFixer,
    StandardToolFixer 
} from './src/v3/preprocessor/index.js';

console.log('ğŸ§ª æ¨¡å—åŒ–é¢„å¤„ç†åŠŸèƒ½æµ‹è¯•');
console.log('=' * 50);

// æµ‹è¯•æ•°æ®
const testContext = {
    providerId: 'modelscope-openai',
    config: {
        endpoint: 'https://api-inference.modelscope.cn/v1/chat/completions',
        modelSpecific: {
            'GLM-4.5': { toolCallFormat: 'text-based' }
        }
    }
};

const testRequest = {
    model: 'ZhipuAI/GLM-4.5',
    messages: [{ role: 'user', content: 'Search for AI info' }],
    tools: [{ function: { name: 'search' } }]
};

async function testModules() {
    console.log('\nğŸ“‹ 1. ç‰¹å¾æ£€æµ‹å™¨æµ‹è¯•');
    console.log('-' * 30);
    
    const needsTextParsing = FeatureDetector.needsTextBasedToolCallParsing(testRequest, testContext);
    const needsEnhancedJSON = FeatureDetector.needsEnhancedJSONFormat(testRequest, testContext);
    const needsStandardFormat = FeatureDetector.needsStandardOpenAIFormat(testRequest, testContext);
    
    console.log(`âœ… éœ€è¦æ–‡æœ¬å·¥å…·è°ƒç”¨è§£æ: ${needsTextParsing}`);
    console.log(`âœ… éœ€è¦å¢å¼ºJSONæ ¼å¼: ${needsEnhancedJSON}`);
    console.log(`âœ… éœ€è¦æ ‡å‡†OpenAIæ ¼å¼: ${needsStandardFormat}`);
    
    console.log('\nğŸ“‹ 2. é¢„å¤„ç†å™¨æµ‹è¯•');
    console.log('-' * 30);
    
    try {
        const preprocessor = new OpenAICompatiblePreprocessor(testContext.config);
        const processed = await preprocessor.processRequest(testRequest, testContext);
        
        console.log(`âœ… é¢„å¤„ç†æˆåŠŸ`);
        console.log(`   - æ¸©åº¦: ${processed.temperature}`);
        console.log(`   - å·¥å…·æ•°é‡: ${processed.tools?.length || 0}`);
        console.log(`   - å·¥å…·é€‰æ‹©: ${processed.tool_choice}`);
        
    } catch (error) {
        console.log(`âŒ é¢„å¤„ç†å¤±è´¥: ${error.message}`);
    }
    
    console.log('\nğŸ“‹ 3. å“åº”å¤„ç†å™¨æµ‹è¯•');
    console.log('-' * 30);
    
    // æ–‡æœ¬å·¥å…·è°ƒç”¨å“åº”æµ‹è¯•
    const textResponse = {
        choices: [{
            message: {
                content: 'I will search. Tool call: search(query: "AI information")'
            }
        }]
    };
    
    const hasTextCalls = FeatureDetector.hasTextBasedToolCallsInResponse(textResponse);
    console.log(`âœ… æ–‡æœ¬å·¥å…·è°ƒç”¨æ£€æµ‹: ${hasTextCalls}`);
    
    if (hasTextCalls) {
        const parsed = TextToolParser.parseTextBasedToolCallResponse(textResponse, testRequest, testContext);
        console.log(`âœ… æ–‡æœ¬å·¥å…·è§£æ: ${parsed.choices[0].message.tool_calls?.length || 0} ä¸ªå·¥å…·è°ƒç”¨`);
    }
    
    // JSONä¿®å¤æµ‹è¯•
    const malformedResponse = {
        choices: [{
            message: {
                tool_calls: [{
                    function: {
                        name: 'search',
                        arguments: '{"query": "test",}'  // æ ¼å¼é”™è¯¯
                    }
                }]
            }
        }]
    };
    
    const needsJSONFix = FeatureDetector.hasmalformedJSONToolCalls(malformedResponse);
    console.log(`âœ… JSONä¿®å¤æ£€æµ‹: ${needsJSONFix}`);
    
    if (needsJSONFix) {
        const fixed = JSONToolFixer.parseAndFixJSONToolCallResponse(malformedResponse, testRequest, testContext);
        console.log(`âœ… JSONä¿®å¤å®Œæˆ: ${fixed.choices[0].message.tool_calls?.length || 0} ä¸ªå·¥å…·è°ƒç”¨`);
    }
    
    console.log('\nğŸ‰ æ‰€æœ‰æ¨¡å—æµ‹è¯•å®Œæˆï¼');
    console.log('\nğŸ“Š æ¨¡å—åŒ–æ¶æ„ä¼˜åŠ¿:');
    console.log('âœ… å•ä¸€èŒè´£: æ¯ä¸ªæ¨¡å—ä¸“æ³¨äºç‰¹å®šåŠŸèƒ½');
    console.log('âœ… æ˜“äºæµ‹è¯•: å¯ç‹¬ç«‹æµ‹è¯•å„ä¸ªæ¨¡å—');
    console.log('âœ… æ˜“äºç»´æŠ¤: ä¿®æ”¹å•ä¸ªåŠŸèƒ½ä¸å½±å“å…¶ä»–æ¨¡å—');
    console.log('âœ… æ˜“äºæ‰©å±•: å¯è½»æ¾æ·»åŠ æ–°çš„ç‰¹å¾æ£€æµ‹æˆ–å¤„ç†å™¨');
}

testModules().catch(console.error);