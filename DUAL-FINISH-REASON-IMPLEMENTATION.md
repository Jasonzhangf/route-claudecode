# Dual Finish Reason Logging Implementation

## ğŸ“‹ å®ç°æ¦‚è¿°

æˆåŠŸå®ç°äº†å¢å¼ºçš„finish reason loggingç³»ç»Ÿï¼Œèƒ½å¤ŸåŒæ—¶è®°å½•åŸå§‹æœåŠ¡å™¨å“åº”å’Œè½¬æ¢åçš„Anthropicæ ¼å¼å“åº”ï¼Œä¸ºè°ƒè¯•å’Œç›‘æ§æä¾›å®Œæ•´çš„æ•°æ®é“¾è·¯è·Ÿè¸ªã€‚

## ğŸ¯ å®ç°çš„åŠŸèƒ½

### 1. âœ… Enhanced Dual Finish Reason Logging
- **åŠŸèƒ½**: åŒæ—¶è®°å½•åŸå§‹æœåŠ¡å™¨è¿”å›çš„finish_reasonå’Œè½¬æ¢åçš„Anthropicæ ¼å¼stop_reason
- **æ–‡ä»¶ä½ç½®**: `src/logging/unified-logger.ts`
- **æ–°å¢æ–¹æ³•**: `logDualFinishReason(originalReason, convertedReason, provider, data, requestId, stage)`
- **åˆ†ç±»è®°å½•**: ä¸‰ç§ç±»å‹çš„è®°å½•ï¼Œæ˜æ˜¾åŒºåˆ†åŸå§‹å’Œè½¬æ¢åçš„æ•°æ®
  - ğŸ”µ `[ORIGINAL-SERVER-RESPONSE]` - åŸå§‹æœåŠ¡å™¨å“åº”
  - ğŸŸ¢ `[CONVERTED-ANTHROPIC-FORMAT]` - è½¬æ¢åçš„æ ¼å¼
  - ğŸ”„ `[CONVERSION-MAPPING]` - è½¬æ¢æ˜ å°„å…³ç³»
- **è§†è§‰åˆ†éš”**: ä½¿ç”¨è¾¹ç•Œçº¿å’Œé¢œè‰²æ ‡è®°è¿›è¡Œæ¸…æ™°åŒºåˆ†
- **æ•°æ®ä¿å­˜**: ç‹¬ç«‹çš„`finish_reason.log`æ–‡ä»¶ + å¸¸è§„æ—¥å¿—æ–‡ä»¶

### 2. âœ… Max Tokens Error Handler  
- **åŠŸèƒ½**: æ£€æµ‹max_tokensé”™è¯¯å¹¶è¿”å›ç”¨æˆ·å‹å¥½çš„API 500é”™è¯¯
- **æ–‡ä»¶ä½ç½®**: `src/utils/max-tokens-error-handler.ts`
- **é”™è¯¯æ£€æµ‹**: è‡ªåŠ¨è¯†åˆ«finish_reasonä¸º"max_tokens"æˆ–"length"çš„å“åº”
- **é”™è¯¯å“åº”**: ç»“æ„åŒ–çš„500é”™è¯¯ï¼ŒåŒ…å«è¯¦ç»†ä¿¡æ¯å’Œå»ºè®®

### 3. âœ… Advanced Error Handling Options
- **åŠŸèƒ½**: è®¾è®¡äº†6ç§é«˜çº§é”™è¯¯å¤„ç†æ‰©å±•é€‰é¡¹
- **æ–‡ä»¶ä½ç½®**: `src/utils/advanced-error-handling-options.md`
- **é€‰é¡¹**: Tokené™åˆ¶ç®¡ç†ã€å¤šçº§é”™è¯¯å“åº”ã€è‡ªåŠ¨é‡è¯•æœºåˆ¶ã€é€šçŸ¥ç³»ç»Ÿã€æ€§èƒ½é™çº§ã€UXä¼˜åŒ–

### 4. âœ… Enhanced Streaming Support
- **åŠŸèƒ½**: Streamingå“åº”ä¸­çš„dual finish reasonè®°å½•
- **æ–‡ä»¶ä½ç½®**: `src/transformers/streaming.ts`
- **æ”¯æŒæ ¼å¼**: OpenAI â†’ Anthropic å’Œ Anthropic â†’ OpenAI åŒå‘è½¬æ¢è®°å½•

## ğŸ”§ æŠ€æœ¯å®ç°ç»†èŠ‚

### æ ¸å¿ƒæ–‡ä»¶ä¿®æ”¹

#### 1. ç»Ÿä¸€æ—¥å¿—ç³»ç»Ÿå¢å¼º (`src/logging/unified-logger.ts`)
```typescript
// æ–°å¢æ–¹æ³•ï¼šåŒæ—¶è®°å½•åŸå§‹å’Œè½¬æ¢åçš„finish reason
logDualFinishReason(
  originalReason: string, 
  convertedReason: string, 
  provider: string,
  data?: any, 
  requestId?: string, 
  stage?: string
): void {
  const message = `Finish reason conversion: ${originalReason} â†’ ${convertedReason}`;
  const entry = this.formatEntry('finish_reason', 'info', message, {
    originalFinishReason: originalReason,    // æœåŠ¡å™¨åŸå§‹è¿”å›
    convertedStopReason: convertedReason,    // è½¬æ¢åçš„Anthropicæ ¼å¼
    provider,
    conversionMapping: `${originalReason} â†’ ${convertedReason}`,
    ...data
  }, requestId, stage);
}
```

#### 2. å…¼å®¹æ€§æ—¥å¿—å±‚æ›´æ–° (`src/utils/logger.ts`)
```typescript
// æ·»åŠ dual loggingæ”¯æŒ
logDualFinishReason: (originalReason: string, convertedReason: string, provider: string, data?: any, requestId?: string, stage?: string) => {
  getCompatLogger().logDualFinishReason(originalReason, convertedReason, provider, data, requestId, stage);
}
```

#### 3. è¾“å‡ºå¤„ç†å™¨é›†æˆ (`src/output/anthropic/processor.ts`)
```typescript
// validateAndNormalizeæ–¹æ³•ä¸­çš„dual logging
if (originalStopReason && originalStopReason !== finalStopReason) {
  logger.logDualFinishReason(
    originalStopReason,
    finalStopReason,
    originalRequest.metadata?.targetProvider || 'unknown',
    { model, responseType: 'non-streaming', context: 'validateAndNormalize' },
    requestId,
    'dual-reason-validate'
  );
}

// convertFromOpenAIæ–¹æ³•ä¸­çš„dual logging
logger.logDualFinishReason(
  originalFinishReason || 'unknown',
  convertedStopReason,
  originalRequest.metadata?.targetProvider || 'unknown',
  { model, responseType: 'non-streaming', context: 'convertFromOpenAI' },
  requestId,
  'dual-reason-openai-convert'
);
```

#### 4. æµå¼è½¬æ¢å™¨æ›´æ–° (`src/transformers/streaming.ts`)
```typescript
// OpenAI â†’ Anthropic streaming
logger.logDualFinishReason(
  originalFinishReason,
  stopReason,
  this.options.sourceFormat,
  {
    model: this.model,
    responseType: 'streaming',
    context: 'streaming-openai-to-anthropic',
    conversionMethod: 'mapFinishReason'
  },
  this.requestId,
  'dual-reason-streaming'
);

// Anthropic â†’ OpenAI streaming  
logger.logDualFinishReason(
  originalStopReason,
  mappedFinishReason,
  this.options.sourceFormat,
  {
    model: this.model,
    responseType: 'streaming',
    context: 'streaming-anthropic-to-openai',
    conversionMethod: 'mapStopReason'
  },
  this.requestId,
  'dual-reason-anthropic-streaming'
);
```

### Max Tokens Error Handlerå®ç°

#### æ ¸å¿ƒæ£€æµ‹é€»è¾‘
```typescript
static checkAndThrowMaxTokensError(
  response: any,
  provider: string,
  model: string,
  requestId: string
): void {
  const finishReason = response?.stop_reason || response?.finish_reason;
  
  if (finishReason === 'max_tokens' || finishReason === 'length') {
    const error = new MaxTokensError(
      'Request exceeded maximum token limit',
      provider,
      model,
      finishReason,
      requestId
    );
    throw error;
  }
}
```

#### æœåŠ¡å™¨é”™è¯¯å¤„ç†é›†æˆ (`src/server.ts`)
```typescript
// ğŸš¨ Special handling for MaxTokensError
if (error instanceof Error && (error as any).code === 'MAX_TOKENS_EXCEEDED') {
  return reply.code(500).send(MaxTokensErrorHandler.formatErrorResponse(error as any));
}
```

## ğŸ“Š æµ‹è¯•éªŒè¯

### æµ‹è¯•è„šæœ¬
- **æ–‡ä»¶**: `test-dual-finish-reason-logging.js`
- **æµ‹è¯•åœºæ™¯**: 
  1. OpenAI â†’ Anthropic è½¬æ¢è®°å½•
  2. Anthropic â†’ OpenAI è½¬æ¢è®°å½•  
  3. å¤æ‚provideråœºæ™¯è®°å½•
- **éªŒè¯é¡¹**: æ—¥å¿—æ–‡ä»¶ç”Ÿæˆã€è½¬æ¢ç®­å¤´æ£€æµ‹ã€å®Œæ•´æ•°æ®ä¿å­˜

### æµ‹è¯•ç»“æœ
```
ğŸ‰ SUCCESS: Enhanced dual finish reason logging is working correctly!
   âœ… All test cases recorded with proper separation
   âœ… Original server responses properly tagged (ğŸ”µ)
   âœ… Converted formats properly tagged (ğŸŸ¢)
   âœ… Conversion mappings properly tagged (ğŸ”„)
   âœ… Clear visual separation with boundary markers

æ§åˆ¶å°è¾“å‡ºç¤ºä¾‹:
================================================================================
ğŸ” DUAL FINISH REASON LOGGING
================================================================================
[22:11:31] [INFO] [finish_reason] [req-001] ğŸ”µ [ORIGINAL-SERVER-RESPONSE] openai returned: "tool_calls"
[22:11:31] [INFO] [finish_reason] [req-001] ğŸŸ¢ [CONVERTED-ANTHROPIC-FORMAT] Transformed to: "tool_use"
[22:11:31] [INFO] [finish_reason] [req-001] ğŸ”„ [CONVERSION-MAPPING] tool_calls â•â•â•â•â•â•â•â–º tool_use
================================================================================
```

## ğŸ” æ—¥å¿—æ–‡ä»¶ä½ç½®

### ä¸»è¦æ—¥å¿—æ–‡ä»¶
- **ç‹¬ç«‹æ–‡ä»¶**: `~/.route-claude-code/logs/port-{PORT}/{TIMESTAMP}/finish_reason.log`
- **å¸¸è§„æ—¥å¿—**: `~/.route-claude-code/logs/port-{PORT}/{TIMESTAMP}/*.log`

### æ—¥å¿—æ ¼å¼ç¤ºä¾‹

#### 1. åŸå§‹æœåŠ¡å™¨å“åº”è®°å½•
```json
{
  "timestamp": "2025-08-05T14:11:31.855Z",
  "beijingTime": "2025-08-05 22:11:31",
  "level": "info",
  "category": "finish_reason",
  "message": "ğŸ”µ [ORIGINAL-SERVER-RESPONSE] openai returned: \"tool_calls\"",
  "data": {
    "type": "original_server_response",
    "originalFinishReason": "tool_calls",
    "provider": "openai",
    "serverResponseType": "raw_finish_reason",
    "timestamp": "2025-08-05T14:11:31.855Z",
    "model": "gpt-4",
    "responseType": "non-streaming",
    "context": "convertFromOpenAI"
  },
  "port": 5508,
  "requestId": "req-12345",
  "stage": "conversion_original"
}
```

#### 2. è½¬æ¢åæ ¼å¼è®°å½•
```json
{
  "timestamp": "2025-08-05T14:11:31.856Z",
  "beijingTime": "2025-08-05 22:11:31",
  "level": "info",
  "category": "finish_reason",
  "message": "ğŸŸ¢ [CONVERTED-ANTHROPIC-FORMAT] Transformed to: \"tool_use\"",
  "data": {
    "type": "converted_anthropic_format",
    "convertedStopReason": "tool_use",
    "provider": "openai",
    "conversionTarget": "anthropic_stop_reason",
    "timestamp": "2025-08-05T14:11:31.856Z",
    "model": "gpt-4",
    "responseType": "non-streaming",
    "context": "convertFromOpenAI"
  },
  "port": 5508,
  "requestId": "req-12345",
  "stage": "conversion_converted"
}
```

#### 3. è½¬æ¢æ˜ å°„å…³ç³»è®°å½•
```json
{
  "timestamp": "2025-08-05T14:11:31.857Z",
  "beijingTime": "2025-08-05 22:11:31",
  "level": "info",
  "category": "finish_reason",
  "message": "ğŸ”„ [CONVERSION-MAPPING] tool_calls â•â•â•â•â•â•â•â–º tool_use",
  "data": {
    "type": "conversion_mapping",
    "originalFinishReason": "tool_calls",
    "convertedStopReason": "tool_use",
    "provider": "openai",
    "conversionMapping": "tool_calls â•â•â•â•â•â•â•â–º tool_use",
    "conversionDirection": "server_to_anthropic",
    "timestamp": "2025-08-05T14:11:31.857Z",
    "model": "gpt-4",
    "responseType": "non-streaming",
    "context": "convertFromOpenAI"
  },
  "port": 5508,
  "requestId": "req-12345",
  "stage": "conversion_mapping"
}
```

## ğŸš€ éƒ¨ç½²è¦æ±‚

### æ„å»ºçŠ¶æ€
- âœ… TypeScriptç¼–è¯‘é€šè¿‡
- âœ… æ‰€æœ‰ä¾èµ–å…³ç³»æ­£ç¡®
- âœ… å…¼å®¹æ€§å±‚å®Œæ•´æ”¯æŒ

### è¿è¡Œæ—¶æ”¯æŒ
- âœ… éä¾µå…¥å¼å®ç°ï¼Œä¸å½±å“ç°æœ‰åŠŸèƒ½
- âœ… å‘åå…¼å®¹ï¼Œæ”¯æŒåŸæœ‰æ—¥å¿—è°ƒç”¨
- âœ… æ€§èƒ½ä¼˜åŒ–ï¼Œå¼‚æ­¥æ–‡ä»¶å†™å…¥

## ğŸ“ˆ ç›‘æ§å’Œè°ƒè¯•

### è°ƒè¯•èƒ½åŠ›å¢å¼º
1. **å®Œæ•´é“¾è·¯è·Ÿè¸ª**: ä»åŸå§‹APIå“åº”åˆ°æœ€ç»ˆç”¨æˆ·å“åº”çš„å®Œæ•´è½¬æ¢è®°å½•
2. **æ ¼å¼è½¬æ¢ç›‘æ§**: å®æ—¶ç›‘æ§OpenAI/Anthropicæ ¼å¼è½¬æ¢çš„å‡†ç¡®æ€§
3. **é”™è¯¯å®šä½ç²¾ç¡®**: é€šè¿‡requestIdå¿«é€Ÿå®šä½ç‰¹å®šè¯·æ±‚çš„è½¬æ¢è¿‡ç¨‹
4. **æ€§èƒ½åˆ†ææ”¯æŒ**: è®°å½•è½¬æ¢æ“ä½œçš„æ—¶é—´æˆ³å’Œä¸Šä¸‹æ–‡ä¿¡æ¯

### ç”Ÿäº§ç¯å¢ƒä»·å€¼
1. **é—®é¢˜è¯Šæ–­**: å¿«é€Ÿè¯†åˆ«finish reasonæ˜ å°„é—®é¢˜
2. **æ•°æ®åˆ†æ**: ç»Ÿè®¡ä¸åŒproviderçš„stop reasonåˆ†å¸ƒ
3. **æœåŠ¡ç›‘æ§**: ç›‘æ§max tokensé”™è¯¯çš„å‘ç”Ÿé¢‘ç‡
4. **ç”¨æˆ·ä½“éªŒ**: ä¸ºtokenè¶…é™æä¾›æ¸…æ™°çš„é”™è¯¯æç¤º

---

**å®ç°çŠ¶æ€**: âœ… å®Œæˆ  
**æµ‹è¯•çŠ¶æ€**: âœ… é€šè¿‡  
**éƒ¨ç½²çŠ¶æ€**: âœ… å°±ç»ª  
**é¡¹ç›®æ‰€æœ‰è€…**: Jason Zhang  
**å®Œæˆæ—¶é—´**: 2025-08-05