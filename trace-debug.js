#!/usr/bin/env node

async function traceDebug() {
  console.log('ğŸ§ª è·Ÿè¸ªè°ƒè¯•...');
  
  console.log('\n1. å¯¼å…¥å¤„ç†å™¨...');
  try {
    const { LMStudioBufferedProcessor } = await import('./src/v3/provider/openai-compatible/lmstudio-buffered-processor.js');
    console.log('âœ… å¯¼å…¥æˆåŠŸ');
    
    console.log('\n2. åˆ›å»ºå®ä¾‹...');
    const processor = new LMStudioBufferedProcessor();
    console.log('âœ… å®ä¾‹åˆ›å»ºæˆåŠŸ');
    
    console.log('\n3. æ£€æŸ¥æ–¹æ³•...');
    console.log('   process æ–¹æ³•å­˜åœ¨:', typeof processor.process === 'function');
    console.log('   isLMStudioResponse æ–¹æ³•å­˜åœ¨:', typeof processor.isLMStudioResponse === 'function');
    
    console.log('\n4. æµ‹è¯•å‰è°ƒç”¨æ ‡è®°...');
    console.log('   å³å°†è°ƒç”¨ process æ–¹æ³•...');
    
    const testData = {
      data: 'Tool call: Bash({"command": "test"})',
      events: null
    };
    
    const context = {
      sessionId: 'trace-session',
      requestId: 'trace-001',
      timestamp: new Date(),
      metadata: { layer: 'trace' },
      debugEnabled: true
    };
    
    console.log('\n5. æ­£åœ¨è°ƒç”¨ process...');
    const result = await processor.process(testData, context);
    console.log('âœ… process è°ƒç”¨å®Œæˆ');
    
    console.log('\n6. ç»“æœåˆ†æ...');
    console.log('   è¾“å…¥:', testData);
    console.log('   è¾“å‡º:', result);
    console.log('   ç›¸åŒå¯¹è±¡:', result === testData);
    
  } catch (error) {
    console.error('âŒ é”™è¯¯:', error.message);
    console.error('   å †æ ˆ:', error.stack);
  }
}

traceDebug();