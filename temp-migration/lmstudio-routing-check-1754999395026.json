{
  "checkId": "lmstudio-routing-check-1754999393407",
  "timestamp": "2025-08-12T11:49:53.407Z",
  "checks": {
    "lmstudioServer": {
      "success": true,
      "running": true,
      "modelCount": 21,
      "currentModel": "unsloth/gpt-oss-120b-gguf/gpt-oss-120b-q4_k_s-00001-of-00002.gguf",
      "completionTest": false,
      "testResponse": {
        "error": {
          "message": "Model \"local-model\" not found. Please specify a valid model.\n\nYour models:\n\nunsloth/gpt-oss-120b-gguf/gpt-oss-120b-q4_k_s-00001-of-00002.gguf\ngpt-oss-20b-mlx\ngpt-oss-120b-mlx\nunsloth/gpt-oss-120b-gguf/._gpt-oss-120b-q4_k_s-00001-of-00002.gguf\nopenai/gpt-oss-120b\nqwen3-4b-thinking-2507-mlx\ngabriellarson/ii-search-4b-gguf/._ii-search-4b-q4_k_s.gguf\ngabriellarson/ii-search-4b-gguf/ii-search-4b-q4_k_s.gguf\ntext-embedding-nomic-embed-text-v1.5\nqwen3-30b-a3b-instruct-2507-mlx\nglm-4.5-air@3bit\nglm-4.5-air@8bit\nqwen/qwen3-235b-a22b-2507\ngemma-3n-e2b-it-mlx\nbge-small-en-v1.5\nnextcoder-32b-mlx\nqwen/qwq-32b\nexternal/gemma-3-27b-it-ud-q4_k_xl/._gemma-3-27b-it-ud-q4_k_xl.gguf\nexternal/gemma-3-27b-it-ud-q4_k_xl/gemma-3-27b-it-ud-q4_k_xl.gguf\nqwen2.5-vl-72b-instruct\nqwen3-30b-a3b-python-coder-mlx",
          "type": "invalid_request_error",
          "param": "model",
          "code": "model_not_found"
        }
      }
    },
    "routerServer": {
      "success": true,
      "running": true,
      "version": "2.0.0",
      "uptime": 491.452243375,
      "providers": [
        "lmstudio-enhanced"
      ],
      "debug": true,
      "health": "healthy",
      "healthyProviders": 1,
      "totalProviders": 1,
      "providerDetails": {
        "lmstudio-enhanced": true
      }
    },
    "routingConfiguration": {
      "success": true,
      "configPath": "/Users/fanzhang/.route-claudecode/config/v3/single-provider/config-lmstudio-v3-5506.json",
      "config": {
        "name": "LM Studio Configuration v3.0 - Enhanced SDK Integration",
        "description": "v3.0 LM Studio configuration with official SDK priority integration and dynamic detection",
        "version": "3.0.0",
        "configType": "single-provider",
        "server": {
          "port": 5506,
          "host": "127.0.0.1",
          "architecture": "v3.0",
          "layered": true
        },
        "providers": {
          "lmstudio-enhanced": {
            "type": "lmstudio",
            "name": "LM Studio Enhanced v3.0",
            "endpoint": "http://localhost:1234",
            "sdkIntegration": {
              "enabled": true,
              "preferOfficialSDK": true,
              "sdkDetectionTimeout": 5000,
              "fallbackMode": true,
              "performanceOptimization": true,
              "detectionMethods": [
                "cli",
                "api",
                "nodejs"
              ],
              "compatibilityMode": "openai-compatible"
            },
            "authentication": {
              "type": "local-server",
              "credentials": {
                "apiKey": "lm-studio-local-key",
                "serverToken": "local-server"
              },
              "required": false
            },
            "models": [
              "gpt-oss-20b-mlx",
              "unsloth-gpt-oss-120b",
              "local-model-default"
            ],
            "defaultModel": "gpt-oss-20b-mlx",
            "capabilities": {
              "chat": true,
              "completions": true,
              "streaming": false,
              "toolCalling": true,
              "embeddings": false,
              "multimodal": false
            },
            "maxTokens": {
              "gpt-oss-20b-mlx": 131072,
              "unsloth-gpt-oss-120b": 131072,
              "local-model-default": 131072
            },
            "timeout": 300000,
            "forceNonStreaming": true,
            "preprocessing": {
              "enabled": true,
              "preprocessorClass": "LMStudioPreprocessor",
              "transformations": [
                "header-normalization",
                "request-body-optimization",
                "local-server-adaptation"
              ],
              "compatibility": {
                "openaiFormat": true,
                "anthropicFormat": false,
                "geminiFormat": false
              }
            },
            "performance": {
              "localModelOptimization": true,
              "batchRequestsEnabled": false,
              "connectionPooling": true,
              "maxConcurrentRequests": 1,
              "requestTimeout": 300000,
              "healthCheckInterval": 30000
            },
            "description": "v3.0 LM Studio provider with official SDK priority integration, dynamic detection, and enhanced preprocessing"
          }
        },
        "routing": {
          "default": {
            "provider": "lmstudio-enhanced",
            "model": "gpt-oss-20b-mlx"
          },
          "background": {
            "provider": "lmstudio-enhanced",
            "model": "gpt-oss-20b-mlx"
          },
          "thinking": {
            "provider": "lmstudio-enhanced",
            "model": "gpt-oss-20b-mlx"
          },
          "longcontext": {
            "provider": "lmstudio-enhanced",
            "model": "unsloth-gpt-oss-120b"
          },
          "search": {
            "provider": "lmstudio-enhanced",
            "model": "gpt-oss-20b-mlx"
          }
        },
        "layers": {
          "client": {
            "enabled": true,
            "interface": "AnthropicCompatible"
          },
          "router": {
            "enabled": true,
            "strategy": "category-driven",
            "fallbackEnabled": false
          },
          "postProcessor": {
            "enabled": true,
            "processors": [
              "response-formatter",
              "error-handler"
            ]
          },
          "transformer": {
            "enabled": true,
            "bidirectional": true,
            "formats": [
              "anthropic",
              "openai",
              "custom"
            ]
          },
          "providerProtocol": {
            "enabled": true,
            "protocol": "lmstudio-v3",
            "sdkManager": "LMStudioOllamaSDKManager"
          },
          "preprocessor": {
            "enabled": true,
            "class": "LMStudioPreprocessor",
            "modifications": "preprocessing-only"
          },
          "server": {
            "enabled": true,
            "healthCheck": true,
            "monitoring": true
          }
        },
        "debug": {
          "enabled": true,
          "logLevel": "info",
          "traceRequests": true,
          "saveRequests": true,
          "logDir": "~/.route-claudecode/logs/v3",
          "ioRecording": {
            "enabled": true,
            "recordAllLayers": true,
            "databasePath": "~/.route-claudecode/database/v3",
            "replayCapability": true
          },
          "performanceMetrics": {
            "enabled": true,
            "collectTimings": true,
            "auditTrail": true
          }
        },
        "maxTokensHandling": {
          "enableAutoHandling": true,
          "triggerThresholdPercent": 90,
          "strategy": "rolling_truncation",
          "maxRetryAttempts": 1,
          "safetyMarginTokens": 500,
          "zeroFallbackCompliance": true,
          "rollingTruncation": {
            "historyRetentionPercent": 80,
            "useSimplifiedPrompt": true,
            "simplifiedPromptPath": "config/v3/simplified-system-prompt.json"
          },
          "toolCallParsing": {
            "enabled": true,
            "enableTextParsing": true,
            "confidenceThreshold": 0.5,
            "logFailuresToDatabase": true,
            "patchSystemEnabled": true
          },
          "logging": {
            "databasePath": "database/v3/tool-parsing-failures.json",
            "enableDetailedLogging": true,
            "retainLogsForDays": 30
          }
        },
        "governance": {
          "complianceRules": [
            "zero-hardcoding",
            "zero-fallback",
            "preprocessing-only-modifications",
            "standard-interface-compliance",
            "testing-requirements",
            "security-compliance"
          ],
          "templateGeneration": true,
          "integrationWorkflow": true,
          "validationEnabled": true
        },
        "metadata": {
          "createdAt": "2025-08-11T11:45:00.000Z",
          "version": "3.0.0",
          "basedOn": "v2.7.0-config-openai-lmstudio-5506.json",
          "author": "Jason Zhang",
          "compatibility": {
            "v2.7.0": false,
            "v3.0": true,
            "backwardCompatible": false
          },
          "requirements": [
            "LMStudioOllamaSDKManager",
            "LMStudioPreprocessor",
            "v3.0-architecture"
          ]
        }
      },
      "isLMStudioConfig": false,
      "version": "3.0.0",
      "port": 5506
    },
    "actualConnection": {
      "success": true,
      "responseTime": 1567,
      "response": {
        "id": "chatcmpl-ksl5m9kr7egvs2vdgbk07",
        "type": "message",
        "role": "assistant",
        "content": [
          {
            "type": "text",
            "text": "The user asks in Chinese: \"请回答：你是通过什么方式连接的？请简短回答。\" They want a short answer: \"I am an AI language model, no physical connection, I run on servers,"
          }
        ],
        "model": "qwen3-30b",
        "stop_reason": "max_tokens",
        "usage": {
          "input_tokens": 83,
          "output_tokens": 46
        }
      },
      "isMockupResponse": false,
      "connectionWorking": true
    },
    "codeAnalysis": {
      "success": true,
      "filesChecked": 4,
      "mockupIndicators": [
        {
          "file": "src/v3/provider-protocol/base-provider.ts",
          "pattern": "/mock|Mock|MOCK/g",
          "matches": 5,
          "examples": [
            "Mock",
            "Mock",
            "Mock"
          ]
        },
        {
          "file": "src/v3/provider-protocol/base-provider.ts",
          "pattern": "/createMockResponse/g",
          "matches": 4,
          "examples": [
            "createMockResponse",
            "createMockResponse",
            "createMockResponse"
          ]
        },
        {
          "file": "src/v3/session/manager.ts",
          "pattern": "/mock|Mock|MOCK/g",
          "matches": 3,
          "examples": [
            "Mock",
            "Mock",
            "Mock"
          ]
        },
        {
          "file": "src/v3/session/manager.ts",
          "pattern": "/Mock implementation/g",
          "matches": 3,
          "examples": [
            "Mock implementation",
            "Mock implementation",
            "Mock implementation"
          ]
        },
        {
          "file": "src/v3/debug/debug-system.ts",
          "pattern": "/mock|Mock|MOCK/g",
          "matches": 1,
          "examples": [
            "Mock"
          ]
        }
      ],
      "hasMockupCode": true
    }
  },
  "summary": {
    "isMockup": true,
    "isConnectedToLMStudio": false,
    "overallStatus": "mockup"
  }
}