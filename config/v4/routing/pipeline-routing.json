{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "version": "4.0.0",
  "description": "RCC v4.0 四层架构流水线路由配置",
  "lastUpdated": "2024-08-15T00:00:00Z",

  "pipelineArchitecture": {
    "layers": [
      {
        "order": 1,
        "name": "transformer",
        "description": "Anthropic ↔ Protocol转换层",
        "required": true
      },
      {
        "order": 2, 
        "name": "protocol",
        "description": "协议控制转换层（流式↔非流式）",
        "required": true
      },
      {
        "order": 3,
        "name": "server-compatibility", 
        "description": "第三方服务器兼容处理层",
        "required": true
      },
      {
        "order": 4,
        "name": "server",
        "description": "标准服务器协议处理层",
        "required": true
      }
    ],
    "strictLayerEnforcement": true,
    "allowCrossLayerCalls": false
  },

  "routingStrategies": {
    "default": {
      "id": "default-strategy",
      "name": "默认路由策略",
      "description": "根据请求模型和优先级进行路由",
      "algorithm": "priority-weight",
      "fallbackEnabled": false,
      "strictErrorReporting": true
    },
    "loadBalanced": {
      "id": "load-balanced-strategy", 
      "name": "负载均衡路由策略",
      "description": "基于Provider负载进行均衡分发",
      "algorithm": "least-loaded",
      "fallbackEnabled": false,
      "strictErrorReporting": true
    },
    "roundRobin": {
      "id": "round-robin-strategy",
      "name": "轮询路由策略", 
      "description": "轮询所有可用Provider",
      "algorithm": "round-robin",
      "fallbackEnabled": false,
      "strictErrorReporting": true
    }
  },

  "routes": [
    {
      "id": "lmstudio-primary-route",
      "name": "LM Studio主要路由",
      "description": "使用LM Studio作为主要AI服务提供商",
      "enabled": true,
      "priority": 100,
      "weight": 0.8,
      "conditions": {
        "models": ["*"],
        "requestTypes": ["chat", "completion"],
        "features": ["streaming", "tools"]
      },
      "pipeline": {
        "layers": [
          {
            "layer": "transformer",
            "moduleId": "anthropic-to-openai-transformer",
            "config": {
              "targetProtocol": "openai"
            }
          },
          {
            "layer": "protocol", 
            "moduleId": "openai-protocol-module",
            "config": {
              "streamingSupport": true
            }
          },
          {
            "layer": "server-compatibility",
            "moduleId": "lmstudio-compatibility",
            "config": {
              "providerId": "lmstudio-compatibility"
            }
          },
          {
            "layer": "server",
            "moduleId": "openai-server-module", 
            "config": {
              "providerId": "lmstudio-compatibility"
            }
          }
        ]
      },
      "healthCheck": {
        "enabled": true,
        "interval": 30000,
        "timeoutMs": 5000
      }
    },

    {
      "id": "openai-fallback-route",
      "name": "OpenAI官方路由",
      "description": "使用OpenAI官方API（非fallback，独立路由）",
      "enabled": false,
      "priority": 90,
      "weight": 0.6,
      "conditions": {
        "models": ["gpt-4", "gpt-3.5-turbo", "gpt-4o"],
        "requestTypes": ["chat", "completion"], 
        "features": ["streaming", "tools", "vision"]
      },
      "pipeline": {
        "layers": [
          {
            "layer": "transformer",
            "moduleId": "anthropic-to-openai-transformer",
            "config": {
              "targetProtocol": "openai"
            }
          },
          {
            "layer": "protocol",
            "moduleId": "openai-protocol-module", 
            "config": {
              "streamingSupport": true
            }
          },
          {
            "layer": "server-compatibility",
            "moduleId": "passthrough-compatibility",
            "config": {
              "mode": "passthrough"
            }
          },
          {
            "layer": "server",
            "moduleId": "openai-server-module",
            "config": {
              "providerId": "openai-official"
            }
          }
        ]
      }
    },

    {
      "id": "anthropic-direct-route",
      "name": "Anthropic直接路由",
      "description": "直接使用Anthropic API（跳过转换）",
      "enabled": false,
      "priority": 95,
      "weight": 0.7,
      "conditions": {
        "models": ["claude-3-5-sonnet-20241022", "claude-3-opus-20240229"],
        "requestTypes": ["chat"],
        "features": ["streaming", "tools", "vision"]
      },
      "pipeline": {
        "layers": [
          {
            "layer": "transformer",
            "moduleId": "passthrough-transformer",
            "config": {
              "mode": "passthrough"
            }
          },
          {
            "layer": "protocol",
            "moduleId": "anthropic-protocol-module",
            "config": {
              "streamingSupport": true  
            }
          },
          {
            "layer": "server-compatibility",
            "moduleId": "passthrough-compatibility",
            "config": {
              "mode": "passthrough"
            }
          },
          {
            "layer": "server", 
            "moduleId": "anthropic-server-module",
            "config": {
              "providerId": "anthropic-official"
            }
          }
        ]
      }
    },

    {
      "id": "ollama-route",
      "name": "Ollama路由",
      "description": "使用Ollama作为本地AI服务",
      "enabled": false,
      "priority": 80,
      "weight": 0.5,
      "conditions": {
        "models": ["llama3.1:8b", "llama3.1:70b"],
        "requestTypes": ["chat", "completion"],
        "features": ["streaming"]
      },
      "pipeline": {
        "layers": [
          {
            "layer": "transformer",
            "moduleId": "anthropic-to-openai-transformer",
            "config": {
              "targetProtocol": "openai"
            }
          },
          {
            "layer": "protocol",
            "moduleId": "openai-protocol-module",
            "config": {
              "streamingSupport": true
            }
          },
          {
            "layer": "server-compatibility", 
            "moduleId": "ollama-compatibility",
            "config": {
              "providerId": "ollama-compatibility"
            }
          },
          {
            "layer": "server",
            "moduleId": "openai-server-module",
            "config": {
              "providerId": "ollama-compatibility"
            }
          }
        ]
      }
    }
  ],

  "routingRules": {
    "modelMapping": {
      "claude-3-5-sonnet-20241022": {
        "preferredRoutes": ["lmstudio-primary-route", "anthropic-direct-route"],
        "modelOverrides": {
          "lmstudio-primary-route": "llama-3.1-70b-instruct"
        }
      },
      "claude-3-haiku-20240307": {
        "preferredRoutes": ["lmstudio-primary-route"],
        "modelOverrides": {
          "lmstudio-primary-route": "llama-3.1-8b-instruct"
        }
      },
      "gpt-4": {
        "preferredRoutes": ["openai-fallback-route", "lmstudio-primary-route"],
        "modelOverrides": {
          "lmstudio-primary-route": "llama-3.1-70b-instruct"
        }
      }
    },
    "defaultRoute": "lmstudio-primary-route",
    "routeSelectionCriteria": {
      "primary": "priority",
      "secondary": "health",
      "tertiary": "weight"
    }
  },

  "configuration": {
    "strictErrorReporting": true,
    "zeroFallbackPolicy": true,
    "maxRetries": 3,
    "requestTimeout": 30000,
    "healthCheckInterval": 30000,
    "debug": false,
    "monitoring": {
      "enabled": true,
      "metricsCollection": true,
      "performanceTracking": true
    }
  },

  "validation": {
    "enforceLayerOrder": true,
    "validateModuleCompatibility": true,
    "requireHealthyProviders": true,
    "preventCrossLayerCalls": true
  }
}