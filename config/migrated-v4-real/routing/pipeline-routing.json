{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "version": "4.0.0",
  "description": "从v3迁移的路由配置",
  "lastUpdated": "2025-08-16T00:18:46.170Z",
  "pipelineArchitecture": {
    "layers": [
      {
        "order": 1,
        "name": "transformer",
        "description": "Anthropic ↔ Protocol转换层",
        "required": true
      },
      {
        "order": 2,
        "name": "protocol",
        "description": "协议控制转换层",
        "required": true
      },
      {
        "order": 3,
        "name": "server-compatibility",
        "description": "第三方服务器兼容处理层",
        "required": true
      },
      {
        "order": 4,
        "name": "server",
        "description": "标准服务器协议处理层",
        "required": true
      }
    ],
    "strictLayerEnforcement": true,
    "allowCrossLayerCalls": false
  },
  "routingStrategies": {
    "default": {
      "id": "migrated-default-strategy",
      "name": "迁移的默认策略",
      "description": "从v3 category-driven 策略迁移",
      "algorithm": "priority-weight",
      "fallbackEnabled": false,
      "strictErrorReporting": true
    }
  },
  "routes": [
    {
      "id": "openai-lmstudio-route",
      "name": "lmstudio openai 路由",
      "description": "从v3迁移的openai路由 - lmstudio",
      "enabled": true,
      "priority": 100,
      "weight": 0.8,
      "conditions": {
        "models": [
          "*"
        ],
        "requestTypes": [
          "chat",
          "completion"
        ],
        "features": [
          "streaming",
          "tools"
        ]
      },
      "pipeline": {
        "layers": [
          {
            "layer": "transformer",
            "moduleId": "anthropic-to-openai-transformer",
            "config": {
              "targetProtocol": "openai"
            }
          },
          {
            "layer": "protocol",
            "moduleId": "openai-protocol-module",
            "config": {
              "streamingSupport": false
            }
          },
          {
            "layer": "server-compatibility",
            "moduleId": "openai-compatibility",
            "config": {
              "providerId": "openai-lmstudio"
            }
          },
          {
            "layer": "server",
            "moduleId": "openai-server-module",
            "config": {
              "providerId": "openai-lmstudio"
            }
          }
        ]
      },
      "healthCheck": {
        "enabled": true,
        "interval": 30000,
        "timeoutMs": 5000
      }
    }
  ],
  "routingRules": {
    "modelMapping": {
      "claude-3-5-sonnet-20241022": {
        "preferredRoutes": [
          "lmstudio-route"
        ],
        "modelOverrides": {
          "lmstudio-route": "llama-3.1-70b-instruct"
        }
      },
      "claude-3-haiku-20240307": {
        "preferredRoutes": [
          "lmstudio-route"
        ],
        "modelOverrides": {
          "lmstudio-route": "llama-3.1-8b-instruct"
        }
      }
    },
    "defaultRoute": "openai-lmstudio-route",
    "routeSelectionCriteria": {
      "primary": "priority",
      "secondary": "health",
      "tertiary": "weight"
    }
  },
  "configuration": {
    "strictErrorReporting": true,
    "zeroFallbackPolicy": true,
    "maxRetries": 3,
    "requestTimeout": 30000,
    "healthCheckInterval": 30000,
    "debug": false,
    "monitoring": {
      "enabled": true,
      "metricsCollection": true,
      "performanceTracking": true
    }
  },
  "validation": {
    "enforceLayerOrder": true,
    "validateModuleCompatibility": true,
    "requireHealthyProviders": true,
    "preventCrossLayerCalls": true
  },
  "_encryption": {
    "version": "4.0.0",
    "algorithm": "aes-256-gcm",
    "encrypted": true,
    "timestamp": "2025-08-16T00:18:46.171Z"
  }
}