#!/usr/bin/env node

/**
 * OpenAI Preprocess Comprehensive Test
 * æµ‹è¯•OpenAIé¢„å¤„ç†åŠŸèƒ½çš„å®Œæ•´æµ‹è¯•
 * Owner: Jason Zhang
 */

const path = require('path');

// è®¾ç½®çŽ¯å¢ƒå˜é‡
process.env.RCC_PORT = '3456';

// è®¾ç½®æ¨¡å—è·¯å¾„åˆ«å
require('module-alias/register');
require('module-alias').addAlias('@', path.join(__dirname, 'dist'));

const { getModularPreprocessingManager } = require('./dist/preprocessing/modular-preprocessing-manager');
const { createOptimizedOpenAIParser } = require('./dist/providers/openai/universal-openai-parser');
const { logger } = require('./dist/utils/logger');

async function testOpenAIPreprocess() {
  console.log('ðŸ§ª [PREPROCESS-TEST] Starting OpenAI Preprocess comprehensive test');
  
  const testResults = {
    total: 0,
    passed: 0,
    failed: 0,
    errors: []
  };

  function runTest(testName, testFn) {
    testResults.total++;
    try {
      console.log(`\nðŸ”§ [TEST] ${testName}`);
      const result = testFn();
      if (result) {
        console.log(`âœ… [PASS] ${testName}`);
        testResults.passed++;
        return true;
      } else {
        console.log(`âŒ [FAIL] ${testName}`);
        testResults.failed++;
        return false;
      }
    } catch (error) {
      console.log(`ðŸ’¥ [ERROR] ${testName}: ${error.message}`);
      testResults.failed++;
      testResults.errors.push({ test: testName, error: error.message });
      return false;
    }
  }

  async function runAsyncTest(testName, testFn) {
    testResults.total++;
    try {
      console.log(`\nðŸ”§ [TEST] ${testName}`);
      const result = await testFn();
      if (result) {
        console.log(`âœ… [PASS] ${testName}`);
        testResults.passed++;
        return true;
      } else {
        console.log(`âŒ [FAIL] ${testName}`);
        testResults.failed++;
        return false;
      }
    } catch (error) {
      console.log(`ðŸ’¥ [ERROR] ${testName}: ${error.message}`);
      testResults.failed++;
      testResults.errors.push({ test: testName, error: error.message });
      return false;
    }
  }

  // æµ‹è¯•1: Modular Preprocessing Manageråˆå§‹åŒ–
  runTest('Modular Preprocessing Manager initialization', () => {
    const preprocessor = getModularPreprocessingManager(5506);
    
    console.log('  ðŸ“‹ Preprocessor created:', !!preprocessor);
    
    return preprocessor !== null && typeof preprocessor === 'object';
  });

  // æµ‹è¯•2: åŸºç¡€è¯·æ±‚é¢„å¤„ç†
  await runAsyncTest('Basic request preprocessing', async () => {
    const preprocessor = getModularPreprocessingManager();
    
    const baseRequest = {
      model: 'gpt-4',
      messages: [
        { role: 'user', content: 'Hello world!' }
      ],
      max_tokens: 1000
    };

    const processedRequest = await preprocessor.preprocessRequest(baseRequest);
    
    console.log('  ðŸ“‹ Original request:', JSON.stringify(baseRequest, null, 2));
    console.log('  ðŸ“‹ Processed request:', JSON.stringify(processedRequest, null, 2));
    
    return (
      processedRequest.model === baseRequest.model &&
      processedRequest.messages.length === baseRequest.messages.length &&
      processedRequest.metadata &&
      typeof processedRequest.metadata.requestId === 'string'
    );
  });

  // æµ‹è¯•3: è¯·æ±‚é¢„å¤„ç†metadataå¤„ç†
  await runAsyncTest('Request preprocessing metadata handling', async () => {
    const preprocessor = getModularPreprocessingManager();
    
    const baseRequest = {
      model: 'claude-sonnet-4',
      messages: [
        { role: 'user', content: 'Test message' }
      ],
      metadata: {
        requestId: 'test-123',
        customField: 'test-value'
      }
    };

    const processedRequest = await preprocessor.preprocessRequest(baseRequest);
    
    console.log('  ðŸ“‹ Metadata preservation:', {
      originalRequestId: baseRequest.metadata.requestId,
      processedRequestId: processedRequest.metadata.requestId,
      customField: processedRequest.metadata.customField
    });
    
    return (
      processedRequest.metadata.requestId === 'test-123' &&
      processedRequest.metadata.customField === 'test-value'
    );
  });

  // æµ‹è¯•4: ç©ºè¯·æ±‚å¤„ç†
  await runAsyncTest('Empty request handling', async () => {
    const preprocessor = getModularPreprocessingManager();
    
    const emptyRequest = {};

    const processedRequest = await preprocessor.preprocessRequest(emptyRequest);
    
    console.log('  ðŸ“‹ Empty request processed:', JSON.stringify(processedRequest, null, 2));
    
    return (
      processedRequest.metadata &&
      processedRequest.metadata.requestId === 'unknown'
    );
  });

  // æµ‹è¯•5: å“åº”é¢„å¤„ç†
  await runAsyncTest('Response preprocessing', async () => {
    const preprocessor = getModularPreprocessingManager();
    
    const baseResponse = {
      id: 'resp-123',
      content: [
        { type: 'text', text: 'Hello there!' }
      ],
      model: 'gpt-4',
      role: 'assistant',
      stop_reason: 'end_turn',
      usage: {
        input_tokens: 10,
        output_tokens: 20
      }
    };

    const processedResponse = await preprocessor.preprocessResponse(baseResponse);
    
    console.log('  ðŸ“‹ Response preprocessing result:', {
      originalId: baseResponse.id,
      processedId: processedResponse.id,
      contentType: processedResponse.content[0].type,
      modelMatch: baseResponse.model === processedResponse.model
    });
    
    return (
      processedResponse.id === baseResponse.id &&
      processedResponse.content.length === baseResponse.content.length &&
      processedResponse.model === baseResponse.model
    );
  });

  // æµ‹è¯•6: Universal OpenAI Parseråˆå§‹åŒ–
  runTest('Universal OpenAI Parser initialization', () => {
    const parser = createOptimizedOpenAIParser('test-request-123');
    
    console.log('  ðŸ“‹ Parser created:', !!parser);
    console.log('  ðŸ“‹ Parser has strategies:', !!parser.strategies);
    
    return parser !== null && typeof parser === 'object';
  });

  // æµ‹è¯•7: OpenAI Streamæ•°æ®è§£æž
  await runAsyncTest('OpenAI stream data parsing', async () => {
    const parser = createOptimizedOpenAIParser('test-stream-456');
    
    const streamData = `data: {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1677652288,"model":"gpt-3.5-turbo","choices":[{"index":0,"delta":{"content":"Hello"},"finish_reason":null}]}

data: {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1677652288,"model":"gpt-3.5-turbo","choices":[{"index":0,"delta":{"content":" world"},"finish_reason":null}]}

data: {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1677652288,"model":"gpt-3.5-turbo","choices":[{"index":0,"delta":{},"finish_reason":"stop"}]}

data: [DONE]`;

    const parsedEvents = await parser.processResponse(streamData, 'test-stream-456');
    
    console.log('  ðŸ“‹ Parsed events count:', parsedEvents.length);
    console.log('  ðŸ“‹ First event:', JSON.stringify(parsedEvents[0] || {}, null, 2));
    console.log('  ðŸ“‹ Last event finish_reason:', parsedEvents[parsedEvents.length - 1]?.choices?.[0]?.finish_reason);
    
    return (
      parsedEvents.length >= 3 &&
      parsedEvents[0].choices[0].delta.content === 'Hello' &&
      parsedEvents[1].choices[0].delta.content === ' world' &&
      parsedEvents[2].choices[0].finish_reason === 'stop'
    );
  });

  // æµ‹è¯•8: å·¥å…·è°ƒç”¨æµå¼æ•°æ®è§£æž
  await runAsyncTest('Tool call stream data parsing', async () => {
    const parser = createOptimizedOpenAIParser('test-tool-789');
    
    const toolCallStreamData = `data: {"id":"chatcmpl-tool","object":"chat.completion.chunk","created":1677652300,"model":"gpt-4","choices":[{"index":0,"delta":{"tool_calls":[{"index":0,"id":"call_123","type":"function","function":{"name":"get_weather","arguments":"{\\"location\\""}}]},"finish_reason":null}]}

data: {"id":"chatcmpl-tool","object":"chat.completion.chunk","created":1677652300,"model":"gpt-4","choices":[{"index":0,"delta":{"tool_calls":[{"index":0,"function":{"arguments":": \\"New York\\"}"}}]},"finish_reason":null}]}

data: {"id":"chatcmpl-tool","object":"chat.completion.chunk","created":1677652300,"model":"gpt-4","choices":[{"index":0,"delta":{},"finish_reason":"tool_calls"}]}

data: [DONE]`;

    const parsedEvents = await parser.processResponse(toolCallStreamData, 'test-tool-789');
    
    console.log('  ðŸ“‹ Tool call events count:', parsedEvents.length);
    console.log('  ðŸ“‹ First tool call event:', JSON.stringify(parsedEvents[0] || {}, null, 2));
    
    return (
      parsedEvents.length >= 3 &&
      parsedEvents[0].choices[0].delta.tool_calls &&
      parsedEvents[0].choices[0].delta.tool_calls[0].function.name === 'get_weather' &&
      parsedEvents[parsedEvents.length - 1].choices[0].finish_reason === 'tool_calls'
    );
  });

  // æµ‹è¯•9: é”™è¯¯æ•°æ®å¤„ç†
  await runAsyncTest('Invalid data handling', async () => {
    const parser = createOptimizedOpenAIParser('test-error-999');
    
    const invalidData = `data: {"invalid": "json"
data: not_json_at_all
data: {"id":"valid","choices":[{"delta":{"content":"ok"},"finish_reason":null}]}
data: [DONE]`;

    const parsedEvents = await parser.processResponse(invalidData, 'test-error-999');
    
    console.log('  ðŸ“‹ Invalid data parsed events:', parsedEvents.length);
    console.log('  ðŸ“‹ Valid event found:', !!parsedEvents.find(e => e.id === 'valid'));
    
    // åº”è¯¥è§£æžå‡º1ä¸ªæœ‰æ•ˆäº‹ä»¶ï¼ˆå¿½ç•¥æ— æ•ˆçš„ï¼‰
    return (
      parsedEvents.length >= 1 &&
      parsedEvents.some(e => e.id === 'valid')
    );
  });

  // æµ‹è¯•10: å¤§é‡æ•°æ®æ€§èƒ½æµ‹è¯•
  await runAsyncTest('Large data performance test', async () => {
    const parser = createOptimizedOpenAIParser('test-perf-1000');
    
    // ç”Ÿæˆå¤§é‡æµå¼æ•°æ®
    const largeStreamData = Array.from({ length: 100 }, (_, i) => 
      `data: {"id":"chatcmpl-perf","object":"chat.completion.chunk","created":1677652300,"model":"gpt-4","choices":[{"index":0,"delta":{"content":"chunk_${i} "},"finish_reason":null}]}`
    ).join('\n') + '\ndata: {"id":"chatcmpl-perf","object":"chat.completion.chunk","created":1677652300,"model":"gpt-4","choices":[{"index":0,"delta":{},"finish_reason":"stop"}]}\ndata: [DONE]';

    const startTime = Date.now();
    const parsedEvents = await parser.processResponse(largeStreamData, 'test-perf-1000');
    const endTime = Date.now();
    const processingTime = endTime - startTime;
    
    console.log('  ðŸ“‹ Performance test:', {
      events: parsedEvents.length,
      processingTime: `${processingTime}ms`,
      eventsPerMs: (parsedEvents.length / processingTime).toFixed(2)
    });
    
    return (
      parsedEvents.length === 101 && // 100 content chunks + 1 stop
      processingTime < 1000 // åº”è¯¥åœ¨1ç§’å†…å®Œæˆ
    );
  });

  // è¾“å‡ºæµ‹è¯•ç»“æžœ
  console.log('\nðŸ“Š [RESULTS] OpenAI Preprocess Test Summary:');
  console.log(`  Total tests: ${testResults.total}`);
  console.log(`  Passed: ${testResults.passed}`);
  console.log(`  Failed: ${testResults.failed}`);
  console.log(`  Success rate: ${((testResults.passed / testResults.total) * 100).toFixed(1)}%`);

  if (testResults.errors.length > 0) {
    console.log('\nðŸ’¥ [ERRORS] Failed tests:');
    testResults.errors.forEach(({ test, error }) => {
      console.log(`  - ${test}: ${error}`);
    });
  }

  const success = testResults.failed === 0;
  console.log(`\n${success ? 'âœ…' : 'âŒ'} [FINAL] OpenAI Preprocess test ${success ? 'PASSED' : 'FAILED'}`);
  
  return success;
}

// è¿è¡Œæµ‹è¯•
if (require.main === module) {
  testOpenAIPreprocess()
    .then(success => {
      process.exit(success ? 0 : 1);
    })
    .catch(error => {
      console.error('ðŸ’¥ [FATAL] Test execution failed:', error);
      process.exit(1);
    });
}

module.exports = { testOpenAIPreprocess };